
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>A guide to the PureScript numeric hierarchy latest documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     'latest',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="a-guide-to-the-purescript-numeric-hierarchy">
<h1>A guide to the PureScript numeric hierarchy<a class="headerlink" href="#a-guide-to-the-purescript-numeric-hierarchy" title="Permalink to this headline">¶</a></h1>
<div class="section" id="table-of-contents">
<h2>Table of contents<a class="headerlink" href="#table-of-contents" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<span id="document-introduction"></span><div class="section" id="introduction">
<h3>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h3>
<p>Welcome to this guide, which aims to give an introduction to the mathematics
behind the numeric hierarchy of type classes in PureScript’s Prelude, aimed at
people who haven’t (necessarily) studied mathematics beyond a high-school
level.</p>
<div class="section" id="why">
<h4>Why?<a class="headerlink" href="#why" title="Permalink to this headline">¶</a></h4>
<p>Normally, algebraic structures like rings or fields are only introduced to
students at undergraduate level. One unfortunate side-effect of this is that
lots of the material currently available on the web which describes these
concepts is sometimes a little inaccessible for people who haven’t studied
mathematics past a high-school level. My aim with these posts is to help people
develop intuition for what these structures are and how they can be used so
that that knowledge can be applied in PureScript code. I also hope that I can
help persuade you of the beauty of mathematics and convince you that it is
worth studying in its own right.</p>
<p>I want to stress that it is <em>not</em> necessary to read and understand all of this
in order to be able to use the PureScript type classes like <code class="docutils literal"><span class="pre">Ring</span></code> or
<code class="docutils literal"><span class="pre">Field</span></code>, and to be able to write functions which work for any type which has
a <code class="docutils literal"><span class="pre">Ring</span></code> or <code class="docutils literal"><span class="pre">Field</span></code> instance. However, I do hope that it will help you
answer questions such as:</p>
<ul class="simple">
<li>“I want to write a function which works for many different numeric
types, but should I give it a <code class="docutils literal"><span class="pre">Semiring</span></code> constraint, or a <code class="docutils literal"><span class="pre">Ring</span></code>
constraint, or something else entirely?”</li>
<li>“I have written a function with a <code class="docutils literal"><span class="pre">Field</span></code> constraint, and I want to find an
appropriate concrete type which is a <code class="docutils literal"><span class="pre">Field</span></code> to test it with. How do I do
that?”</li>
<li>“What’s the point in all of this maths mumbo-jumbo anyway — what’s wrong with
plain old Haskell-style <code class="docutils literal"><span class="pre">Num</span></code>?”</li>
</ul>
</div>
<div class="section" id="prerequisites">
<h4>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h4>
<p>I will try to assume as little knowledge of mathematics as I can. If I
accidentally assume knowledge of something which makes you unable to understand
a part of this guide, please let me know by <a class="reference external" href="https://github.com/hdgarrood/purescript-numeric-hierarchy-guide">opening an issue on
GitHub</a> or
emailing me at <a class="reference external" href="mailto:harry&#37;&#52;&#48;garrood&#46;me">harry<span>&#64;</span>garrood<span>&#46;</span>me</a>.</p>
<p>Although this guide is primarily aimed at PureScript users, I will only
reference PureScript infrequently for the purpose of illustrating examples.
This guide is really about mathematics, not PureScript.</p>
<p>Therefore, as far as is reasonably possible, I am also interested in making
this guide accessible to programmers using other languages or libraries which
make use of these same abstractions (rings, fields, etc). If you fit into this
category, and you are unable to follow something I’ve written because it
requires more than a very basic level of PureScript knowledge, please feel free
to file an issue.</p>
</div>
<div class="section" id="how-to-read-this-guide">
<h4>How to read this guide<a class="headerlink" href="#how-to-read-this-guide" title="Permalink to this headline">¶</a></h4>
<p>I will provide exercises throughout. Whenever you encounter an exercise, I
strongly recommend you attempt it before reading on! I speak from experience as
a maths student: in my personal experience, it’s simply not possible to reach
the same level of understanding without having worked through problems myself.</p>
<p>I should note that I often find it extremely tempting to skip to the solution,
read through it, and tell myself “yes, I could have done that.” Be careful of
this! It’s very easy for me to persuade myself that I could have solved a
problem when in fact I probably wouldn’t have been able to. But also it’s okay
to look at the solution if you’re really stuck; <em>attempting</em> the problem first
is the most important thing.</p>
<p>If you get stuck on an exercise for more than, say, 10 minutes, it’s okay to
skip it or simply look at the solution (although if you find yourself needing
to skip lots of exercises, perhaps consider going back and rereading some
earlier bits). Another good idea if you get stuck is to do something else and
come back to the problem the following day — of course, if you’re a programmer,
you might already know this.</p>
<p>One more thing I will say is that you shouldn’t expect to be able to read this
sort of material anywhere nearly as quickly as you might read most other types
of non-fiction prose. Mathematical writing is usually extremely dense — I don’t
mean this as a criticism of the writing style of mathematicians, but rather to
help avoid unrealistic expectations. In fact I think this density is a mostly
unavoidable consequence of the nature of mathematics. Don’t be put off if it
takes you a long time to get through this!</p>
</div>
<div class="section" id="license">
<h4>License<a class="headerlink" href="#license" title="Permalink to this headline">¶</a></h4>
<a class="reference external image-reference" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a>
<p>This work is licensed under a <a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons
Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
<p>This means you are free to copy and redistribute it as well as make changes,
but you must give credit, link to the license, and indicate if changes were
made. The license also forbids commercial use.</p>
<p>Note that the work is not necessarily exclusively licensed under CC BY-NC-SA
4.0. In particular, if you’re worried about whether your use of it counts as a
commercial use please contact me and we’ll probably be able to sort something
out.</p>
</div>
</div>
<span id="document-logic"></span><div class="section" id="logic">
<h3>Logic<a class="headerlink" href="#logic" title="Permalink to this headline">¶</a></h3>
<p>We will start with a short discussion of logic, in particular we will briefly
cover some notation and a few proof techniques. We will need these later on to
be able to make sense of statements concerning things like rings and fields,
and also to prove or disprove these statements.</p>
<p>You will probably be happy with the idea that statements such as “the sky is
blue” and “pigs can fly” can have truth-values (i.e. “true” or “false”). There
are also ways of combining statements to make new statements, which again you
are most likely familiar with already:</p>
<ul class="simple">
<li>If you have two statements <span class="math">\(P\)</span> and <span class="math">\(Q\)</span>, you can make a new
statement “<span class="math">\(P \text{ and } Q\)</span>”, which is true if both <span class="math">\(P\)</span> and
<span class="math">\(Q\)</span> are true. This is often written as <span class="math">\(P \land Q\)</span>.</li>
<li>Similarly, you can also make a new statement “<span class="math">\(P \text{ or } Q\)</span>”, which
is true if at least one of <span class="math">\(P\)</span> and <span class="math">\(Q\)</span> are true. This is often
written as <span class="math">\(P \lor Q\)</span>.</li>
</ul>
<p>So for example, if we let the symbol <span class="math">\(P\)</span> represent the statement “the sky
is blue”, and let the symbol <span class="math">\(Q\)</span> represent the statement “pigs can fly”,
the statement <span class="math">\(P \lor Q\)</span> is true, because at least one of them, in this
case <span class="math">\(P\)</span>, is true.</p>
<p><strong>Exercise 1.1.</strong> Using the same assignment of the symbols <span class="math">\(P\)</span> and
<span class="math">\(Q\)</span>, what is the truth-value of the statement <span class="math">\(P \land Q\)</span>?</p>
<div class="section" id="truth-tables">
<h4>Truth tables<a class="headerlink" href="#truth-tables" title="Permalink to this headline">¶</a></h4>
<p>We can describe the behaviour of logical operators like <span class="math">\(\land\)</span> and
<span class="math">\(\lor\)</span> using things called <em>truth tables</em>. For example, here is the truth
table for logical and (<span class="math">\(\land\)</span>):</p>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="26%" />
<col width="49%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math">\(P\)</span></th>
<th class="head"><span class="math">\(Q\)</span></th>
<th class="head"><span class="math">\(P \land Q\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>T</td>
<td>T</td>
<td>T</td>
</tr>
<tr class="row-odd"><td>T</td>
<td>F</td>
<td>F</td>
</tr>
<tr class="row-even"><td>F</td>
<td>T</td>
<td>F</td>
</tr>
<tr class="row-odd"><td>F</td>
<td>F</td>
<td>F</td>
</tr>
</tbody>
</table>
<p>The table lists the four possible combinations of truth-values of <span class="math">\(P\)</span> and
<span class="math">\(Q\)</span>, as well as the truth-value of <span class="math">\(P \land Q\)</span> in each case. If
this isn’t clear, it might help to compare it to an implementation of
<span class="math">\(\land\)</span> in PureScript:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">logicalAnd</span> <span class="p">::</span> <span class="n">Boolean</span> <span class="o">-&gt;</span> <span class="n">Boolean</span> <span class="o">-&gt;</span> <span class="n">Boolean</span>
<span class="n">logicalAnd</span> <span class="n">true</span> <span class="n">true</span> <span class="o">=</span> <span class="n">true</span>
<span class="n">logicalAnd</span> <span class="n">true</span> <span class="n">false</span> <span class="o">=</span> <span class="n">false</span>
<span class="n">logicalAnd</span> <span class="n">false</span> <span class="n">true</span> <span class="o">=</span> <span class="n">false</span>
<span class="n">logicalAnd</span> <span class="n">false</span> <span class="n">false</span> <span class="o">=</span> <span class="n">false</span>
</pre></div>
</div>
<p><strong>Exercise 1.2.</strong> Write out the truth table for logical or, <span class="math">\(\lor\)</span>.</p>
</div>
<div class="section" id="logical-equivalence">
<h4>Logical equivalence<a class="headerlink" href="#logical-equivalence" title="Permalink to this headline">¶</a></h4>
<p>We say that two statements are <em>logically equivalent</em> if they always have the
same truth value as each other, that is, if they are always either both true or
both false. Here is a truth table for logical equivalence with some entries
missing:</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="60%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math">\(P\)</span></th>
<th class="head"><span class="math">\(Q\)</span></th>
<th class="head"><span class="math">\(P \Leftrightarrow Q\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>T</td>
<td>T</td>
<td>T</td>
</tr>
<tr class="row-odd"><td>T</td>
<td>F</td>
<td>F</td>
</tr>
<tr class="row-even"><td>F</td>
<td>T</td>
<td>?</td>
</tr>
<tr class="row-odd"><td>F</td>
<td>F</td>
<td>?</td>
</tr>
</tbody>
</table>
<p><strong>Exercise 1.3.</strong> Complete the missing entries of this truth table.</p>
<p>So for example, <span class="math">\(P \land P\)</span> is always logically equivalent to <span class="math">\(P\)</span>,
regardless of the truth-value of <span class="math">\(P\)</span>. We can express this in symbols by
using a double-ended arrow like this: <span class="math">\(P \land P \Leftrightarrow P\)</span>.</p>
</div>
<div class="section" id="logical-negation">
<h4>Logical negation<a class="headerlink" href="#logical-negation" title="Permalink to this headline">¶</a></h4>
<p>Another thing we can do with statements is <em>negate</em> them: make a new statement
which is true if the original statement is false, and false if the original
statement is true. If <span class="math">\(P\)</span> is a statement, then the logical negation of
<span class="math">\(P\)</span> is written as <span class="math">\(\neg P\)</span>.</p>
<p>The following two equivalences hold regardless of the truth-values of <span class="math">\(P\)</span>
and <span class="math">\(Q\)</span>:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\neg (P \land Q) \; \Leftrightarrow \; \neg P \lor \neg Q\\\neg (P \lor Q) \; \Leftrightarrow \; \neg P \land \neg Q\end{aligned}\end{align} \]</div>
<p>These two equivalences are called <em>De Morgan’s laws.</em></p>
<p><strong>Exercise 1.4.</strong> Persuade yourself that De Morgan’s laws hold. One way to do
this is to write out a truth table.</p>
</div>
<div class="section" id="logical-implication">
<h4>Logical implication<a class="headerlink" href="#logical-implication" title="Permalink to this headline">¶</a></h4>
<p>We now consider statements of the form “if <span class="math">\(P\)</span>, then <span class="math">\(Q\)</span>“, for
example:</p>
<ul class="simple">
<li>if it is raining, then we will get wet,</li>
<li>if <span class="math">\(x\)</span> is even, then it can be divided by <span class="math">\(2\)</span> exactly,</li>
<li>if <span class="math">\(y\)</span> is even and <span class="math">\(z\)</span> is even, then <span class="math">\(y + z\)</span> is even.</li>
</ul>
<p>We represent this kind of statement by defining a new logical operator called
<em>logical implication</em>, which we write as a rightwards-pointing arrow:
<span class="math">\(\text{it is raining} \Rightarrow \text{we will get wet}\)</span>.</p>
<p>The logical implication operator is defined as follows:</p>
<table border="1" class="docutils">
<colgroup>
<col width="22%" />
<col width="22%" />
<col width="56%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math">\(P\)</span></th>
<th class="head"><span class="math">\(Q\)</span></th>
<th class="head"><span class="math">\(P \Rightarrow Q\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>T</td>
<td>T</td>
<td>T</td>
</tr>
<tr class="row-odd"><td>T</td>
<td>F</td>
<td>F</td>
</tr>
<tr class="row-even"><td>F</td>
<td>T</td>
<td>T</td>
</tr>
<tr class="row-odd"><td>F</td>
<td>F</td>
<td>T</td>
</tr>
</tbody>
</table>
<p>That is, <span class="math">\(P \Rightarrow Q\)</span> is a logical statement just like all of the
others we have seen, and it has a truth-value which depends on the truth-values
of <span class="math">\(P\)</span> and <span class="math">\(Q\)</span>.</p>
<p><strong>Exercise 1.5.</strong> Persuade yourself, by using a truth table (or any other
method that works for you), that <span class="math">\(P \Rightarrow Q\)</span> is always logically
equivalent to <span class="math">\(\neg P \lor Q\)</span> regardless of the truth-values of <span class="math">\(P\)</span>
and <span class="math">\(Q\)</span>.</p>
<p>The standard way of proving a statement of the form <span class="math">\(P \Rightarrow Q\)</span> is
to first assume that <span class="math">\(P\)</span> is true, and then show that <span class="math">\(Q\)</span> follows,
i.e. show that <span class="math">\(Q\)</span> must also be true.</p>
<p>For example, suppose we wanted to prove the statement</p>
<div class="math">
\[x \text{ is even} \Rightarrow x^2 \text{ is even}.\]</div>
<p>We would start by letting <span class="math">\(x\)</span> be some arbitrary integer and assuming that
it is even. Since <span class="math">\(x\)</span> is even, we can write <span class="math">\(x = 2m\)</span> for some
integer <span class="math">\(m\)</span>. Then, <span class="math">\(x^2 = 4m^2\)</span> and therefore we have shown
<span class="math">\(x^2\)</span> has <span class="math">\(4\)</span> as a factor, so it must also have <span class="math">\(2\)</span> as a
factor, which means it must be even.</p>
</div>
<div class="section" id="converses">
<h4>Converses<a class="headerlink" href="#converses" title="Permalink to this headline">¶</a></h4>
<p>If we have a statement which is a logical implication, for example <span class="math">\(x
\text{ is even} \Rightarrow x \text{ can be divided by 2 exactly}\)</span>, there is
another closely related statement called its <em>converse</em>. To find the converse
of an implication statement, we simply swap the two operands. For example, the
converse of the statement</p>
<div class="math">
\[x \text{ is even} \Rightarrow x \text{ can be divided by 2 exactly}\]</div>
<p>is this:</p>
<div class="math">
\[x \text{ can be divided by 2 exactly} \Rightarrow x \text{ is even}\]</div>
<p>Notice that both of the above statements are true. However, this is often not
the case! If a statement is true, it is not safe to assume that its converse is
also true. For example, consider the statement</p>
<div class="math">
\[y \text{ is even and } z \text{ is even} \Rightarrow y + z \text{ is even}\]</div>
<p>The converse of this statement is</p>
<div class="math">
\[y + z \text{ is even} \Rightarrow y \text{ is even and } z \text{ is even}\]</div>
<p>Notice that, while the first is true, the second is not. For instance, if
we take <span class="math">\(y = z = 1\)</span>, then <span class="math">\(y + z\)</span> is even, but neither <span class="math">\(y\)</span>
nor <span class="math">\(z\)</span> is.</p>
</div>
<div class="section" id="contrapositives">
<h4>Contrapositives<a class="headerlink" href="#contrapositives" title="Permalink to this headline">¶</a></h4>
<p>If we have a statement which is a logical implication, for example
<span class="math">\(\text{my pet is a cat} \Rightarrow \text{my pet is a mammal}\)</span>, there is
another closely related statement called its <em>contrapositive</em>. To find the
contrapositive of a logical implication statement, we swap the operands and
negate them both. So, for example, the contrapositive of the statement
<span class="math">\(\text{my pet is a cat} \Rightarrow \text{my pet is a mammal}\)</span> is the
statement <span class="math">\(\text{my pet is not a mammal} \Rightarrow \text{my pet is not
a cat}\)</span>.</p>
<p>The first thing to notice is that any implication statement is always logically
equivalent to its contrapositive.</p>
<p><strong>Exercise 1.6.</strong> Check this! Persuade yourself that <span class="math">\(P \Rightarrow Q\)</span> is
always logically equivalent to <span class="math">\(\neg Q \Rightarrow \neg P\)</span>, perhaps with
a truth table.</p>
<p>This exercise suggests another way of proving statements of the form <span class="math">\(P
\Rightarrow Q\)</span>, which is to instead assume that <span class="math">\(\neg Q\)</span> is true, and
show that <span class="math">\(\neg P\)</span> follows. This technique is called <em>contraposition;</em>
the new statement is called the <em>contrapositive</em> of the original one.</p>
<p><strong>Exercise 1.7.</strong> Use contraposition to prove the statement</p>
<div class="math">
\[x^2 \text{ is odd} \Rightarrow x \text{ is odd}.\]</div>
<p>Another way of thinking of logical equivalence is in terms of logical
implication. Specifically, an alternative way of defining
<span class="math">\(\Leftrightarrow\)</span> is by saying that <span class="math">\(P \Leftrightarrow Q\)</span> is the
same as this bad boy:</p>
<div class="math">
\[(P \Rightarrow Q) \land (Q \Rightarrow P)\]</div>
<p>In fact, the standard way of proving a statement of the form <span class="math">\(P
\Leftrightarrow Q\)</span> is to first prove <span class="math">\(P \Rightarrow Q\)</span> and then to prove
<span class="math">\(Q \Rightarrow P\)</span>.</p>
</div>
<div class="section" id="sets">
<h4>Sets<a class="headerlink" href="#sets" title="Permalink to this headline">¶</a></h4>
<p>For our purposes, it will be sufficient to say a set is a collection of any
kind of mathematical object: sets may contain numbers, functions, sets of
numbers, and so on.</p>
<p>We can write a set by listing the elements in between curly braces, like this:</p>
<div class="math">
\[\{1, 2, 3\}\]</div>
<p>Note that sets have no concept of ordering, so the set <span class="math">\(\{1, 3, 2\}\)</span> is
the same as the set <span class="math">\(\{1, 2, 3\}\)</span>.</p>
<p>The only thing we can really do with a set is to ask whether it contains some
particular thing. The notation for the statement “<span class="math">\(a\)</span> exists within the
set <span class="math">\(A\)</span>” looks like this:</p>
<div class="math">
\[a \in A.\]</div>
<p>We also have a notation for the negation of this statement, i.e. “<span class="math">\(a\)</span>
does not exist within the set <span class="math">\(A\)</span>“:</p>
<div class="math">
\[a \notin A.\]</div>
<p>Often (but not always), uppercase letters denote sets, and lowercase letters
denote elements of sets.</p>
<p>Here are a few sets you may have come across already:</p>
<ul class="simple">
<li>The set of <em>natural numbers,</em> <span class="math">\(\{0, 1, 2, 3, 4, ...\}\)</span>. That is, the
set of all the integers which are not negative. This set comes up fairly
often so we have a special notation for it: <span class="math">\(\mathbb{N}\)</span>. (Note:
depending on context, <span class="math">\(0\)</span> is sometimes not considered to be an element
of <span class="math">\(\mathbb{N}\)</span>; in this guide we will say that it is.)</li>
<li>The set of <em>integers,</em> <span class="math">\(\{0, 1, -1, 2, -2, 3, -3, ...\}\)</span>. Like
<span class="math">\(\mathbb{N}\)</span> but it also includes negative numbers. We have a special
notation for this set too: <span class="math">\(\mathbb{Z}\)</span>, from the German <em>Zahlen,</em>
which just means “numbers”.</li>
<li>The set of <em>real numbers,</em> which is the kind of number you’re probably most
used to. <span class="math">\(0, 1, 37, \frac{1}{2}\)</span>, and <span class="math">\(\pi\)</span> are all examples of
real numbers. This set also has a special notation: <span class="math">\(\mathbb{R}\)</span>.</li>
</ul>
<p>So for example, the following are all true:</p>
<div class="math">
\[ \begin{align}\begin{aligned}6 \in \mathbb{N}\\\frac{2}{3} \in \mathbb{R}\\
\frac{2}{3} \notin \mathbb{N}.\end{aligned}\end{align} \]</div>
</div>
<div class="section" id="quantifiers">
<h4>Quantifiers<a class="headerlink" href="#quantifiers" title="Permalink to this headline">¶</a></h4>
<p>Up to now, the symbols <span class="math">\(P\)</span> and <span class="math">\(Q\)</span> have always represented
statements. However we can also use symbols to represent <em>predicates</em>, which
are like functions which return statements. For example, we might have a
predicate “<span class="math">\(x\)</span> is even”, “<span class="math">\(x\)</span> is divisible by 6”, or “<span class="math">\(x\)</span> is
prime”.</p>
<p>If we let <span class="math">\(P(x)\)</span> represent the predicate “<span class="math">\(x\)</span> is even”, then we can
write the statement “2 is even” as <span class="math">\(P(2)\)</span>. Similarly we can
write the statement “3 is even” as <span class="math">\(P(3)\)</span>. In each case we get a
statement whose truth-value can depend on the specific value of <span class="math">\(x\)</span> which
was chosen — in this case, <span class="math">\(P(2)\)</span> would be true, and <span class="math">\(P(3)\)</span> would
be false.</p>
<p>If we have a predicate, we can make statements about the truth-values of a
predicate over all the possible values it can take as arguments by using things
called <em>quantifiers</em>.</p>
<p>The first quantifier we will introduce is called “for all”, written as an
upside-down capital letter A like this: <span class="math">\(\forall\)</span>. Here is how we write the
statement “the square of any real number is greater than or equal to 0” using
the <span class="math">\(\forall\)</span> quantifier:</p>
<div class="math">
\[\forall x \in \mathbb{R}.\; x^2 \geq 0\]</div>
<p>This can be read as: “For all <span class="math">\(x\)</span> in <span class="math">\(\mathbb{R}\)</span>, <span class="math">\(x\)</span>
squared is greater than or equal to <span class="math">\(0\)</span>.”</p>
<p>The standard way of proving a statement like this is more or less what you
might expect: we have to show that every element of the set satisfies the
predicate. If the set is finite, we can do this by checking each element
individually. However, individual checking quickly gets very tedious for even
fairly small sets. Additionally, we often deal with infinite sets, where
exhaustively checking each element individually is not possible. Therefore, we
will usually prove statements of this kind by constructing an argument which
deals with every single element of the set <em>at the same time.</em> In fact, we have
already seen an example of such a proof: the proof that <span class="math">\(x\)</span> being even
implies that <span class="math">\(x^2\)</span> is also even, from a moment ago.</p>
<p>The other quantifier we will use is written as a back-to-front capital letter
E, like this: <span class="math">\(\exists\)</span>, and can be read as “there exists”. Here is how
we would write the statement “there exists a real number whose square is 4” in
mathematical notation:</p>
<div class="math">
\[\exists x \in \mathbb{R}.\; x^2 = 4\]</div>
<p>There are two possible values of <span class="math">\(x\)</span> which you can use as examples to
show that this statement is true: <span class="math">\(2\)</span> and <span class="math">\(-2\)</span>. In fact, the
standard way of proving a statement of the form <span class="math">\(\exists x. P(x)\)</span> is to
pick a specific value of <span class="math">\(x\)</span> and demonstrate that <span class="math">\(P(x)\)</span> is true
for that <span class="math">\(x\)</span> (again, as you might expect).</p>
<p><strong>Exercise 1.8.</strong> Prove the statement <span class="math">\(\exists x \in \mathbb{R}.\; 3x + 4
= 13\)</span> by finding a suitable value for <span class="math">\(x\)</span>.</p>
<p>The last thing we need to know in this section is how to negate statements that
contain quantifiers. Here goes:</p>
<ul class="simple">
<li>The negation of the statement <span class="math">\(\forall x. P(x)\)</span> is <span class="math">\(\exists x.
\neg P(x)\)</span>.</li>
<li>The negation of the statement <span class="math">\(\exists x. P(x)\)</span> is <span class="math">\(\forall x.
\neg P(x)\)</span>.</li>
</ul>
<p>This is all rather pleasingly symmetric, isn’t it? Try to make sense of these
two rules if you can; they will be useful later. Hopefully if you think about
them for a bit you’ll be able to persuade yourself intuitively why they are
true.</p>
<p><strong>Exercise 1.9.</strong> Show that the statement <span class="math">\(\forall x \in \mathbb{R}.\;
x &lt; x^2\)</span> is false by finding a <em>counterexample</em> — that is, a value of
<span class="math">\(x\)</span> such that <span class="math">\(x &lt; x^2\)</span> does not hold. Do you see how we are using
the first of the above two rules for negating statements with quantifiers here?</p>
</div>
</div>
<span id="document-monoids"></span><div class="section" id="monoids">
<h3>Monoids<a class="headerlink" href="#monoids" title="Permalink to this headline">¶</a></h3>
<p>You are probably already aware of <em>monoids</em> (via the <code class="docutils literal"><span class="pre">Monoid</span></code> type class),
since they come up quite often in programming. We’ll just quickly remind
ourselves about what makes something a monoid and cover a few examples, but in
a slightly more mathematically-oriented way. The main aim of this section is to
make you a bit more comfortable about mathematical ideas and notations by using
them to describe an idea which you are hopefully already familiar with. Another
purpose of this section is to prepare you for the next section, in which we
will talk about a specific kind of monoid which turns out to be rather
important.</p>
<p>Here are a few rules about how adding integers together works:</p>
<ul class="simple">
<li>If we add together two integers, we always get another integer.</li>
<li>It doesn’t matter what order we bracket up additions, we always get the same
answer. That is, <span class="math">\((x + y) + z\)</span> is always the same as <span class="math">\(x + (y +
z)\)</span> for any integers <span class="math">\(x, y, z\)</span>.</li>
<li>Adding <span class="math">\(0\)</span> to any integer yields the same integer.</li>
</ul>
<p>Here are a few more rules about how multiplying integers works:</p>
<ul class="simple">
<li>If we multiply two integers, we always get another integer.</li>
<li>It doesn’t matter what order we bracket up multiplications, we always get the
same answer. That is, <span class="math">\((xy)z\)</span> is always the same as <span class="math">\(x(yz)\)</span> for
any integers <span class="math">\(x, y, z\)</span>.</li>
<li>Multiplying any integer by <span class="math">\(1\)</span> yields the same integer.</li>
</ul>
<p>Now, instead of integers, we will consider a different set: the set of
truth-values <span class="math">\(\{T, F\}\)</span>. This set corresponds to the <code class="docutils literal"><span class="pre">Boolean</span></code> type in
PureScript. Here are some rules for how the “logical and” operation
<span class="math">\((\land)\)</span> works on truth-values:</p>
<ul class="simple">
<li>If we apply the <span class="math">\(\land\)</span> operation to two truth-values, we always get
another truth-value.</li>
<li>It doesn’t matter what order we bracket up <span class="math">\(\land\)</span>, we always get the
same answer. That is, <span class="math">\((x \land y) \land z\)</span> is the same as <span class="math">\(x
\land (y \land z)\)</span> for all <span class="math">\(x, y, z\)</span>.</li>
<li><span class="math">\(P \land T\)</span> is always the same as <span class="math">\(P\)</span>, for any truth-value
<span class="math">\(P\)</span>. If it’s not obvious what I mean by <span class="math">\(P \land T\)</span>, it means the
same thing as the PureScript code <code class="docutils literal"><span class="pre">p</span> <span class="pre">&amp;&amp;</span> <span class="pre">true</span></code>.</li>
</ul>
<p>Hopefully a pattern will be starting to emerge: in each case, we have a set,
an operation which gives us a way of combining two elements of that set to
produce another element of the same set, and some rules that the operation
should satisfy. The general definition of a monoid is as follows:</p>
<p>A monoid is a set <span class="math">\(M\)</span>, together with an operation <span class="math">\(*\)</span>, such that
the following laws hold:</p>
<ol class="arabic simple">
<li><em>Closure.</em> <span class="math">\(\forall x, y \in M.\; x * y \in M\)</span>.</li>
<li><em>Associativity.</em> <span class="math">\(\forall x, y, z \in M.\; (x * y) * z = x * (y * z)\)</span>.</li>
<li><em>Identity.</em> <span class="math">\(\exists e \in M.\; \forall x \in M.\; e * x = x * e = x\)</span>.</li>
</ol>
<p>Looking back to the examples above, we have the monoids of:</p>
<ul class="simple">
<li><em>the integers under addition</em>, where the set is <span class="math">\(\mathbb{Z}\)</span>, the
operation is addition, and the identity element is <span class="math">\(0\)</span>,</li>
<li><em>the integers under multiplication</em>, where the set is <span class="math">\(\mathbb{Z}\)</span>, the
operation is multiplication, and the identity element is <span class="math">\(1\)</span>,</li>
<li><em>truth values under logical and</em>, where the set is <span class="math">\(\{T, F\}\)</span>, the
operation is <span class="math">\(\land\)</span>, and the identity element is <span class="math">\(T\)</span>.</li>
</ul>
<p>The operation <span class="math">\(*\)</span> corresponds to <code class="docutils literal"><span class="pre">append</span></code> in PureScript, and that the
identity element (conventionally written <span class="math">\(e\)</span>) corresponds to <code class="docutils literal"><span class="pre">mempty</span></code>
in PureScript.</p>
<p>We will now look at a few non-examples of monoids and talk about why they fail
to be monoids.</p>
<p>First, if we take the set of natural numbers which are less than 4, that is
<span class="math">\(\{0, 1, 2, 3\}\)</span>, and take addition as the operation, this fails to be a
monoid because it does not satisfy closure. To show this we need to find a pair
of elements such that their sum is not in the set. One such choice is <span class="math">\(3
+ 1\)</span>, which of course equals <span class="math">\(4\)</span>, which is not in the set. We say that a
set is <em>closed under</em> an operation if performing that operation on two elements
of the set always produces another element of the set; this is where the name
“closure” comes from.</p>
<p>An example of something failing to be a monoid because the operation is not
associative could be the set of floating point number values under addition.
For example, try <code class="docutils literal"><span class="pre">(0.1</span> <span class="pre">+</span> <span class="pre">0.2)</span> <span class="pre">+</span> <span class="pre">0.3</span></code> in a console, and compare the result to
<code class="docutils literal"><span class="pre">0.1</span> <span class="pre">+</span> <span class="pre">(0.2</span> <span class="pre">+</span> <span class="pre">0.3)</span></code>.</p>
<p>An example of something failing to be a monoid because of a lack of an
identity element could be the set of even numbers under multiplication. The
first two laws are satisfied, but since 1 is not an even number, we don’t have
an identity element.</p>
<p>A brief interlude on notation: if we want to refer to a specific monoid, we
write it as a pair where the first element is the set and the second is the
operation. For example, the monoid of integers under addition is written as
<span class="math">\((\mathbb{Z}, +)\)</span>. If it is clear from context which operation we are
talking about, we often omit the operation and just write the set, e.g. we
might simply say <span class="math">\(\mathbb{Z}\)</span> is a monoid.</p>
<p><strong>Exercise 2.1.</strong> Consider the set of natural numbers together with the
operation of subtraction: <span class="math">\((\mathbb{N}, -)\)</span>. This is <em>not</em> a monoid. Can
you say which of the three laws fail to hold (it might be more than one) and
why?</p>
<p><strong>Exercise 2.2.</strong> The set of <em>rational numbers</em> is the set of numbers which can
be written as the ratio of two integers <span class="math">\(\frac{a}{b}\)</span>. There is a
short-hand notation for this set too: <span class="math">\(\mathbb{Q}\)</span> (for “quotient”).
Show that <span class="math">\((\mathbb{Q}, +)\)</span> is a monoid by checking each of the three
laws. What is the identity element?</p>
<div class="section" id="uniqueness-of-identity-elements">
<h4>Uniqueness of identity elements<a class="headerlink" href="#uniqueness-of-identity-elements" title="Permalink to this headline">¶</a></h4>
<p><strong>Exercise 2.3.</strong> (Harder) Prove that a monoid can only have one identity
element. To do this, first suppose that you have two elements of some monoid;
call them, say, <span class="math">\(e\)</span> and <span class="math">\(e'\)</span>, and then show that if they are both
identity elements then they must be equal to each other. Be careful here: it’s
not enough to take one specific example of a monoid and show that it only has
one identity element. You have to construct an argument which will work for
<em>any</em> monoid, which means you aren’t allowed to assume anything beyond what is
in the definition of a monoid.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In general, if we want to prove that there is a unique element of some set
which has some particular property, we do this by taking two arbitrary
elements of the set, assuming that they both have this property, and then
showing that they must be equal.</p>
</div>
<p>Since monoids have a unique identity element, we can talk about <em>the</em> identity
element of a monoid, rather than just <em>an</em> identity element.</p>
</div>
<div class="section" id="some-more-examples">
<h4>Some more examples<a class="headerlink" href="#some-more-examples" title="Permalink to this headline">¶</a></h4>
<p>Consider the set <span class="math">\(\{e\}\)</span>, which contains precisely one element,
<span class="math">\(e\)</span>. We can define an operation <span class="math">\(*\)</span> on this set as follows:</p>
<div class="math">
\[e * e = e\]</div>
<p>That’s all we need to do to define <span class="math">\(*\)</span>, because there are no other
possible values to consider. Then, <span class="math">\(\{e\}\)</span> is a monoid. It’s not very
interesting which is why it gets called the <em>trivial monoid</em>. This corresponds
exactly to the <code class="docutils literal"><span class="pre">Unit</span></code> type in PureScript; the <code class="docutils literal"><span class="pre">Unit</span></code> type has precisely
this <code class="docutils literal"><span class="pre">Monoid</span></code> instance too.</p>
<p>Let <span class="math">\(X\)</span> be any set, and consider the set of functions from <span class="math">\(X\)</span> to
<span class="math">\(X\)</span>, which we denote by <span class="math">\(\mathrm{Maps}(X, X)\)</span>. If we take function
composition <span class="math">\(\circ\)</span> as our operation, we have a monoid
<span class="math">\((\mathrm{Maps}(X, X), \circ)\)</span>.  Let’s check this:</p>
<ol class="arabic simple">
<li><em>Closure.</em> The composite of two functions from <span class="math">\(X\)</span> to <span class="math">\(X\)</span> is
itself a function from <span class="math">\(X\)</span> to <span class="math">\(X\)</span>, so closure is satisfied.</li>
<li><em>Associativity.</em> Function composition is associative, so associativity is
satisfied.</li>
<li><em>Identity.</em> The identity function <span class="math">\(e : X \rightarrow X\)</span> defined by
<span class="math">\(e(x) = x\)</span> for all <span class="math">\(x \in X\)</span> is the identity element with
respect to function composition, so identity is satisfied.</li>
</ol>
<p>This may seem a bit abstract, so here’s a concrete example. We will take the
set <span class="math">\(X\)</span> to be the set <span class="math">\(\{A, B\}\)</span> which contains just two elements.
(The elements <span class="math">\(A\)</span> and <span class="math">\(B\)</span> don’t really mean anything here, they’re
just symbols.) Then there are four functions from <span class="math">\(X\)</span> to <span class="math">\(X\)</span>:</p>
<ul class="simple">
<li>The identity function <span class="math">\(e(x) = x\)</span>,</li>
<li>The constant functions <span class="math">\(f_A\)</span> and <span class="math">\(f_B\)</span>, which ignore their
argument and always return <span class="math">\(A\)</span> and <span class="math">\(B\)</span> respectively, and</li>
<li>The swapping function <span class="math">\(f_{swap}\)</span>, which sends <span class="math">\(A\)</span> to <span class="math">\(B\)</span>,
and <span class="math">\(B\)</span> to <span class="math">\(A\)</span>.</li>
</ul>
<p>In PureScript:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">e</span> <span class="p">::</span> <span class="n">X</span> <span class="o">-&gt;</span> <span class="n">X</span>
<span class="n">e</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
  <span class="o">--</span> <span class="ow">or</span> <span class="n">simply</span> <span class="n">e</span> <span class="o">=</span> <span class="n">identity</span>

<span class="n">fA</span> <span class="p">::</span> <span class="n">X</span> <span class="o">-&gt;</span> <span class="n">X</span>
<span class="n">fA</span> <span class="n">_</span> <span class="o">=</span> <span class="n">A</span>
  <span class="o">--</span> <span class="ow">or</span> <span class="n">simply</span> <span class="n">f1</span> <span class="o">=</span> <span class="n">const</span> <span class="n">A</span>

<span class="n">fB</span> <span class="p">::</span> <span class="n">X</span> <span class="o">-&gt;</span> <span class="n">X</span>
<span class="n">fB</span> <span class="n">_</span> <span class="o">=</span> <span class="n">B</span>
  <span class="o">--</span> <span class="ow">or</span> <span class="n">simply</span> <span class="n">f2</span> <span class="o">=</span> <span class="n">const</span> <span class="n">B</span>

<span class="n">fSwap</span> <span class="p">::</span> <span class="n">X</span> <span class="o">-&gt;</span> <span class="n">X</span>
<span class="n">fSwap</span> <span class="n">A</span> <span class="o">=</span> <span class="n">B</span>
<span class="n">fSwap</span> <span class="n">B</span> <span class="o">=</span> <span class="n">A</span>
</pre></div>
</div>
<p>Here are a few examples of how the monoid operation works in this monoid:</p>
<div class="math">
\[ \begin{align}\begin{aligned}f_A \circ f_B = f_A\\f_B \circ f_{swap} = f_B\\f_{swap} \circ f_{swap} = e\end{aligned}\end{align} \]</div>
<p>(check that you agree).</p>
<p>This monoid is implemented in PureScript in the module <code class="docutils literal"><span class="pre">Data.Monoid.Endo</span></code>,
which is part of the <code class="docutils literal"><span class="pre">purescript-prelude</span></code> library.</p>
<p>We now move on to the last example of a monoid in this chapter:</p>
<p><strong>Exercise 2.4.</strong> Let <span class="math">\((M, *)\)</span> be any monoid, and let <span class="math">\(X\)</span> be any
set. Define an operation <span class="math">\(\star\)</span> on the set <span class="math">\(\mathrm{Maps}(X, M)\)</span> —
that is, the set of functions from <span class="math">\(X\)</span> to <span class="math">\(M\)</span> — as follows:</p>
<div class="math">
\[f \star g = x \mapsto f(x) * g(x)\]</div>
<p>On notation: the arrow (<span class="math">\(\mapsto\)</span>) can be read “maps to”. The
mathematical notation <span class="math">\(x \mapsto x + 4\)</span> means essentially the same thing
as the PureScript code <code class="docutils literal"><span class="pre">\x</span> <span class="pre">-&gt;</span> <span class="pre">x</span> <span class="pre">+</span> <span class="pre">4</span></code>, that is, it denotes a function.</p>
<p>That is, the star product <span class="math">\(\star\)</span> of two functions <span class="math">\(f\)</span> and
<span class="math">\(g\)</span> is a new function which applies both <span class="math">\(f\)</span> and <span class="math">\(g\)</span> to its
argument, and then combines the results using the monoid operation <span class="math">\(*\)</span>
from the monoid <span class="math">\(M\)</span>.  Prove that <span class="math">\((\mathrm{Maps}(X, M), \star)\)</span> is
a monoid; what is the identity element?</p>
<p>The monoid in this exercise is <em>also</em> implemented in PureScript’s <code class="docutils literal"><span class="pre">Prelude</span></code>;
in fact it is the default <code class="docutils literal"><span class="pre">Monoid</span></code> instance for functions, written as
<code class="docutils literal"><span class="pre">Monoid</span> <span class="pre">b</span> <span class="pre">=&gt;</span> <span class="pre">Monoid</span> <span class="pre">(a</span> <span class="pre">-&gt;</span> <span class="pre">b)</span></code>.</p>
</div>
</div>
<span id="document-groups"></span><div class="section" id="groups">
<h3>Groups<a class="headerlink" href="#groups" title="Permalink to this headline">¶</a></h3>
<p>Suppose we have some arbitrary monoid <span class="math">\((M, *)\)</span>, and we are given two
elements <span class="math">\(a, b \in M\)</span>, and we want to solve an equation of the form:</p>
<div class="math">
\[a * x = b\]</div>
<p>That is, we want to find some <span class="math">\(x \in M\)</span> such that the equation is
satisfied. Can we always do this?</p>
<p>We will start by looking at some examples. First consider <span class="math">\((\mathbb{Z},
+)\)</span>. In this case, one example of such an equation might be this:</p>
<div class="math">
\[4 + x = 7\]</div>
<p>You can probably see how to solve this already: simply subtract 4 from both
sides, and you’re left with this:</p>
<div class="math">
\[x = 7 - 4 = 3\]</div>
<p>Easy. In fact, with this monoid, we can always solve this kind of equation,
regardless of which values of <span class="math">\(a\)</span> and <span class="math">\(b\)</span> we are given: in general,
the solution is <span class="math">\(x = b - a\)</span>.</p>
<p>Now we consider a different monoid: <span class="math">\((\mathbb{N}, +)\)</span>. Can we solve the
following equation with this monoid?</p>
<div class="math">
\[4 + x = 2\]</div>
<p>We can’t! If we were working with a set which contains negative numbers, we
would be fine: in this case, the answer would be <span class="math">\(-2\)</span>. But <span class="math">\(-2
\notin \mathbb{N}\)</span>.</p>
<p><strong>Exercise 3.1.</strong> Can you think of another example of a monoid <span class="math">\(M\)</span> and
elements <span class="math">\(a, b \in M\)</span> so that the equation <span class="math">\(a*x = b\)</span> has no
solutions in <span class="math">\(M\)</span>? Hint: we discussed one possible monoid in the previous
chapter.</p>
<p>So it appears that there’s some fundamental difference between
the monoids <span class="math">\((\mathbb{Z}, +)\)</span> and <span class="math">\((\mathbb{N}, +)\)</span>. This suggests
that there might be a way of categorising monoids, based on whether any
equation of this form can be solved. Our next task as mathematicians is to try
to make this a bit more precise!</p>
<p>We do this by defining a new algebraic structure called a <em>group</em>, which is a
monoid with one extra requirement. Suppose we have a monoid <span class="math">\((G, *)\)</span>. We
say that <span class="math">\((G, *)\)</span> is a group if and only if it satisfies this additional
law:</p>
<ul class="simple">
<li><em>Inverses.</em> <span class="math">\(\forall g \in G.\; \exists h \in G.\; g * h = h * g = e\)</span></li>
</ul>
<p>That is, every element has an inverse, and combining an element with its
inverse gives you the identity.</p>
<p>If you’re wondering why I’m using different letters now, it’s nothing more than
a convention: people generally use <span class="math">\(G\)</span> to refer to some arbitrary group,
and lowercase letters starting from <span class="math">\(g\)</span> to refer to elements of a group.</p>
<p>We often omit the <span class="math">\(*\)</span> symbol; you might see people expressing the above
property as <span class="math">\(\forall g \in G.\; \exists h \in G.\; gh = hg = e\)</span>.</p>
<p><span class="math">\((\mathbb{Z}, +)\)</span> is the first example of a group we will consider. In
this group, the inverse of <span class="math">\(1\)</span> is <span class="math">\(-1\)</span>, the inverse of <span class="math">\(-5\)</span>
is <span class="math">\(5\)</span>, and in general the inverse of <span class="math">\(x\)</span> is <span class="math">\(-x\)</span>.</p>
<p><span class="math">\((\mathbb{N}, +)\)</span> is not a group, because no positive elements have
inverses.</p>
<p><span class="math">\((\mathbb{Q}, +)\)</span> and <span class="math">\((\mathbb{R}, +)\)</span> are both groups, and these
groups both have the same rule for finding inverses as we saw with
<span class="math">\((\mathbb{Z}, +)\)</span>. That is, we find the inverse of an element by
multiplying by <span class="math">\(-1\)</span>.</p>
<p>The trivial monoid is also a group, and unsurprisingly we call it the <em>trivial
group</em>. To show that the trivial monoid is a group, we need to find an inverse
for every element. Because the trivial monoid only has one element, there’s
only one element which we need to find an inverse for: <span class="math">\(e\)</span>.  Similarly
there’s only one candidate for that inverse: also <span class="math">\(e\)</span>. We already know
that <span class="math">\(e * e = e\)</span> so we are good; <span class="math">\(e^{-1} = e\)</span>, and <span class="math">\(\{e\}\)</span> is
a group.</p>
<div class="section" id="uniqueness-of-inverses">
<h4>Uniqueness of inverses<a class="headerlink" href="#uniqueness-of-inverses" title="Permalink to this headline">¶</a></h4>
<p>It turns out that in any group, every element has <em>exactly one</em> inverse. We can
prove this:</p>
<p>Let <span class="math">\((G, *)\)</span> be a group, and let <span class="math">\(g \in G\)</span>. Suppose we have two
additional elements, <span class="math">\(h_1, h_2 \in G\)</span>, such that <span class="math">\(h_1\)</span> and
<span class="math">\(h_2\)</span> are both inverses of <span class="math">\(g\)</span>.</p>
<p>Then:</p>
<ol class="arabic simple">
<li><span class="math">\(h_1\)</span> is equal to <span class="math">\(h_1 * e\)</span>, since <span class="math">\(e\)</span> is the identity
element.</li>
<li><span class="math">\(h_1 * e\)</span> is in turn equal to <span class="math">\(h_1 * (g * h_2)\)</span>: since <span class="math">\(g\)</span>
and <span class="math">\(h_2\)</span> are inverses, we can replace <span class="math">\(e\)</span> with <span class="math">\(g * h_2\)</span>.</li>
<li><span class="math">\(h_1 * (g * h_2)\)</span> is equal to <span class="math">\((h_1 * g) * h_2\)</span> by the
associativity law.</li>
<li><span class="math">\((h_1 * g) * h_2\)</span> is equal to <span class="math">\(e * h_2\)</span> since <span class="math">\(g\)</span> and
<span class="math">\(h_1\)</span> are inverses.</li>
<li><span class="math">\(e * h_2\)</span> is just <span class="math">\(h_2\)</span>.</li>
</ol>
<p>So <span class="math">\(h_1 = h_2\)</span>, and therefore we have shown that any element has exactly
one inverse.</p>
<p>Because elements of a group always have exactly one inverse, we can talk about
<em>the</em> inverse of an element, as opposed to just <em>an</em> inverse of an element
(just like with identity elements of monoids). Also, we can define a notation
for the inverse of an element: if <span class="math">\(g\)</span> is some element of a group, then we
often write the inverse of <span class="math">\(g\)</span> as <span class="math">\(g^{-1}\)</span>.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This notation can be a little treacherous: it isn’t always the same as
exponentiation of numbers which you have probably seen before. It depends on
the group we’re talking about. For example, we saw that in
<span class="math">\((\mathbb{Z}, +)\)</span>, we find the inverse of an element by negating it.
So in <span class="math">\((\mathbb{Z}, +)\)</span>, we could write that <span class="math">\(4^{-1} = -4\)</span>.
Normally, however, we would expect that <span class="math">\(4^{-1}\)</span> means the same thing
as <span class="math">\(1/4\)</span>. This ambiguity can be a bit awkward, so it’s best to avoid
this notation for inverses in cases where it can be ambiguous.</p>
</div>
<p><strong>Exercise 3.2.</strong> In an arbitrary group, what is the inverse of the identity
element?</p>
<p><strong>Exercise 3.3.</strong> Let <span class="math">\(G\)</span> be a group, and let <span class="math">\(g, h \in G\)</span>. Show
that <span class="math">\(g^{-1} h^{-1} = (hg)^{-1}\)</span>.</p>
</div>
<div class="section" id="modular-arithmetic">
<h4>Modular arithmetic<a class="headerlink" href="#modular-arithmetic" title="Permalink to this headline">¶</a></h4>
<p><em>Finite</em> groups — that is, groups with a finite number of elements — are often
a little easier to deal with, so we will now talk about an example of a finite
group. Modular arithmetic is a fairly widely known concept, but we will cover
it in a slightly more rigorous way than you may have seen before; the reason I
have done this is that it will help explain other concepts further along.</p>
<p>Let <span class="math">\(x, y, m \in \mathbb{Z},\)</span> with <span class="math">\(m &gt; 0\)</span>. We say that <span class="math">\(x\)</span>
is <em>congruent to</em> <span class="math">\(y\)</span> modulo <span class="math">\(m\)</span> if and only if <span class="math">\(x - y\)</span> is a
multiple of <span class="math">\(m\)</span>. In mathematical notation:</p>
<div class="math">
\[x \equiv y \; (\mathrm{mod} \; m) \; \Leftrightarrow \; \exists a \in \mathbb{Z}.\; x - y = am\]</div>
<p>For example, we will take <span class="math">\(m = 12\)</span>. Then, <span class="math">\(15\)</span> is congruent to
<span class="math">\(3\)</span> modulo <span class="math">\(12\)</span>, because <span class="math">\(15 - 3 = 12\)</span>. Also, <span class="math">\(27\)</span> is
congruent to <span class="math">\(3\)</span> modulo <span class="math">\(12\)</span>, because <span class="math">\(27 - 3 = 24 = 2 \times
12\)</span>.</p>
<p>By contrast, <span class="math">\(2\)</span> is not congruent to <span class="math">\(1\)</span> modulo <span class="math">\(12\)</span>, because
<span class="math">\(2 - 1 = 1\)</span> and <span class="math">\(1\)</span> is not an integer multiple of <span class="math">\(12\)</span>.</p>
<p>Note that any integer is congruent to itself modulo <span class="math">\(12\)</span>, because we say
that <span class="math">\(0\)</span> counts as an integer multiple of <span class="math">\(12\)</span>; we can take
<span class="math">\(a = 0\)</span> in the definition above and we see that <span class="math">\(0 \times 12 = 0\)</span>.</p>
<p>Now, we ask: given some integer <span class="math">\(x \in \mathbb{Z}\)</span>, and a modulus
<span class="math">\(m \in \mathbb{Z}, m &gt; 0\)</span>, can we find the entire set of integers which
are congruent to <span class="math">\(x\)</span> modulo <span class="math">\(m\)</span>? For example, can we find the
entire set of integers congruent to <span class="math">\(0\)</span> modulo <span class="math">\(12\)</span>?</p>
<p>Before we continue, we will introduce a new notation to describe sets like
this. It is called <em>set-builder notation,</em> and it looks like this:</p>
<div class="math">
\[\{\, y \in \mathbb{Z} \,|\, x \equiv y \; (\mathrm{mod} \; m) \,\}\]</div>
<p>Read: “the set of <span class="math">\(y\)</span> in <span class="math">\(\mathbb{Z}\)</span> such that <span class="math">\(x\)</span> is
congruent to <span class="math">\(y\)</span> modulo <span class="math">\(m\)</span>“.</p>
<p>We will define <span class="math">\(\overline{x}\)</span> to be this set; that is:</p>
<div class="math">
\[\overline{x} = \{\, y \in \mathbb{Z} \,|\, x \equiv y \; (\mathrm{mod} \; m) \,\}\]</div>
<p>The set <span class="math">\(\overline{x}\)</span> is called the <em>congruence class</em> of <span class="math">\(x\)</span>.</p>
<p>In particular, when <span class="math">\(m = 12\)</span>, we have seen that <span class="math">\(15 \in
\overline{3}\)</span>, and <span class="math">\(27 \in \overline{3}\)</span>, but <span class="math">\(2 \notin
\overline{1}\)</span>. It turns out that in this case, <span class="math">\(\overline{15}\)</span> is
actually the exact same set as <span class="math">\(\overline{3}\)</span>, and again the exact same
set as <span class="math">\(\overline{27}\)</span>.</p>
<p>In fact, for any <span class="math">\(x \in \mathbb{Z}\)</span>, we have that <span class="math">\(\overline{x} =
\overline{x + m}\)</span>. To prove that two sets <span class="math">\(U\)</span> and <span class="math">\(V\)</span> are the same,
we first need to show that every element of <span class="math">\(U\)</span> is an element of
<span class="math">\(V\)</span>, and then we show that every element of <span class="math">\(V\)</span> is also an element
of <span class="math">\(U\)</span>.  It’s not enough to just do one of these steps; we need to do
both, because <span class="math">\(U\)</span> might be a subset of <span class="math">\(V\)</span> or vice versa, and both
steps are required to rule this out.</p>
<p>Therefore, we first prove that every element of <span class="math">\(\overline{x}\)</span> is also an
element of <span class="math">\(\overline{x + m}\)</span>. Let <span class="math">\(x, y \in \mathbb{Z}\)</span>, with
<span class="math">\(y \in \overline{x}\)</span>. Then, there exists an <span class="math">\(a \in \mathbb{Z}\)</span> such
that <span class="math">\(x - y = am\)</span>. Then, adding <span class="math">\(m\)</span> to both sides, we have:</p>
<div class="math">
\[ \begin{align}\begin{aligned}x + m - y = am + m\\(x + m) - y = (a + 1)m\end{aligned}\end{align} \]</div>
<p>That is, <span class="math">\(x + m \equiv y \; (\mathrm{mod} \; m)\)</span> and <span class="math">\(y \in
\overline{x + m}\)</span>. So if <span class="math">\(y \in \overline{x}\)</span>, then we also have that
<span class="math">\(y \in \overline{x + m}\)</span>. The second part of the proof, that is, showing
that every element of <span class="math">\(\overline{x + m}\)</span> is also an element of
<span class="math">\(\overline{x}\)</span>, is very similar: the main difference is that we subtract
<span class="math">\(m\)</span> from both sides instead of adding.</p>
<p>The important thing to take from all this is that there are exactly <span class="math">\(m\)</span>
such congruence classes.  We will define a set <span class="math">\(\mathbb{Z}_m\)</span> containing
all of these, which we can write as <span class="math">\(\overline{0}\)</span> up to
<span class="math">\(\overline{m-1}\)</span>:</p>
<div class="math">
\[\mathbb{Z}_{12} = \{ \overline{0}, \overline{1}, ... , \overline{10}, \overline{11} \}\]</div>
<p>Then, for each <span class="math">\(m \in \mathbb{Z}, m &gt; 0\)</span>, every <span class="math">\(x \in \mathbb{Z}\)</span>
is contained in exactly one element of <span class="math">\(\mathbb{Z}_{m}\)</span>. I omit a proof
of this, but it follows as a consequence of congruence modulo <span class="math">\(m\)</span> being a
particular kind of relation called an <em>equivalence relation.</em> I might expand on
equivalence relations in a future version of this guide.</p>
<p>We can define an addition operation on this set, too:</p>
<div class="math">
\[\overline{x} + \overline{y} = \overline{x + y}\]</div>
<p>For example, in <span class="math">\(\mathbb{Z}_{12}\)</span>, we have that <span class="math">\(\overline{8} +
\overline{9} = \overline{8 + 9} = \overline{17} = \overline{5}\)</span>.</p>
<p>It turns out that this addition operation satisfies all of the group axioms, so
we have a finite group. In particular, <span class="math">\(\overline{0}\)</span> is the identity
element. Again, I won’t prove this right now for the sake of expediency,
although I might put a proof in an appendix later.</p>
<p><strong>Exercise 3.4.a.</strong> Which element of <span class="math">\(\mathbb{Z}_{12}\)</span> solves the
equation <span class="math">\(\overline{3} + \overline{x} = \overline{2}\)</span>?</p>
<p><strong>Exercise 3.4.b.</strong> What is the additive inverse of <span class="math">\(\overline{5}\)</span> in
<span class="math">\(\mathbb{Z}_{12}\)</span>? That is, which element of <span class="math">\(\mathbb{Z}_{12}\)</span>
solves the equation <span class="math">\(\overline{5} + \overline{x} = \overline{0}\)</span>?</p>
</div>
<div class="section" id="permutations">
<span id="injectivity-and-surjectivity"></span><h4>Permutations<a class="headerlink" href="#permutations" title="Permalink to this headline">¶</a></h4>
<p>We now consider another example of a finite group which arises from the monoid
<span class="math">\((\mathrm{Maps}(X, X), \circ)\)</span>, which we saw in the previous chapter.</p>
<p>Firstly, a very brief interlude on functions and terminology: a <em>function</em>
sends elements in one set to elements of some other set. If a function
<span class="math">\(f\)</span> sends elements of the set <span class="math">\(X\)</span> to elements of the set <span class="math">\(Y\)</span>,
we indicate this using mathematical notation by writing <span class="math">\(f : X
\rightarrow Y\)</span>, or equivalently, <span class="math">\(f \in \mathrm{Maps}(X, Y)\)</span>. We call the
set <span class="math">\(X\)</span>, from which <span class="math">\(f\)</span> takes its argument, the <em>domain;</em> we call
the set <span class="math">\(Y\)</span>, to which <span class="math">\(f\)</span> sends those elements, the <em>codomain</em>.</p>
<p>The first thing to notice is that not all elements of <span class="math">\(\mathrm{Maps}(X,
X)\)</span> are <em>invertible;</em> that is, given some <span class="math">\(f \in \mathrm{Maps}(X, X)\)</span>, we
can’t always find a <span class="math">\(g \in \mathrm{Maps}(X, X)\)</span> such that <span class="math">\(f \circ
g = g \circ f = e\)</span>. For example, suppose that we take <span class="math">\(X = \{A, B\}\)</span> as
before. We defined a function <span class="math">\(f_A\)</span> in the previous chapter which sends
both <span class="math">\(A\)</span> and <span class="math">\(B\)</span> to <span class="math">\(A\)</span>. To invert <span class="math">\(f_A\)</span>, we need to
come up with a rule, so that if we are given any element <span class="math">\(y \in Y\)</span>, we
can find the unique element <span class="math">\(x \in X\)</span> satisfying <span class="math">\(f_A(x) = y\)</span>. That
is, given the result of applying <span class="math">\(f_A\)</span> to something, we have to be able
to find that thing.</p>
<p>But this is impossible! Suppose we are told that the result of applying
<span class="math">\(f_A\)</span> to something was <span class="math">\(A\)</span>. Well, <span class="math">\(f_A\)</span> always produces
<span class="math">\(A\)</span>, regardless of what you put in, so we can’t know what the original
thing was; it could just as well have been <span class="math">\(A\)</span> or <span class="math">\(B\)</span> as far as we
know.</p>
<p>Alternatively, suppose we are told that the result of applying <span class="math">\(f_A\)</span> to
something was <span class="math">\(B\)</span>. But <span class="math">\(f_A\)</span> never produces <span class="math">\(B\)</span> as its
result, so we certainly can’t find some other element <span class="math">\(x\)</span> such that
<span class="math">\(f_A(x) = B\)</span>.</p>
<p>So <span class="math">\(f_A\)</span> is not invertible, and similarly, neither is <span class="math">\(f_B\)</span> (recall
that <span class="math">\(f_B\)</span> was defined similarly to <span class="math">\(f_A\)</span>, except that the result
is always <span class="math">\(B\)</span> rather than <span class="math">\(A\)</span>).</p>
<p>However, <span class="math">\(f_{swap}\)</span> is invertible, and its inverse is <span class="math">\(f_{swap}\)</span>
(itself).</p>
<p>We have a few ways of classifying functions which we need to talk about briefly
before continuing. Specifically, we need to clarify what it means for a
function to be invertible.</p>
<div class="section" id="injectivity">
<h5>Injectivity<a class="headerlink" href="#injectivity" title="Permalink to this headline">¶</a></h5>
<p>Firstly, as we saw with <span class="math">\(f_A\)</span>, we can’t invert a function if it sends two
different things to the same thing. Another example: the function <span class="math">\(f :
\mathbb{R} \rightarrow \mathbb{R}\)</span> given by <span class="math">\(f (x) = x^2\)</span> sends both of
<span class="math">\(2\)</span> and <span class="math">\(-2\)</span> to <span class="math">\(4\)</span>, so it is not invertible.</p>
<p>Functions which don’t suffer from this problem are called <em>injective.</em> We say
that a function <span class="math">\(f : X \rightarrow Y\)</span> is <em>injective</em> if and only if</p>
<div class="math">
\[\forall x_1, x_2 \in X.\; x_1 \neq x_2 \Rightarrow f(x_1) \neq f(x_2)\]</div>
<p>The identity function <span class="math">\(f(x) = x\)</span> is injective, as is the function
<span class="math">\(f(x) = x^3\)</span>. For functions from <span class="math">\(\mathbb{R}\)</span> to
<span class="math">\(\mathbb{R}\)</span>, a good way of thinking about injectivity is that a function
<span class="math">\(f\)</span> is injective if and only if any horizontal line drawn on a graph will
only intersect with the curve <span class="math">\(y = f(x)\)</span> <em>at most once</em> — that is, either
exactly once or not at all.</p>
</div>
<div class="section" id="surjectivity">
<h5>Surjectivity<a class="headerlink" href="#surjectivity" title="Permalink to this headline">¶</a></h5>
<p>Another problem that we saw with <span class="math">\(f_A\)</span> is that we can’t invert a function
if there is some element in the codomain which isn’t ‘hit’ by the function.
That is, if there’s no element <span class="math">\(y\)</span> in the codomain such that <span class="math">\(f(x)
= y\)</span> for some <span class="math">\(x\)</span> in the domain, we can’t invert it, because we don’t
have anything to send <span class="math">\(y\)</span> to. The function <span class="math">\(f : \mathbb{R}
\rightarrow \mathbb{R}\)</span> defined by <span class="math">\(f(x) = x^2\)</span> also suffers from this
problem: there’s no real number <span class="math">\(x\)</span> such that <span class="math">\(x^2 = -1\)</span>, for
example.</p>
<p>We call functions that don’t suffer from this problem <em>surjective</em>. We say that
a function <span class="math">\(f : X \rightarrow Y\)</span> is <em>surjective</em> if and only if</p>
<div class="math">
\[\forall y \in Y.\; \exists x \in X.\; f(x) = y\]</div>
<p>The functions <span class="math">\(f(x) = x\)</span> and <span class="math">\(f(x) = x^3\)</span> are surjective in
addition to being injective. Using a similar idea to the one we had with
injectivity, a function <span class="math">\(f : \mathbb{R} \rightarrow \mathbb{R}\)</span> is
surjective if and only if any horizontal line drawn on a graph will intersect
with the curve <span class="math">\(y = f(x)\)</span> <em>at least once.</em></p>
</div>
<div class="section" id="bijectivity">
<h5>Bijectivity<a class="headerlink" href="#bijectivity" title="Permalink to this headline">¶</a></h5>
<p>We are now ready to say what an invertible function is: a function is
invertible if it is both injective and surjective. Functions which are both
injective and surjective are also called <em>bijective</em>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You might ask what the point is of having two words, <em>bijective</em> and
<em>invertible</em>, which mean the same thing. It might just be a historical
accident. There is a subtle difference between these words though: the word
‘invertible’ is quite general, as it can refer to many different kinds of
objects; by contrast, ‘bijective’ almost always refers to functions.</p>
</div>
<p>If a function <span class="math">\(f : X \rightarrow Y\)</span> is bijective, then it has an
<em>inverse,</em> which we usually write as <span class="math">\(f^{-1} : Y \rightarrow X\)</span>. For the
inverse of <span class="math">\(f\)</span>, we have that <span class="math">\(f^{-1}(f(x)) = x\)</span> for all <span class="math">\(x
\in X\)</span>, and additionally <span class="math">\(f(f^{-1}(y)) = y\)</span> for all <span class="math">\(y \in Y\)</span>. In
essence, <span class="math">\(f^{-1}\)</span> undoes the effect of <span class="math">\(f\)</span>, putting us back to
where we started.</p>
<p>Going back to the example from the last chapter, <span class="math">\(e\)</span> and <span class="math">\(f_{swap}\)</span>
are both injective and surjective and thus bijective, while <span class="math">\(f_A\)</span> and
<span class="math">\(f_B\)</span> fail to be either injective or surjective.</p>
</div>
<div class="section" id="the-symmetric-group">
<h5>The symmetric group<a class="headerlink" href="#the-symmetric-group" title="Permalink to this headline">¶</a></h5>
<p>If <span class="math">\(X\)</span> is some finite set, and we want to make a group out of
<span class="math">\((\mathrm{Maps}(X, X), \circ)\)</span>, all we need to do is discard the elements
of <span class="math">\(\mathrm{Maps}(X, X)\)</span> which fail to be bijective.</p>
<p>Because the actual set <span class="math">\(X\)</span> we choose doesn’t really matter in the context
of group theory, it is conventional to use integers from <span class="math">\(1\)</span> up to
<span class="math">\(n\)</span>; that is, we take <span class="math">\(X = \{ 1, 2, ... , n \}\)</span>. Clearly, then,
this set has <span class="math">\(n\)</span> elements.</p>
<p>The group of permutations on this set is very important, so it has a name: it
is called the <em>symmetric group of degree</em> <span class="math">\(n\)</span>. We denote this group by
<span class="math">\(S_n\)</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Be careful not to confuse the set <span class="math">\(\{ 1, 2, ... , n\}\)</span> with the group
of permutations on that set, <span class="math">\(S_n\)</span>. Remember that the elements of
<span class="math">\(S_n\)</span> are <em>functions</em>, not numbers.</p>
</div>
<p><strong>Exercise 3.5.</strong> If <span class="math">\(n\)</span> is a positive integer, the product of all
positive integers less than or equal to <span class="math">\(n\)</span> is called <span class="math">\(n\)</span>
factorial, written <span class="math">\(n!\)</span>. Show that <span class="math">\(S_n\)</span> has <span class="math">\(n!\)</span> elements.</p>
<p>As for checking the group laws for <span class="math">\(S_n\)</span>: we have already shown that
<span class="math">\((\mathrm{Maps}(X, X), \circ)\)</span> is a monoid, which means that we
get associativity “for free”, since we’re using the same operation as before.
The identity function is bijective, which means we don’t discard it and we can
use it for the identity element in our group, and so the identity law is
satisfied too. Also, we know that bijective functions have inverses, so the
inverses law is satisfied. The only thing left to check is closure; that is, we
need to check that the composite of two bijective functions is itself
bijective. This is true, although I will not prove it here. I encourage you to
look for a proof elsewhere on the web if you’re itching to see one.</p>
</div>
</div>
<div class="section" id="cancellation">
<h4>Cancellation<a class="headerlink" href="#cancellation" title="Permalink to this headline">¶</a></h4>
<p>Now that we have seen a few more examples of groups, we go back to our original
problem, except this time, we assume that we have a group, not just a monoid.
That is, we let <span class="math">\((G, *)\)</span> be some group, and let <span class="math">\(a, b \in G\)</span>. We
want to know if there is a solution to the equation</p>
<div class="math">
\[a * x = b\]</div>
<p>Because it’s an equation, we can do the same thing to both sides, so we will
combine both sides with <span class="math">\(a^{-1}\)</span> on the left, like this:</p>
<div class="math">
\[a^{-1} * a * x = a^{-1} * b\]</div>
<p>We can now cancel:</p>
<div class="math">
\[x = a^{-1} * b\]</div>
<p>And we have solved for <span class="math">\(x\)</span>. So, if we are dealing with a group, then an
equation of the form <span class="math">\(a * x = b\)</span> always has exactly one solution.
<em>Cancellation</em> — the ability to move elements to the other side of equations
like this — is arguably a defining property of groups.</p>
</div>
<div class="section" id="abelian-groups">
<h4>Abelian groups<a class="headerlink" href="#abelian-groups" title="Permalink to this headline">¶</a></h4>
<p>Before moving on we just need to talk about one more specific kind of group.</p>
<p>We say that a group is an <em>Abelian group,</em> or a <em>commutative group,</em> if it
satisfies the following additional law:</p>
<ul class="simple">
<li><em>Commutativity.</em> <span class="math">\(\forall g, h \in G.\; g*h = h*g\)</span>.</li>
</ul>
<p>Almost all of the groups we have seen so far have been Abelian; in particular,
you were probably already aware that <span class="math">\(x + y = y + x\)</span> for all <span class="math">\(x, y
\in \mathbb{R}\)</span>.</p>
<p>The only non-Abelian groups we have seen so far are the symmetric groups: the
symmetric group of degree <span class="math">\(n\)</span> is non-Abelian whenever <span class="math">\(n \geq 3\)</span>.</p>
<p>It is possible to prove, although we will not do so here, that any non-Abelian
group must have at least <span class="math">\(6\)</span> elements. In fact, the symmetric group of
degree <span class="math">\(3\)</span>, that is <span class="math">\(S_3\)</span>, is the smallest possible non-Abelian
group, with exactly <span class="math">\(6\)</span> elements.</p>
</div>
<div class="section" id="a-final-note-on-groups">
<h4>A final note on groups<a class="headerlink" href="#a-final-note-on-groups" title="Permalink to this headline">¶</a></h4>
<p>Groups might seem like a simple concept but they give rise to an astonishing
amount of rather lovely mathematics. I don’t want to dwell on them too much
here, because we want to get on to rings and fields and things, but I recommend
studying them in more depth if you get the chance.</p>
<p>In my experience, it’s fairly uncommon to want a Group type class in PureScript
code, but if you do ever happen to want one, it’s in the <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-group">purescript-group
library</a>.</p>
</div>
</div>
<span id="document-rings"></span><div class="section" id="rings">
<h3>Rings<a class="headerlink" href="#rings" title="Permalink to this headline">¶</a></h3>
<p>Congratulations on getting this far — we are finally ready to introduce rings!</p>
<p>I will begin by reminding you of some properties that the real numbers have.</p>
<p>Firstly, <span class="math">\((\mathbb{R}, +)\)</span> is an Abelian group, where the identity
element is <span class="math">\(0\)</span>.</p>
<p>Secondly, <span class="math">\((\mathbb{R}, \times)\)</span> — that is, the set <span class="math">\(\mathbb{R}\)</span>
together with multiplication — is a monoid, where the identity element is
<span class="math">\(1\)</span>.</p>
<p>Thirdly, multiplication <em>distributes over</em> addition. What this means is that
for all <span class="math">\(x, y, z \in \mathbb{R},\)</span></p>
<div class="math">
\[ \begin{align}\begin{aligned}x(y + z) = xy + xz\\(x + y)z = xz + yz.\end{aligned}\end{align} \]</div>
<p>Now we will consider a different set: the set of truth-values <span class="math">\(\{T, F\}\)</span>,
which from now on I will call <span class="math">\(\mathrm{Bool}\)</span>. I will first introduce a
new operation on <span class="math">\(\mathrm{Bool}\)</span> called <em>exclusive-or</em> or <em>XOR</em> for
short, written <span class="math">\(\oplus\)</span>:</p>
<table border="1" class="docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math">\(P\)</span></th>
<th class="head"><span class="math">\(Q\)</span></th>
<th class="head"><span class="math">\(P \oplus Q\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>T</td>
<td>T</td>
<td>F</td>
</tr>
<tr class="row-odd"><td>T</td>
<td>F</td>
<td>T</td>
</tr>
<tr class="row-even"><td>F</td>
<td>T</td>
<td>T</td>
</tr>
<tr class="row-odd"><td>F</td>
<td>F</td>
<td>F</td>
</tr>
</tbody>
</table>
<p>An easy way to remember this is that <span class="math">\(P \oplus Q\)</span> is true if and only if
<span class="math">\(P\)</span> is different from <span class="math">\(Q\)</span>.</p>
<p>Firstly, <span class="math">\((\mathrm{Bool}, \oplus)\)</span> is an Abelian group, with identity
<span class="math">\(F\)</span> (check this yourself if you want to).</p>
<p>Secondly, <span class="math">\((\mathrm{Bool}, \land)\)</span> is a monoid, with identity <span class="math">\(T\)</span>
(we saw this monoid earlier on, in the monoids chapter).</p>
<p>Thirdly, <span class="math">\(\land\)</span> distributes over <span class="math">\(\oplus\)</span>; that is, for all
<span class="math">\(P, Q, R \in \mathrm{Bool},\)</span></p>
<div class="math">
\[ \begin{align}\begin{aligned}P \land (Q \oplus R) = (P \land Q) \oplus (P \land R)\\(P \oplus Q) \land R = (P \land R) \oplus (Q \land R)\end{aligned}\end{align} \]</div>
<p>I also encourage you to check this for yourself. Note that there are eight
possibilities to consider, since we need to check that this works for any
choice of <span class="math">\(P, Q,\)</span> and <span class="math">\(R\)</span>.</p>
<p>The last example I will talk about before giving you the definition of a ring
is <span class="math">\(\mathbb{Z}_3\)</span>, the set of integers modulo <span class="math">\(3\)</span>, which we saw in
the previous chapter. Recall that <span class="math">\(\mathbb{Z}_3\)</span> has three elements:</p>
<div class="math">
\[\mathbb{Z}_3 = \{\overline{0}, \overline{1}, \overline{2}\}\]</div>
<p>We saw in the previous chapter how to define an addition operation on
<span class="math">\(\mathbb{Z}_3\)</span> so that <span class="math">\((\mathbb{Z}_3, +)\)</span> is an Abelian group,
with identity <span class="math">\(\overline{0}\)</span>.</p>
<p>I will now reveal that we can define a multiplication operation in
<span class="math">\(\mathbb{Z}_3\)</span>, which I will write as <span class="math">\(\cdot\)</span>, like this:</p>
<div class="math">
\[\overline{x} \cdot \overline{y} = \overline{xy}\]</div>
<p>For example, <span class="math">\(\overline{1} \cdot \overline{2} = \overline{1 \times 2} =
\overline{2}\)</span>, and <span class="math">\(\overline{2} \cdot \overline{2} = \overline{2 \times
2} = \overline{4} = \overline{1}\)</span>.</p>
<p>This makes <span class="math">\((\mathbb{Z}_3, \cdot)\)</span> into a monoid, with identity
<span class="math">\(\overline{1}\)</span>.</p>
<p>Finally, multiplication distributes over addition in <span class="math">\(\mathbb{Z}_3\)</span> too;
we sort of get this “for free” since we have defined multiplication and
addition in terms of normal multiplication and addition in <span class="math">\(\mathbb{Z}\)</span>.</p>
<p>Putting all this together, we see that <span class="math">\(\mathbb{Z}_3\)</span> is a ring. In fact,
<span class="math">\(\mathbb{Z}_m\)</span> is a ring for any positive integer <span class="math">\(m\)</span>, with
multiplication defined in exactly the same way. So for example, in
<span class="math">\(\mathbb{Z}_{12}\)</span>, we have <span class="math">\(\overline{5} \cdot \overline{6}
= \overline{30} = \overline{6}\)</span>.</p>
<div class="section" id="the-definition">
<h4>The definition<a class="headerlink" href="#the-definition" title="Permalink to this headline">¶</a></h4>
<p>Now that you have seen some examples, I will give you the definition of a ring.
A <em>ring</em> is a set <span class="math">\(R\)</span> equipped with two binary operations <span class="math">\(+\)</span> and
<span class="math">\(\cdot\)</span>, called “addition” and “multiplication” respectively, such that
the three following laws hold:</p>
<ol class="arabic simple">
<li><span class="math">\((R, +)\)</span> is an Abelian group.</li>
<li><span class="math">\((R, \cdot)\)</span> is a monoid.</li>
<li>Multiplication distributes over addition. That is, for all <span class="math">\(x, y, z
\in R,\)</span></li>
</ol>
<div class="math">
\[ \begin{align}\begin{aligned}x \cdot (y + z) = x \cdot y + x \cdot z\\(x + y) \cdot z = x \cdot z + y \cdot z.\end{aligned}\end{align} \]</div>
<p>From now on I will generally omit the <span class="math">\(\cdot\)</span> symbol and represent
multiplication by writing two symbols next to each other; that is, I will write
<span class="math">\(xy\)</span> to mean <span class="math">\(x \cdot y\)</span>.</p>
<p>We call the the identity element of the group <span class="math">\((R, +)\)</span> the <em>additive
identity</em> of the ring <span class="math">\(R\)</span>. The additive identity is written as
<span class="math">\(0_R\)</span> or just <span class="math">\(0\)</span> when it’s clear from context which ring <span class="math">\(R\)</span>
we are talking about. Similarly, we call the identity element of the monoid
<span class="math">\((R, \cdot)\)</span> the <em>multiplicative identity</em> of the ring <span class="math">\(R\)</span>. The
multiplicative identity is written as <span class="math">\(1_R\)</span> or simply <span class="math">\(1\)</span> when it’s
clear which ring we are using.</p>
<p>Since <span class="math">\(R\)</span> forms a group under addition, every element <span class="math">\(x \in R\)</span> has
an additive inverse, which we will write <span class="math">\(-x\)</span>. We also write <span class="math">\(x -
y\)</span> as a shorthand for <span class="math">\(x + (-y)\)</span>.</p>
<p>An important thing to note is that in a ring, multiplication need not be
commutative! A ring in which the multiplication operation is commutative is
called a <em>commutative ring.</em> So far, all the rings we have seen have
commutative, but we will soon see some examples of non-commutative rings.</p>
<p>One last thing that I should mention quickly: just as there is a trivial monoid
and a trivial group, there is a trivial ring with just one element, usually
written <span class="math">\(\{0\}\)</span>. This ring is called the <strong>zero ring</strong>. It is not very
interesting so we often rule it out by saying we a dealing with a “non-zero
ring”; this phrase is nothing more than a shorthand for “any ring but the zero
ring”.</p>
</div>
<div class="section" id="properties-of-rings">
<h4>Properties of rings<a class="headerlink" href="#properties-of-rings" title="Permalink to this headline">¶</a></h4>
<p>So I have just shown you three examples of rings: <span class="math">\(\mathbb{R}\)</span>,
<span class="math">\(\mathrm{Bool}\)</span>, and <span class="math">\(\mathbb{Z}_m\)</span>. I will introduce a few more
exotic examples of rings in subsequent chapters, but for now, we will establish
a few properties which all rings have.</p>
<p>The first property is that <span class="math">\(\forall x \in R.\; 0x = 0\)</span>. That is,
multiplying anything by <span class="math">\(0\)</span> yields <span class="math">\(0\)</span>. We will prove this using
just the ring laws, so that we know it is true for any ring.</p>
<p>Let <span class="math">\(R\)</span> be a ring, and let <span class="math">\(x \in R\)</span>. Then:</p>
<ol class="arabic simple">
<li>We know that <span class="math">\(0x = (0 + 0)x\)</span>, since <span class="math">\(0\)</span> is the additive
identity, and so anything is equal to itself plus <span class="math">\(0\)</span>.</li>
<li>By the distributive law, <span class="math">\((0 + 0)x = 0x + 0x\)</span>.</li>
<li>We now have that <span class="math">\(0x = 0x + 0x\)</span>. Because we know that <span class="math">\(R\)</span> is a
group under addition, we can subtract <span class="math">\(0x\)</span> from both sides, yielding
<span class="math">\(0 = 0x\)</span>, as required.</li>
</ol>
<p>Another property which holds for all rings <span class="math">\(R\)</span> is that <span class="math">\(\forall x,
y \in R.\; (-x)y = -(xy)\)</span>. We can prove this too:</p>
<ol class="arabic simple">
<li>By distributivity, we know that <span class="math">\(xy + (-x)y = (x + (-x))y.\)</span></li>
<li>Since <span class="math">\(-x\)</span> is the additive inverse of <span class="math">\(x\)</span>, we know that
<span class="math">\((x + (-x))y = 0y.\)</span></li>
<li>We proved a moment ago that <span class="math">\(\, 0y = 0.\)</span></li>
<li>So <span class="math">\(\, xy + (-x)y = 0; \,\)</span> subtracting <span class="math">\(xy\)</span> from both sides yields
<span class="math">\((-x)y = -(xy)\)</span>, as required.</li>
</ol>
<p><strong>Exercise 4.1.</strong> Let <span class="math">\(R\)</span> be a ring. Prove that <span class="math">\((-x)(-y) = xy\)</span> for
all <span class="math">\(x, y \in R\)</span>. Maybe you will find this a satisfying explanation of
why “a minus times a minus is a plus”!</p>
</div>
<div class="section" id="semirings">
<h4>Semirings<a class="headerlink" href="#semirings" title="Permalink to this headline">¶</a></h4>
<p>We might want to come up with a slightly weaker structure than a ring, in which
we only require that <span class="math">\((R, +)\)</span> is a commutative monoid rather than a
group. Unfortunately, though, if we do this, our proof that anything times
<span class="math">\(0\)</span> is <span class="math">\(0\)</span> will no longer work, because in the proof we used the
fact that any ring forms a group under its addition operation.</p>
<p>Having multiplication by <span class="math">\(0\)</span> always produce <span class="math">\(0\)</span> is a useful
property, though, so to make sure it still holds, we add it as an extra law. We
then obtain the following:</p>
<p>A <em>semiring</em> is a set <span class="math">\(R\)</span> equipped with two binary operations <span class="math">\(+\)</span>
and <span class="math">\(\cdot\)</span>, called “addition” and “multiplication” respectively, such
that the three following laws hold:</p>
<ol class="arabic simple">
<li><span class="math">\((R, +)\)</span> is a commutative monoid.</li>
<li><span class="math">\((R, \cdot)\)</span> is a monoid.</li>
<li>Multiplication distributes over addition. That is, for all <span class="math">\(x, y, z
\in R,\)</span></li>
</ol>
<div class="math">
\[ \begin{align}\begin{aligned}x \cdot (y + z) = x \cdot y + x \cdot z\\(x + y) \cdot z = x \cdot z + y \cdot z.\end{aligned}\end{align} \]</div>
<ol class="arabic simple" start="4">
<li>Anything multiplied by <span class="math">\(0\)</span> is <span class="math">\(0\)</span>.</li>
</ol>
<p>I won’t spend too much time talking about semirings in this guide, as most of
the number systems you’re likely to be dealing with as a programmer have more
structure. I’ll just give a couple of examples before we move on:</p>
<p>The natural example of a semiring is the natural numbers <span class="math">\(\mathbb{N}\)</span>;
recall that <span class="math">\((\mathbb{N}, +)\)</span> is a commutative monoid but not a group.
Therefore, <span class="math">\(\mathbb{N}\)</span> is a semiring but not a ring.</p>
<p>The simplest semiring which is not a ring is called the <em>Boolean semiring</em>. It
has just two elements, <span class="math">\(0\)</span> and <span class="math">\(1\)</span>, and it is defined by the
equation <span class="math">\(1 + 1 = 1\)</span>. Note that we don’t need to specify the results of
adding or multiplying any other elements, because the semiring laws already
tell us what they will be. The Boolean semiring is different from the ring
<span class="math">\(\mathrm{Bool}\)</span> above; recall that in <span class="math">\(\mathrm{Bool}\)</span>, we have
<span class="math">\(1 + 1 = 0\)</span>.</p>
</div>
</div>
<span id="document-matrices"></span><div class="section" id="matrices">
<h3>Matrices<a class="headerlink" href="#matrices" title="Permalink to this headline">¶</a></h3>
<p>Matrices are a source of many important examples of rings and fields, so we’re
going to get a bit more concrete in this chapter and talk about matrices for a
bit. You may already be aware that matrices have many applications in
computing; two examples that spring to my mind are computer graphics and
machine learning.</p>
<div class="section" id="vectors">
<h4>Vectors<a class="headerlink" href="#vectors" title="Permalink to this headline">¶</a></h4>
<p>We begin by talking about <em>vectors</em> in <span class="math">\(\mathbb{R}^n\)</span>; if you haven’t
seen this before, an element of <span class="math">\(\mathbb{R}^n\)</span> is an ordered collection
of <span class="math">\(n\)</span> elements of <span class="math">\(\mathbb{R}\)</span>. We usually write vectors in a
column, and it’s also conventional to use bold symbols for vectors (to help
distinguish them from <em>scalars</em>, which are elements of <span class="math">\(\mathbb{R}\)</span>). For
example:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\begin{split}\boldsymbol{x} = \begin{bmatrix}1\\0\end{bmatrix}\end{split}\\\begin{split}\boldsymbol{y} = \begin{bmatrix}4\\-2\end{bmatrix}\end{split}\\\boldsymbol{x}, \boldsymbol{y} \in \mathbb{R}^2\end{aligned}\end{align} \]</div>
<p>Sometimes it’s helpful to be able to write vectors on one line, and we do so by
listing the components in parentheses, separated by commas. For example,
<span class="math">\(\boldsymbol{x} = (1, 0)\)</span>.</p>
<p>We define addition for <span class="math">\(\mathbb{R}^n\)</span> by adding corresponding components:</p>
<div class="math">
\[\begin{split}\boldsymbol{x} + \boldsymbol{y}
  &amp;= \begin{bmatrix}1\\0\end{bmatrix} + \begin{bmatrix}4\\-2\end{bmatrix} \\
  &amp;= \begin{bmatrix}1+4\\0+(-2)\end{bmatrix} \\
  &amp;= \begin{bmatrix}5\\-2\end{bmatrix}\end{split}\]</div>
<p>The identity element of vector addition is the <em>zero vector;</em> the vector which
has a zero for every component. This is quite an important vector so we have a
short-hand notation for it, which is a bold zero:</p>
<div class="math">
\[\begin{split}\boldsymbol{0} = \begin{bmatrix}0\\0\end{bmatrix}\end{split}\]</div>
<p>We can also multiply every component of a vector by some fixed number. This
operation is called <em>scalar multiplication:</em></p>
<div class="math">
\[\begin{split}3\boldsymbol{x} &amp;= \begin{bmatrix}3 \times 1\\3 \times 0\end{bmatrix} \\
                &amp;= \begin{bmatrix}3\\0\end{bmatrix}\end{split}\]</div>
<p><strong>Exercise 5.1.</strong> We have seen that <span class="math">\(\mathbb{R}^2\)</span> is closed under vector
addition (that is, adding two vectors always gives you another vector), and
also that there is an identity element for vector addition in
<span class="math">\(\mathbb{R}^2\)</span>. Now, show that <span class="math">\((\mathbb{R}^2, +)\)</span> is a monoid
by checking the remaining monoid law (associativity).</p>
<p><strong>Exercise 5.2.</strong> Show that <span class="math">\((\mathbb{R}^2, +)\)</span> is a group by explaining
how to find the inverse of an element.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><span class="math">\((\mathbb{R}^n, +)\)</span> is actually a group for any <span class="math">\(n\)</span>, not
just <span class="math">\(n = 2\)</span>. We will spend the majority of this chapter working
with <span class="math">\(\mathbb{R}^2\)</span>, but everything we’re doing generalises very
naturally to larger choices of <span class="math">\(n\)</span>.</p>
</div>
<p><strong>Exercise 5.3.</strong> Show that scalar multiplication distributes over vector
addition in <span class="math">\(\mathbb{R}^2\)</span>; that is, <span class="math">\(\forall \boldsymbol{x},
\boldsymbol{y} \in \mathbb{R}^2, k \in \mathbb{R}.\; k(\boldsymbol{x} +
\boldsymbol{y}) = k\boldsymbol{x} + k\boldsymbol{y}\)</span>.</p>
<p>There is one more vector operation we need, called the <em>dot product</em>. It
takes two vectors in <span class="math">\(\mathbb{R}^n\)</span> and produces as a result a single
element of <span class="math">\(\mathbb{R}\)</span>, by multiplying corresponding components together
and then adding all of the results:</p>
<div class="math">
\[\begin{split}\boldsymbol{x} \cdot \boldsymbol{y}
  &amp;= \begin{bmatrix}1\\0\end{bmatrix} \cdot \begin{bmatrix}4\\-2\end{bmatrix} \\
  &amp;= (1 \times 4) + (0 \times -2) \\
  &amp;= 4 + 0 \\
  &amp;= 4\end{split}\]</div>
<p>The dot product is sometimes also called the <em>scalar product</em> because the
result is a scalar.</p>
<p>The dot product interacts nicely with the other two vector operations; the
following are true for any vectors <span class="math">\(\boldsymbol{x}, \boldsymbol{y},
\boldsymbol{z} \in \mathbb{R}^2\)</span> and scalars <span class="math">\(k_1, k_2 \in \mathbb{R}\)</span>:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\boldsymbol{x} \cdot (\boldsymbol{y} + \boldsymbol{z}) =
  \boldsymbol{x} \cdot \boldsymbol{y} + \boldsymbol{x} \cdot \boldsymbol{z}\\(k_1 \boldsymbol{x}) \cdot (k_2 \boldsymbol{y}) =
  k_1 k_2 (\boldsymbol{x} \cdot \boldsymbol{y})\end{aligned}\end{align} \]</div>
<p>We sometimes need to be a bit careful about keeping track of which operations
are which; in particular, note that in the first equation, we have <em>vector</em>
addition on the left hand side, but <em>scalar</em> addition on the right.</p>
<p><strong>Exercise 5.4.</strong> Prove these two identities regarding the interaction of the
dot product with vector addition and scalar multiplication respectively. Hint:
we already know that multiplication distributes over addition in
<span class="math">\(\mathbb{R}\)</span>; that is, <span class="math">\(\forall x, y, z \in \mathbb{R}.\; x(y + z)
= xy + xz\)</span>.</p>
</div>
<div class="section" id="linear-mappings">
<h4>Linear mappings<a class="headerlink" href="#linear-mappings" title="Permalink to this headline">¶</a></h4>
<p>Let <span class="math">\(f\)</span> be a function from <span class="math">\(\mathbb{R}^2\)</span> to <span class="math">\(\mathbb{R}^2\)</span>,
such that the following two laws are satisfied for all <span class="math">\(\boldsymbol{x},
\boldsymbol{y} \in \mathbb{R}^2, k \in \mathbb{R}\)</span>:</p>
<div class="math">
\[ \begin{align}\begin{aligned}f(\boldsymbol{x} + \boldsymbol{y}) = f(\boldsymbol{x}) + f(\boldsymbol{y})\\f(k \boldsymbol{x}) = k f(\boldsymbol{x})\end{aligned}\end{align} \]</div>
<p>That is, if we have a pair of vectors and a function <span class="math">\(f\)</span> defined as
above, we can add the vectors together and then apply <span class="math">\(f\)</span>, or we can
apply <span class="math">\(f\)</span> to each of the vectors individually and then add the results
together, but in both cases we will always get the same result. Similarly if we
have a vector and a scalar, we can multiply the vector by the scalar and then
apply <span class="math">\(f\)</span>, or apply <span class="math">\(f\)</span> to the vector first and then do the scalar
multiplication on the result, but either way the we end up with the same vector.</p>
<p>Functions of this kind are important enough that we have a name for them:
<em>linear mappings</em>.</p>
<p>Here is one example of a linear mapping:</p>
<div class="math">
\[\begin{split}f(\begin{bmatrix}x_1\\x_2\end{bmatrix}) =
  \begin{bmatrix} 2x_1 + 3x_2 \\ x_1 - 2x_2 \end{bmatrix}\end{split}\]</div>
<p>Try choosing a couple of vectors in <span class="math">\(\mathbb{R}^2\)</span> and checking that the
linear mapping laws are satisfied with those vectors.</p>
<p>Here is an example of a function which fails to be a linear mapping:</p>
<div class="math">
\[\begin{split}f(\begin{bmatrix}x_1\\x_2\end{bmatrix}) =
  \begin{bmatrix} x_1^2 \\ x_2 \end{bmatrix}\end{split}\]</div>
<p>For example, if we take <span class="math">\(\boldsymbol{x} = (2, 0)\)</span> and <span class="math">\(k = 3\)</span>, then</p>
<div class="math">
\[\begin{split}f(k \boldsymbol{x}) =
  f(3 \begin{bmatrix}2\\0\end{bmatrix}) =
  f(\begin{bmatrix}6\\0\end{bmatrix}) =
  \begin{bmatrix}36\\0\end{bmatrix}\end{split}\]</div>
<p>However, if we apply the function first and then do the scalar multiplication,
we get a different result:</p>
<div class="math">
\[\begin{split}k f(\boldsymbol{x}) =
  3 f(\begin{bmatrix}2\\0\end{bmatrix}) =
  3 \begin{bmatrix}4\\0\end{bmatrix} =
  \begin{bmatrix}12\\0\end{bmatrix}\end{split}\]</div>
<div class="section" id="describing-linear-mappings-with-dot-products">
<h5>Describing linear mappings with dot products<a class="headerlink" href="#describing-linear-mappings-with-dot-products" title="Permalink to this headline">¶</a></h5>
<p>Now, suppose we have 2 vectors <span class="math">\(\boldsymbol{a_1}, \boldsymbol{a_2}, \in
\mathbb{R}^2\)</span>. We can use these to define a function which maps vectors in
<span class="math">\(\mathbb{R}^2\)</span> to vectors in <span class="math">\(\mathbb{R}^2\)</span> like this:</p>
<div class="math">
\[\begin{split}\boldsymbol{x}
  \mapsto
  \begin{bmatrix}
    \boldsymbol{a_1} \cdot \boldsymbol{x} \\
    \boldsymbol{a_2} \cdot \boldsymbol{x} \\
  \end{bmatrix}\end{split}\]</div>
<p>That is, we produce a new vector where the first component is the dot product
of <span class="math">\(\boldsymbol{a_1}\)</span> with the parameter <span class="math">\(\boldsymbol{x}\)</span>, and the
second component is the dot product of <span class="math">\(\boldsymbol{a_2}\)</span> with
<span class="math">\(\boldsymbol{x}\)</span>.</p>
<p>For example, let us take the following vectors for <span class="math">\(\boldsymbol{a_1}\)</span> and
<span class="math">\(\boldsymbol{a_2}\)</span>:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\begin{split}\boldsymbol{a_1} = \begin{bmatrix}1\\0\end{bmatrix}\end{split}\\\begin{split}\boldsymbol{a_2} = \begin{bmatrix}4\\-2\end{bmatrix}\end{split}\end{aligned}\end{align} \]</div>
<p>We can now define a function using them:</p>
<div class="math">
\[\begin{split}\begin{bmatrix}x_1\\x_2\end{bmatrix} \mapsto
  \begin{bmatrix}
    1x_1 + 0x_2 \\
    4x_1 - 2x_2 \\
  \end{bmatrix} =
  \begin{bmatrix}
    x_1 \\
    4x_1 - 2x_2
  \end{bmatrix}\end{split}\]</div>
<p>This particular function takes <span class="math">\((1,1)\)</span> to <span class="math">\((1,2)\)</span>, and it takes
<span class="math">\((2,0)\)</span> to <span class="math">\((2, 8)\)</span> — check this!</p>
<p>It turns out that functions which can be defined in terms of dot products like
this are precisely linear mappings — that is, if you define a function in terms
of dot products in this way, it will always be a linear mapping, and
conversely, any linear mapping can be described in terms of dot products like
we have just done here.</p>
<p><strong>Exercise 5.5.</strong> Show that any function defined in terms of dot products will
be a linear mapping, using previously given properties of the dot product.</p>
<p><strong>Exercise 5.6.</strong> Show that the composition of two linear mappings is itself
a linear mapping. That is, if <span class="math">\(f\)</span> and <span class="math">\(g\)</span> are linear mappings, then
the function <span class="math">\(f \circ g\)</span>, which is defined as <span class="math">\(\boldsymbol{x}
\mapsto f(g(\boldsymbol{x}))\)</span>, is itself a linear mapping.</p>
</div>
</div>
<div class="section" id="representation-of-linear-mappings-as-matrices">
<h4>Representation of linear mappings as matrices<a class="headerlink" href="#representation-of-linear-mappings-as-matrices" title="Permalink to this headline">¶</a></h4>
<p>An <span class="math">\(m \times n\)</span> matrix (read: “<span class="math">\(m\)</span> by <span class="math">\(n\)</span>“) is a rectangular
array of things — usually numbers, but not always — with <span class="math">\(m\)</span> rows and
<span class="math">\(n\)</span> columns. Here is a <span class="math">\(2 \times 2\)</span> matrix:</p>
<div class="math">
\[\begin{split}\begin{bmatrix}
  1 &amp; 2 \\
  3 &amp; 4 \\
\end{bmatrix}\end{split}\]</div>
<p>We define matrix addition in more or less the same way as vector addition, i.e.
adding corresponding components:</p>
<div class="math">
\[\begin{split}\begin{bmatrix}
  1 &amp; 2 \\
  3 &amp; 4
\end{bmatrix} +
\begin{bmatrix}
  5 &amp; 6 \\
  7 &amp; 8
\end{bmatrix} &amp;=
\begin{bmatrix}
  1+5 &amp; 2+6 \\
  3+7 &amp; 4+8
\end{bmatrix} \\ &amp;=
\begin{bmatrix}
  6 &amp; 8 \\
  10 &amp; 12
\end{bmatrix}\end{split}\]</div>
<p>Again, there is a zero matrix which is the identity for matrix addition, and it
is also written <span class="math">\(\boldsymbol{0}\)</span>. This overloaded notation doesn’t turn
out to be too much of a problem in practice, as it’s usually clear from context
which is meant.</p>
<p>As you might expect, for any pair of natural numbers <span class="math">\(m, n
\in \mathbb{N}\)</span>, the set of <span class="math">\(m \times n\)</span> matrices forms an Abelian group
under addition. Note that matrices must have the same dimensions if you want to
be able to add them together.</p>
<p>We represent a linear mapping from <span class="math">\(\mathbb{R}^2\)</span> to <span class="math">\(\mathbb{R}^2\)</span>
as a matrix by taking the vectors <span class="math">\(\boldsymbol{a_1}\)</span> and
<span class="math">\(\boldsymbol{a_2}\)</span> which we used to define the linear mapping and putting
each of them in the corresponding row of the matrix. So components of
<span class="math">\(\boldsymbol{a_1}\)</span> become the first row and components of
<span class="math">\(\boldsymbol{a_2}\)</span> become the second row. Here is the matrix
representation of the example linear mapping which we saw just a moment ago:</p>
<div class="math">
\[\begin{split}\begin{bmatrix}
    1 &amp; 0 \\
    4 &amp; -2
\end{bmatrix}\end{split}\]</div>
<p>We can multiply a matrix by a vector by writing them next to each other; this
operation corresponds to <em>application</em> of the linear mapping to the vector:</p>
<div class="math">
\[\begin{split}\begin{bmatrix}
    1 &amp; 0 \\
    4 &amp; -2
\end{bmatrix}
\begin{bmatrix} 1 \\ 1 \end{bmatrix} =
\begin{bmatrix} (1 \times 1) + (0 \times 1) \\ (4 \times 1) + (-2 \times 1) \end{bmatrix} =
\begin{bmatrix} 1 \\ 2 \end{bmatrix}\end{split}\]</div>
<p>We learned a moment ago that linear mappings can always be defined in terms of
dot products, and also that functions defined in terms of dot products are
linear mappings. Since a matrix is just another way of writing the vectors
<span class="math">\(\boldsymbol{a_1}\)</span> and <span class="math">\(\boldsymbol{a_2}\)</span>, matrices and linear
mappings are in one-to-one correspondence. This is very useful: if we are asked
a question about linear mappings which is difficult to answer, we can translate
it into an equivalent question about matrices (and vice versa) because of this
correspondence.  Sometimes, simply by translating a question about linear
mappings to one about matrices, we can make the answer immediately obvious,
even for questions which originally seemed very difficult.</p>
<p>We can generalise the operation of multiplying a matrix by a vector to allow us
to multiply matrices by other matrices. We do this by splitting the matrix on
the right hand side into columns, multiplying the matrix on the left by each of
these columns individually, and then joining up the resulting vectors so that
they form the columns of a new matrix.</p>
<p>For example, suppose we want to multiply these matrices:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\begin{split}A = \begin{bmatrix}
    1 &amp; 0 \\
    4 &amp; -2
\end{bmatrix}\end{split}\\\begin{split}B = \begin{bmatrix}
    1 &amp; 5 \\
    1 &amp; 3
\end{bmatrix}\end{split}\\AB = \;?\end{aligned}\end{align} \]</div>
<p>We start by splitting the right-hand matrix, <span class="math">\(B\)</span>, into columns:</p>
<div class="math">
\[\begin{split}\begin{bmatrix}1\\1\end{bmatrix} \;
\begin{bmatrix}5\\3\end{bmatrix} \;\end{split}\]</div>
<p>Then we multiply each of these by the left-hand matrix <span class="math">\(A\)</span>. We already
know that the result of multiplying <span class="math">\(A\)</span> by <span class="math">\((1,1)\)</span> is
<span class="math">\((1,2)\)</span>. The result of multiplying <span class="math">\(A\)</span> by the other column,
<span class="math">\((5,3)\)</span>, is <span class="math">\((5,6)\)</span> — again, I recommend checking this.  Finally we
put these columns back together:</p>
<div class="math">
\[\begin{split}AB = \begin{bmatrix}
  1 &amp; 5 \\
  2 &amp; 6
\end{bmatrix}\end{split}\]</div>
<p>In general, then, a product of <span class="math">\(2 \times 2\)</span> matrices looks like this:</p>
<div class="math">
\[\begin{split}\begin{bmatrix}
  a_1 &amp; b_1 \\
  c_1 &amp; d_1
\end{bmatrix}
\begin{bmatrix}
  a_2 &amp; b_2 \\
  c_2 &amp; d_2
\end{bmatrix} =
\begin{bmatrix}
  a_1 a_2 + b_1 c_2 &amp; a_1 b_2 + b_1 d_2 \\
  c_1 a_2 + d_1 c_2 &amp; c_1 b_2 + d_1 d_2
\end{bmatrix}\end{split}\]</div>
<p>The website <a class="reference external" href="http://matrixmultiplication.xyz">http://matrixmultiplication.xyz</a> is an interactive matrix
multiplication calculator, which you might like to play around with a bit to
get more of a feel for what is going on. I should also add that there are lots
of different ways of thinking about matrix multiplication. If what I’ve
described makes no sense to you, you might be able to find an alternative way
of thinking about it that works better for you with a little googling.</p>
<p>Matrix multiplication turns out to correspond to <em>composition</em> of linear
mappings. That is, if the matrix <span class="math">\(A\)</span> represents the linear mapping
<span class="math">\(f\)</span>, and the matrix <span class="math">\(B\)</span> represents the linear mapping <span class="math">\(g\)</span>,
then the matrix product <span class="math">\(AB\)</span> represents the linear mapping <span class="math">\(f \circ
g\)</span>.</p>
</div>
<div class="section" id="properties-of-matrix-operations">
<h4>Properties of matrix operations<a class="headerlink" href="#properties-of-matrix-operations" title="Permalink to this headline">¶</a></h4>
<p>The set of <span class="math">\(n \times n\)</span> matrices under matrix multiplication turns out to
be a monoid:</p>
<ul class="simple">
<li>The result of multiplying two <span class="math">\(n \times n\)</span> matrices is always a
<span class="math">\(n \times n\)</span> matrix.</li>
<li>Matrix multiplication is associative; that is, if we have three <span class="math">\(n
\times n\)</span> matrices <span class="math">\(A, B, C\)</span>, then <span class="math">\((AB)C = A(BC)\)</span>.</li>
<li>Matrix multiplication has an identity, called the <em>identity matrix</em>. There
is an <span class="math">\(n \times n\)</span> identity matrix for every <span class="math">\(n \in \mathbb{N}\)</span>;
multiplying any matrix by it gives you back the same matrix.</li>
</ul>
<p>The question of how to prove that matrix multiplication is associative is a
very good example of one of those questions it is easy to see the answer to by
translating the question into a different one. Although possible, it is
extremely tedious to show that matrix multiplication is associative directly. A
better approach is to simply say that since matrix multiplication corresponds
to composition of linear mappings, and since function composition is
associative, matrix multiplication must be associative too.</p>
<p>The <span class="math">\(2 \times 2\)</span> identity matrix looks like this:</p>
<div class="math">
\[\begin{split}\begin{bmatrix}
    1 &amp; 0 \\
    0 &amp; 1
\end{bmatrix}\end{split}\]</div>
<p>You might like to try multiplying it with some other matrices to check that it
is indeed the identity for multiplication.</p>
<p>Matrix multiplication also distributes over matrix addition. That is, for
<span class="math">\(n \times n\)</span> matrices <span class="math">\(A, B, C,\)</span> we have that</p>
<div class="math">
\[ \begin{align}\begin{aligned}A(B+C) = AB + AC\\(A+B)C = AC + BC\end{aligned}\end{align} \]</div>
<p>just like with real numbers. Therefore, we have seen that the three ring laws
for the set of <span class="math">\(n \times n\)</span> matrices under matrix addition and matrix
multiplication hold, and therefore this set is a ring. We denote the ring of
<span class="math">\(n \times n\)</span> matrices with entries in <span class="math">\(\mathbb{R}\)</span> by
<span class="math">\(\mathrm{Mat}(n; \mathbb{R})\)</span>.</p>
<p>However, unlike real numbers, matrix multiplication is not commutative. In fact
I promised to show you a non-commutative ring in the previous chapter; here it
is! With matrices, <span class="math">\(AB\)</span> does not always equal <span class="math">\(BA\)</span>. For example, if
we have</p>
<div class="math">
\[ \begin{align}\begin{aligned}\begin{split}A = \begin{bmatrix}
    1 &amp; 1 \\
    0 &amp; 1
\end{bmatrix}\end{split}\\\begin{split}B = \begin{bmatrix}
    0 &amp; 1 \\
    0 &amp; 1
\end{bmatrix},\end{split}\end{aligned}\end{align} \]</div>
<p>then multiplying one way gives us</p>
<div class="math">
\[\begin{split}AB = \begin{bmatrix}
    0 &amp; 2 \\
    0 &amp; 1
\end{bmatrix}\end{split}\]</div>
<p>but the other way gives us</p>
<div class="math">
\[\begin{split}BA = \begin{bmatrix}
  0 &amp; 1 \\
  0 &amp; 1
\end{bmatrix}.\end{split}\]</div>
<p>Since matrices correspond to linear mappings, we can also conclude that linear
mappings form a noncommutative ring where the multiplication operation is
function composition. What will the addition operation be? (Hint: it’s the
linear mapping analogue of matrix addition.)</p>
</div>
</div>
<span id="document-integral-domains"></span><div class="section" id="integral-domains">
<h3>Integral domains<a class="headerlink" href="#integral-domains" title="Permalink to this headline">¶</a></h3>
<p>Now that you have seen a few examples of rings, we will talk about a
particular kind of ring called an <em>integral domain</em>.</p>
<p>There is a fact about <span class="math">\(\mathbb{R}\)</span> which you might know already, called
the <strong>cancellation law</strong>, which says that for any <span class="math">\(a, b, c \in
\mathbb{R}\)</span>, such that <span class="math">\(a \neq 0\)</span> and <span class="math">\(ab = ac\)</span>, it must be the
case that <span class="math">\(b = c\)</span>. We can establish this without too much effort: since
<span class="math">\(a\)</span> is nonzero, we can divide both sides of the equation <span class="math">\(ab = ac\)</span>
by <span class="math">\(a\)</span>, and this yields the desired result.</p>
<p>Now <span class="math">\(\mathbb{R}\)</span> is a ring, so we might now wonder if a version of the
above statement is true for all rings. In fact it is not, and at this point I
can show you two counterexamples!</p>
<p>First recall the ring <span class="math">\(\mathbb{Z}_{12}\)</span>. In this ring, if we let <span class="math">\(a
= \overline{6}, b = \overline{5},\)</span> and <span class="math">\(c = \overline{1}\)</span>, then <span class="math">\(a
\neq \overline{0}\)</span> and <span class="math">\(ab = ac\)</span>, but <span class="math">\(b \neq c\)</span> (check this!).</p>
<p>Now, consider the ring <span class="math">\(\mathrm{Mat}(2;\mathbb{R})\)</span>. In this ring, we
have</p>
<div class="math">
\[\begin{split}\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{bmatrix}
\begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 0 \end{bmatrix}
=
\begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 0 \end{bmatrix}\end{split}\]</div>
<p>but also</p>
<div class="math">
\[\begin{split}\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{bmatrix}
\begin{bmatrix} -1 &amp; -1 \\ 1 &amp; 1 \end{bmatrix}
=
\begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 0 \end{bmatrix}\end{split}\]</div>
<p>so if we define</p>
<div class="math">
\[ \begin{align}\begin{aligned}\begin{split}A = \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 1 \end{bmatrix}\end{split}\\\begin{split}B = \begin{bmatrix} 0 &amp; 0 \\ 0 &amp; 0 \end{bmatrix}\end{split}\\\begin{split}C = \begin{bmatrix} -1 &amp; -1 \\ 1 &amp; 1 \end{bmatrix}\end{split}\end{aligned}\end{align} \]</div>
<p>then we have <span class="math">\(AB = AC\)</span> and <span class="math">\(A \neq 0\)</span>, but <span class="math">\(B \neq C\)</span>.</p>
<p>So what do we do now? Clearly the cancellation law holds for some rings, but
not all of them. Whenever we come across a new ring, or if we are just working
with some abstract ring and we don’t know which specific ring it is, we would
like to be able to say whether the cancellation law holds in it.</p>
<p>To do this we need a new definition. Let <span class="math">\(R\)</span> be any ring, and let
<span class="math">\(a \in R\)</span> with <span class="math">\(a\)</span> nonzero. We say that <span class="math">\(a\)</span> is a
<em>zero-divisor</em> if there exists a nonzero <span class="math">\(b \in R\)</span> such that either
<span class="math">\(ab = 0\)</span> or <span class="math">\(ba = 0\)</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In a commutative ring <span class="math">\(ab\)</span> is always equal to <span class="math">\(ba\)</span>, so it is
redundant to say “either <span class="math">\(ab = 0\)</span> or <span class="math">\(ba = 0\)</span>“; we might as well
just say “<span class="math">\(ab = 0\)</span>”. However, we want our theory to work with
noncommutative rings too, which is why we specify that either <span class="math">\(ab = 0\)</span>
or <span class="math">\(ba = 0\)</span>.</p>
</div>
<p><strong>Exercise 6.1.</strong> Show that <span class="math">\(a = \overline{3}\)</span> is a zero-divisor in
<span class="math">\(\mathbb{Z}_{12}\)</span> by finding a value <span class="math">\(b\)</span> such that <span class="math">\(ab =
\overline{0}\)</span>.</p>
<p><strong>Exercise 6.2.</strong> Let <span class="math">\(R\)</span> be any ring. Show that the multiplicative
identity in <span class="math">\(R\)</span> cannot be a zero-divisor.</p>
<p>Now we can introduce integral domains; an <em>integral domain</em> is a non-zero
commutative ring which has no zero-divisors. We can equivalently define an
integral domain as a non-zero commutative ring <span class="math">\(R\)</span> in which for all
<span class="math">\(a, b \in R\)</span>, if both <span class="math">\(a \neq 0\)</span> and <span class="math">\(b \neq 0\)</span> then their
product <span class="math">\(ab \neq 0\)</span> (why?).</p>
<p>The natural first example of an integral domain is <span class="math">\(\mathbb{Z}\)</span>, and this
is probably where the name “integral domain” comes from.</p>
<p>Our next example of an integral domain is <span class="math">\(\mathbb{Z}_2\)</span>. Why is this an
integral domain? Well, first, we know it is a commutative ring (we saw this in
the Rings chapter). But we still need to check it has no zero-divisors. In this
case there are only two elements to check: <span class="math">\(\overline{0}\)</span> and
<span class="math">\(\overline{1}\)</span>. We can immediately rule out <span class="math">\(\overline{0}\)</span>, because
a zero-divisor must be nonzero. We also saw in exercise 6.2 that
<span class="math">\(\overline{1}\)</span> cannot be a zero-divisor of <span class="math">\(\mathbb{Z}_2\)</span> because
it is the multiplicative identity. Therefore <span class="math">\(\mathbb{Z}_2\)</span> has no
zero-divisors. So we have established that <span class="math">\(\mathbb{Z}_2\)</span> satisfies both
of the requirements to be an integral domain.</p>
<p>We have also seen some non-examples. We found a zero-divisor in
<span class="math">\(\mathbb{Z}_{12}\)</span> in exercise 6.1, so <span class="math">\(\mathbb{Z}_{12}\)</span> is not an
integral domain. We also saw a zero-divisor in
<span class="math">\(\mathrm{Mat}(2;\mathbb{R})\)</span> earlier in this chapter, namely the matrix
<span class="math">\(A\)</span>, so this ring is not an integral domain either. We could also show
that <span class="math">\(\mathrm{Mat}(2;\mathbb{R})\)</span> is not an integral domain by observing
that it is not commutative.</p>
<p><strong>Exercise 6.3.</strong> Show that <span class="math">\(\mathbb{Z}_{8}\)</span> is not an integral domain.</p>
<p>I think it is quite an interesting result that whether or not
<span class="math">\(\mathbb{Z}_m\)</span> is an integral domain depends on the choice of <span class="math">\(m\)</span>;
in particular, we now know that <span class="math">\(\mathbb{Z}_2\)</span> is an integral domain, but
neither of <span class="math">\(\mathbb{Z}_{12}\)</span> or <span class="math">\(\mathbb{Z}_8\)</span> are.</p>
<p><strong>Exercise 6.4. (hard)</strong> Try to establish whether <span class="math">\(\mathbb{Z}_m\)</span> is an
integral domain for a couple more choices of <span class="math">\(m\)</span>. Can you think of a rule
for determining whether <span class="math">\(\mathbb{Z}_m\)</span> is an integral domain for any
given <span class="math">\(m \geq 2\)</span>?</p>
<div class="section" id="the-cancellation-law-for-integral-domains">
<h4>The cancellation law for integral domains<a class="headerlink" href="#the-cancellation-law-for-integral-domains" title="Permalink to this headline">¶</a></h4>
<p>The subheading of this paragraph probably gives the game away a bit. Well
anyway, I can reveal to you that the cancellation law holds for any integral
domain! We just need to state and prove this now.</p>
<p>Let <span class="math">\(R\)</span> be any integral domain. The cancellation law says that for any
<span class="math">\(a, b, c \in R\)</span>, such that <span class="math">\(a \neq 0\)</span> and <span class="math">\(ab = ac\)</span>, then
<span class="math">\(b = c\)</span>.</p>
<p>To prove this, suppose we have <span class="math">\(a, b, c \in R\)</span> with <span class="math">\(a \neq 0\)</span> and
<span class="math">\(ab = ac\)</span>. Then we can subtract <span class="math">\(ac\)</span> from both sides to get
<span class="math">\(ab - ac = 0\)</span>, and factor out <span class="math">\(a\)</span> on the left hand side to get
<span class="math">\(a(b - c) = 0\)</span>. Now since <span class="math">\(R\)</span> is an integral domain, and since
<span class="math">\(a \neq 0\)</span>, it must be the case that <span class="math">\(b - c = 0\)</span>, that is, <span class="math">\(b
= c\)</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You might be wondering why this proof is different to the earlier proof I
gave for why the cancellation law holds in <span class="math">\(\mathbb{R}\)</span>. The reason for
this is that in <span class="math">\(\mathbb{R}\)</span>, every nonzero number has a multiplicative
inverse, but this is not always true in an integral domain. For example,
<span class="math">\(2\)</span> has no multiplicative inverse in <span class="math">\(\mathbb{Z}\)</span>. We will talk
more about multiplicative inverses later on, when we get on to fields.</p>
</div>
</div>
</div>
<span id="document-fields"></span><div class="section" id="fields">
<h3>Fields<a class="headerlink" href="#fields" title="Permalink to this headline">¶</a></h3>
<p>We are finally ready to talk about one of the most important types of rings,
namely <em>fields</em>.</p>
<p>Let <span class="math">\(R\)</span> be a ring, and let <span class="math">\(x \in R\)</span>. We say that <span class="math">\(x\)</span> is a
<em>unit</em> if there exists some <span class="math">\(y \in R\)</span> such that <span class="math">\(xy = yx = 1\)</span>,
that is, if <span class="math">\(x\)</span> has a multiplicative inverse. For example, in any ring,
<span class="math">\(1\)</span> is always a unit, and <span class="math">\(0\)</span> is never a unit.</p>
<p>Then, a <em>field</em> is defined as a commutative ring in which every nonzero element
is a unit. We can equivalently say that a field is a commutative ring for which
the nonzero elements form a group under multiplication. We usually use the
notation <span class="math">\(x^{-1}\)</span> for the multiplicative inverse of <span class="math">\(x\)</span> in a field.</p>
<p>Here are some examples of fields which we have already seen:</p>
<ul class="simple">
<li>The real numbers, <span class="math">\(\mathbb{R}\)</span></li>
<li>The rational numbers, <span class="math">\(\mathbb{Q}\)</span></li>
<li>The integers modulo <span class="math">\(2\)</span>, <span class="math">\(\mathbb{Z}_2\)</span>. Note that the
multiplicative inverse for <span class="math">\(1\)</span> in any ring necessarily exists (it is
also <span class="math">\(1\)</span>), and this ring has no other nonzero elements to consider, so
it must be a field.</li>
</ul>
<p>Here are some non-examples:</p>
<ul>
<li><p class="first">The ring of integers, <span class="math">\(\mathbb{Z}\)</span>. This fails to be a field because
the only nonzero elements with multiplicative inverses are <span class="math">\(1\)</span> and
<span class="math">\(-1\)</span>; there is no integer which can be multiplied by <span class="math">\(2\)</span> to yield
<span class="math">\(1\)</span>, for example.</p>
</li>
<li><p class="first">The ring of integers modulo <span class="math">\(4\)</span>, <span class="math">\(\mathbb{Z}_4\)</span>. This fails to be
a field because the element <span class="math">\(\overline{2}\)</span> does not have a
multiplicative inverse. We can check this exhaustively:</p>
<div class="math">
\[\begin{split}\overline{1} \cdot \overline{2} = \overline{2} \\
\overline{2} \cdot \overline{2} = \overline{0} \\
\overline{3} \cdot \overline{2} = \overline{2}\end{split}\]</div>
<p>None of these are equal to <span class="math">\(\overline{1}\)</span>, so we can conclude that none
of them is a multiplicative inverse of <span class="math">\(\overline{2}\)</span>.</p>
</li>
<li><p class="first">The ring of <span class="math">\(2 \times 2\)</span> matrices with entries in <span class="math">\(\mathbb{R}\)</span>.
This fails to be a field because it is non-commutative, as we have seen, and
also because there are nonzero elements which do not have multiplicative
inverses.</p>
</li>
</ul>
<p>We also have a name for rings in which all nonzero elements are units but
multiplication is not necessarily commutative: these are called <em>division
rings</em>, or sometimes <em>skew fields</em>. It just happens that most of the
interesting examples of division rings are also fields, so we tend to spend
more time thinking about fields.  There is, however, one important example of a
division ring which is not a field, which we will see later on.</p>
<div class="section" id="a-quick-diversion-into-set-theory">
<h4>A quick diversion into set theory<a class="headerlink" href="#a-quick-diversion-into-set-theory" title="Permalink to this headline">¶</a></h4>
<p>There are a couple of important results concerning fields which we will soon
establish, but first we need another quick diversion into set theory. This
builds upon the <a class="reference internal" href="index.html#injectivity-and-surjectivity"><span class="std std-ref">Permutations</span></a> section in the chapter on
groups, so if you need a refresher now might be a good time to revisit it.</p>
<div class="section" id="subsets">
<h5>Subsets<a class="headerlink" href="#subsets" title="Permalink to this headline">¶</a></h5>
<p>Let <span class="math">\(A\)</span> and <span class="math">\(B\)</span> be sets. We say that <span class="math">\(A\)</span> is a <em>subset</em> of
<span class="math">\(B\)</span> if <span class="math">\(x \in A \Rightarrow x \in B\)</span>, that is, every element of
<span class="math">\(A\)</span> is also an element of <cite>B</cite>. Symbolically, we write <span class="math">\(A \subseteq
B\)</span>.</p>
<p>One consequence of this definition is that every set is a subset of itself. If
we want to rule out this case, we would say that <span class="math">\(A\)</span> is a <em>proper subset</em>
of <span class="math">\(B\)</span>, and this is written <span class="math">\(A \subset B\)</span>.</p>
</div>
<div class="section" id="images-of-functions">
<h5>Images of functions<a class="headerlink" href="#images-of-functions" title="Permalink to this headline">¶</a></h5>
<p>We call the set of elements that can be produced as a result of applying
a function <span class="math">\(f\)</span> to an element of its domain the <em>image</em> of <span class="math">\(f\)</span>.
Note that this set is necessarily a subset of the codomain; in fact, another
way of defining a surjective function is one whose image is equal to its
codomain.</p>
<p>Notationally, the image of a function <span class="math">\(f : X \rightarrow Y\)</span> is written as
<span class="math">\(f(X)\)</span> — this is arguably a bit of an abuse of notation, as this looks
like we’re applying a function to a set, which, if we’re being pedantic,
doesn’t make sense — but it is defined as follows:</p>
<div class="math">
\[f(X) = \{\, f(x) \,|\, x \in X \,\}\]</div>
<p>So we have that <span class="math">\(f(X) \subseteq Y\)</span> is true for any function <span class="math">\(f : X
\rightarrow Y\)</span>, and also that <span class="math">\(f(X) = Y\)</span> if and only if <span class="math">\(f\)</span> is
surjective.</p>
</div>
<div class="section" id="injectivity-and-surjectivity-with-finite-sets">
<h5>Injectivity and surjectivity with finite sets<a class="headerlink" href="#injectivity-and-surjectivity-with-finite-sets" title="Permalink to this headline">¶</a></h5>
<p>Here is an important result which we will need shortly:</p>
<ul class="simple">
<li>Let <span class="math">\(X\)</span> be a set with finitely many elements, and let <span class="math">\(f : X
\rightarrow X\)</span> be a function. Then <span class="math">\(f\)</span> is injective if and only if it
is surjective.</li>
</ul>
<p>In this proof we will use <span class="math">\(n\)</span> to refer to the size of the set <span class="math">\(X\)</span>,
i.e. <span class="math">\(X\)</span> has <span class="math">\(n\)</span> distinct elements.</p>
<p>First, suppose <span class="math">\(f\)</span> is injective. That is, if <span class="math">\(x \neq y\)</span>, then
<span class="math">\(f(x) \neq f(y)\)</span>. It follows that <span class="math">\(f(X)\)</span> has at least <span class="math">\(n\)</span>
elements, as each of the <span class="math">\(n\)</span> elements of <span class="math">\(X\)</span> which we can apply
<span class="math">\(f\)</span> to is mapped to a distinct element of the codomain of <span class="math">\(f\)</span>
(which, here, is also <span class="math">\(X\)</span>). Since <span class="math">\(X\)</span> is also the codomain of
<span class="math">\(f\)</span>, we have that <span class="math">\(f(X) \subseteq X\)</span>, and in particular,
<span class="math">\(f(X)\)</span> can have no more than <span class="math">\(n\)</span> elements (since <span class="math">\(X\)</span> only has
<span class="math">\(n\)</span> elements). So <span class="math">\(f(X)\)</span> has exactly <span class="math">\(n\)</span> elements, and since
each of them is an element of <span class="math">\(X\)</span> we can conclude that <span class="math">\(f(X) = X\)</span>,
i.e. <span class="math">\(f\)</span> is surjective.</p>
<p>Conversely, suppose that <span class="math">\(f\)</span> is surjective, i.e. each element of
<span class="math">\(X\)</span> can be obtained by applying <span class="math">\(f\)</span> to some (possibly different)
element of <span class="math">\(X\)</span>. In this case it must be injective; if it weren’t, there
would be at least two elements of <span class="math">\(X\)</span> which were mapped to the same thing
by <span class="math">\(f\)</span>, and then of the remaining <span class="math">\(n - 2\)</span> elements of <span class="math">\(X\)</span>, we
have <span class="math">\(n - 1\)</span> elements of <span class="math">\(X\)</span> to reach, which is not possible.</p>
<p>Okay, that’s everything. Back to fields!</p>
</div>
</div>
<div class="section" id="every-field-is-an-integral-domain">
<h4>Every field is an integral domain<a class="headerlink" href="#every-field-is-an-integral-domain" title="Permalink to this headline">¶</a></h4>
<p>This is fairly straightforward to prove. Let <span class="math">\(F\)</span> be a field, and let
<span class="math">\(a, b \in F\)</span>, with <span class="math">\(a \neq 0\)</span>. Suppose <span class="math">\(ab = 0\)</span>. Since
<span class="math">\(F\)</span> is a field, <span class="math">\(a^{-1}\)</span> exists. Multiplying both sides by
<span class="math">\(a^{-1}\)</span> yields <span class="math">\(a^{-1}ab = a^{-1}0\)</span>, which simplifies to <span class="math">\(b
= 0\)</span>. That is, <span class="math">\(F\)</span> has no zero-divisors. We have by assumption that
<span class="math">\(F\)</span> is commutative (since this is one of the requirements for a field)
and therefore <span class="math">\(F\)</span> is an integral domain.</p>
<p>This gives us a useful trick for determining whether some ring is a field or
not: since all fields are integral domains, we can immediately deduce that a
ring cannot be a field if it fails to be an integral domain, e.g. if it has any
zero-divisors. Note that for two of the three non-examples of fields listed
earlier, namely <span class="math">\(\mathbb{Z}_4\)</span> and <span class="math">\(\mathrm{Mat}(2;\mathbb{R})\)</span>, it
can be shown that they are not fields in this way.</p>
<p>Let’s do a quick recap on the hierarchy we have seen so far; we have:</p>
<ul class="simple">
<li>rings <span class="math">\(\supset\)</span> commutative rings <span class="math">\(\supset\)</span> integral domains
<span class="math">\(\supset\)</span> fields.</li>
</ul>
<p>That is, every commutative ring is a ring (but not every ring is
commutative), every integral domain is a commutative ring (but not every
commutative ring is an integral domain), and so on.</p>
</div>
<div class="section" id="every-finite-integral-domain-is-a-field">
<h4>Every finite integral domain is a field<a class="headerlink" href="#every-finite-integral-domain-is-a-field" title="Permalink to this headline">¶</a></h4>
<p>This is slightly more difficult to prove, so don’t worry if the proof doesn’t
make complete sense to you at first.</p>
<p>Let <span class="math">\(R\)</span> be a finite integral domain, and let <span class="math">\(a \in R\)</span> with
<span class="math">\(a \neq 0\)</span>. Now, define a function <span class="math">\(\lambda_a : R \rightarrow R\)</span> by
<span class="math">\(\lambda_a(x) = ax\)</span>, that is, the function <span class="math">\(\lambda_a\)</span> represents
multiplication by <span class="math">\(a\)</span>. Now let <span class="math">\(b, c \in R\)</span>, and notice that the
cancellation law for integral domains tells us that <span class="math">\(ab = ac\)</span> implies
<span class="math">\(b = c\)</span>. That is, if <span class="math">\(\lambda_a(b) = \lambda_a(c)\)</span>, then <span class="math">\(b =
c\)</span>. This is precisely what it means for the function <span class="math">\(\lambda_a\)</span> to be
injective.</p>
<p>Using our previously established result that an injective function on a finite
set must also be surjective, we can deduce that <span class="math">\(\lambda_a\)</span> is
surjective, and consequently also bijective. Therefore, it must have an inverse
function <span class="math">\(\lambda_a^{-1}\)</span>, and in particular if we let <span class="math">\(d =
\lambda_a^{-1}(1)\)</span>, then we have that <span class="math">\(ad = 1\)</span>, i.e. <span class="math">\(d\)</span> is a
multiplicative inverse for <span class="math">\(a\)</span>.</p>
<p>We have now found a multiplicative inverse for every nonzero element of
<span class="math">\(R\)</span>, and we have by assumption that <span class="math">\(R\)</span> is commutative, so it
follows that <span class="math">\(R\)</span> is a field.</p>
<p>Look back now to exercise 6.4 in the previous chapter, which asks you to
provide a rule for whether <span class="math">\(\mathbb{Z}_m\)</span> is an integral domain given any
<span class="math">\(m \geq 2\)</span>. This is quite a difficult exercise but the result is quite
useful, so I recommend that you look at the solution now if you weren’t able to
solve it yourself.</p>
<p>Using our new result that every finite integral domain is a field, we can now
strengthen the result we found in exercise 6.4: since <span class="math">\(\mathbb{Z}_m\)</span> is
finite, if it is an integral domain, it must be a field. The field of integers
modulo <span class="math">\(m\)</span> for an appropriately chosen <span class="math">\(m\)</span> (I’m deliberately being
vague to avoid spoiling you for exercise 6.4 if you want to have another go at
it) is generally my go-to example of a field, as these fields tend to be the
simplest to deal with and can be faithfully represented on computers very
easily — unlike, say, <span class="math">\(\mathbb{R}\)</span>.</p>
</div>
</div>
<span id="document-complex-numbers"></span><div class="section" id="complex-numbers">
<h3>Complex numbers<a class="headerlink" href="#complex-numbers" title="Permalink to this headline">¶</a></h3>
<p>We encountered the set <span class="math">\(\mathbb{R}^2\)</span> in the <a class="reference internal" href="index.html#document-matrices"><span class="doc">Matrices</span></a> chapter, and
defined an addition operation which made <span class="math">\((\mathbb{R}^2, +)\)</span> an abelian
group. In this section we will come across a multiplication operation on
<span class="math">\(\mathbb{R}^2\)</span> and we will see that with these two operations,
<span class="math">\(\mathbb{R}^2\)</span> can be made into a field, which is called the field of
<em>complex numbers</em>. When we are making use of the field structure we will
usually write this field as <span class="math">\(\mathbb{C}\)</span> rather than
<span class="math">\(\mathbb{R}^2\)</span>.</p>
<p>Complex numbers have a variety of applications, including in geometry, for e.g.
representing figures in two dimensions, for modelling behaviour of electrical
signals, and for analysing the behaviour of systems which can be modelled using
differential equations, such as how populations of different species in a food
web change over time, how heat flows through an object, or how mechanical
systems like suspension in a car will behave. They also function as useful
tools in many other areas of mathematics. For instance, they play a major role
in the proof that quintic equations — that is, equations of the form
<span class="math">\(ax^5 + bx^4 + cx^3 + dx^2 + ex + f = 0\)</span> — cannot be solved in general,
as well as offering some nifty tricks to perform otherwise difficult
integrations of real-valued functions.</p>
<p>First, instead of writing elements of <span class="math">\(\mathbb{R}^2\)</span> in the usual way,
i.e. <span class="math">\((a, b)\)</span>, we will write them as <span class="math">\(a + bi\)</span>, where <span class="math">\(a\)</span> and
<span class="math">\(b\)</span> are real numbers. For example, we write <span class="math">\((1,2)\)</span> as <span class="math">\(1 +
2i\)</span>, we write <span class="math">\((1,0)\)</span> as just <span class="math">\(1\)</span>, and we write <span class="math">\((0,1)\)</span> as
just <span class="math">\(i\)</span>. For a complex number <span class="math">\(a + bi\)</span>, we call <span class="math">\(a\)</span> the
“real part”, and <span class="math">\(b\)</span> the “imaginary part”.</p>
<p>Therefore, to add two complex numbers together, we simply add the real and
imaginary parts. That is, <span class="math">\((a + bi) + (c + di) = (a+c) + (b+d)i\)</span>.</p>
<p>For the multiplication operation, if we remember that <span class="math">\(i^2 = -1\)</span>, the
rest sort of falls out. That is, to multiply two complex numbers together,
we can write <span class="math">\((a + bi)(c + di) = ac + adi + bci + bdi^2\)</span>, making use of
distributivity, and then using distributivity again (but in the reverse
direction) and replacing <span class="math">\(i^2\)</span> with <span class="math">\(-1\)</span>, we can write this as
<span class="math">\((ac - bd) + (ad + bc)i\)</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This approach is a bit sloppy because we are assuming that
<span class="math">\(\mathbb{C}\)</span> is a field before even defining its multiplication
operation. I hope you can forgive me for this.</p>
</div>
<p>Notice that the subset of <span class="math">\(\mathbb{C}\)</span> given by the complex numbers which
have an imaginary part of <span class="math">\(0\)</span> behaves in exactly the same way as
<span class="math">\(\mathbb{R}\)</span>; because of this, we can consider <span class="math">\(\mathbb{R}\)</span> as a
subset of <span class="math">\(\mathbb{C}\)</span>. In the same vein we will describe elements of
<span class="math">\(\mathbb{C}\)</span> which have an imaginary part of <span class="math">\(0\)</span> as “real”.</p>
<p>Another useful thing to notice is that to multiply a real number by a complex
number, you simply multiply the real and imaginary parts by that number. That
is, for <span class="math">\(a \in \mathbb{R}\)</span>,</p>
<div class="math">
\[(a+0i)(c+di) = (ac + 0d) + (ad + 0c)i = (ac) + (ad)i\]</div>
<p>Establishing that <span class="math">\(\mathbb{C}\)</span> is a ring (in fact, a commutative ring)
with respect to these addition and multiplication operations is a little
tedious, so I won’t set it as an ‘official’ exercise, but you may find it worth
doing anyway.</p>
<p>However, establishing that <span class="math">\(\mathbb{C}\)</span> is a field — in particular,
showing that all nonzero elements have multiplicative inverses — is more
interesting.</p>
<p>To find the multiplicative inverse of an arbitrary complex number, we use an
operation called <em>conjugation</em>. The <em>conjugate</em> of a complex number is obtained
by negating the imaginary part, i.e. the conjugate of <span class="math">\(a + bi\)</span> is
<span class="math">\(a - bi\)</span>. The first thing to notice is that multiplying a complex number
by its conjugate always yields a real number:</p>
<div class="math">
\[\begin{split}(a + bi)(a - bi)
&amp;= a^2 + abi - abi - b^2i^2 \\
&amp;= a^2 + b^2\end{split}\]</div>
<p>Now, if we write the multiplicative inverse of <span class="math">\(a + bi\)</span> as a fraction
<span class="math">\(\frac{1}{a+bi}\)</span>, the answer becomes a little clearer. Just as with real
numbers, we can multiply top and bottom by the same quantity:</p>
<div class="math">
\[\begin{split}\frac{1}{a+bi}
&amp;= \frac{a-bi}{(a+bi)(a-bi)} \\
&amp;= \frac{a-bi}{a^2+b^2}\end{split}\]</div>
<p>Now we have the product of a complex number with a real number, i.e. we have
<span class="math">\(a - bi\)</span> multiplied by <span class="math">\(\frac{1}{a^2 + b^2}\)</span>. As we showed before
we can simply multiply the real and imaginary parts by this real number,
which gives us the inverse of <span class="math">\(a + bi\)</span> as:</p>
<div class="math">
\[\frac{a-bi}{a^2+b^2} = \frac{a}{a^2+b^2} - \frac{b}{a^2+b^2}i\]</div>
<p>Let’s check that this really is the multiplicative inverse of <span class="math">\(a + bi\)</span>,
just to be safe:</p>
<div class="math">
\[\begin{split}(a+bi) \left( \frac{a}{a^2+b^2} - \frac{b}{a^2+b^2}i \right)
&amp;= \frac{a^2}{a^2+b^2} - \frac{ab}{a^2+b^2}i + \frac{ab}{a^2+b^2}i - \frac{b^2}{a^2+b^2}i^2 \\
&amp;= \frac{a^2 + b^2}{a^2 + b^2} \\
&amp;= 1\end{split}\]</div>
<p>So there you have it — we can indeed make <span class="math">\(\mathbb{R}^2\)</span> into a field!</p>
<p>There is so, so much more I could say about complex numbers, but I think I will
leave it here for now.</p>
</div>
<span id="document-euclidean-algorithm"></span><div class="section" id="the-euclidean-algorithm">
<h3>The Euclidean Algorithm<a class="headerlink" href="#the-euclidean-algorithm" title="Permalink to this headline">¶</a></h3>
<p>We now return to the familiar world of the integers, where we will learn (or
perhaps remind ourselves) about what the <em>greatest common divisor</em> of two
integers is, and about an algorithm which allows us to compute them easily, and
why it works. This will form part of the motivation for the idea of a
<em>euclidean ring</em>, a structure which generalises the integers.</p>
<div class="section" id="integer-division">
<h4>Integer division<a class="headerlink" href="#integer-division" title="Permalink to this headline">¶</a></h4>
<p>Let <span class="math">\(a, b \in \mathbb{Z}\)</span>. We say that <span class="math">\(a\)</span> <em>divides</em> <span class="math">\(b\)</span> if
there exists some <span class="math">\(q \in \mathbb{Z}\)</span> such that <span class="math">\(aq = b\)</span>. Another
way of understanding this is that <span class="math">\(b\)</span> can be divided exactly by <span class="math">\(a\)</span>
to yield <span class="math">\(q\)</span>. In symbols, this is written <span class="math">\(a \mid b\)</span>.</p>
<p>For example, <span class="math">\(5 \mid 20\)</span>, and also <span class="math">\(4 \mid 20\)</span>.</p>
<p>Of course, we often have to deal with the less happy situation where integers
don’t divide exactly into each other. All hope is not lost, though: if we have
two integers <span class="math">\(a, b\)</span>, with <span class="math">\(b &gt; 0\)</span>, then there always exists a pair
of integers <span class="math">\(q\)</span> and <span class="math">\(r\)</span> such that <span class="math">\(a = qb + r\)</span>, and <span class="math">\(0
\leq r &lt; b\)</span>. We usually call <span class="math">\(q\)</span> the <em>quotient</em> and we call <span class="math">\(r\)</span>
the <em>remainder</em>. You probably know already that a remainder of <span class="math">\(0\)</span>
indicates that the pair of integers we are dealing with do divide into each
other exactly.</p>
</div>
<div class="section" id="greatest-common-divisors">
<h4>Greatest common divisors<a class="headerlink" href="#greatest-common-divisors" title="Permalink to this headline">¶</a></h4>
<p>If <span class="math">\(d\)</span> divides <span class="math">\(a\)</span>, and <span class="math">\(d\)</span> also divides <span class="math">\(b\)</span>, we say
that <span class="math">\(d\)</span> is a <em>common divisor</em> of <span class="math">\(a\)</span> and <span class="math">\(b\)</span>. If <span class="math">\(d\)</span>
is greater than any other common divisor of <span class="math">\(a\)</span> and <span class="math">\(b\)</span>, we say
that <span class="math">\(d\)</span> is the <em>greatest common divisor</em> of <span class="math">\(a\)</span> and <span class="math">\(b\)</span>.
This chapter is mostly concerned with finding the greatest common divisor of
any pair of integers; we can do this by using an algorithm called the Euclidean
Algorithm.</p>
<p>Before we go on to talk about the Euclidean Algorithm, though, we first need a
result concerning divisors. Here it comes:</p>
<p>Let <span class="math">\(a, b, d \in \mathbb{Z}\)</span>, and suppose that <span class="math">\(d \mid a\)</span> and that
<span class="math">\(d \mid b\)</span>.  Then, <span class="math">\(d \mid ma + nb\)</span> for any <span class="math">\(m, n \in
\mathbb{Z}\)</span>.</p>
<p>To prove this, we go back to the definition; we just need to find an integer
<span class="math">\(c\)</span> such that <span class="math">\(cd = ma + nb\)</span>. How might we go about that? Well we
already know that <span class="math">\(d \mid a\)</span>, so we know that there is an integer
<span class="math">\(c_1\)</span> such that <span class="math">\(c_1d = a\)</span>. We also know that <span class="math">\(d \mid b\)</span>, so
we know that there is another integer <span class="math">\(c_2\)</span> such that <span class="math">\(c_2d = b\)</span>.
It follows, then, that <span class="math">\(mc_1d = ma\)</span>, and that <span class="math">\(nc_2d = nb\)</span>. Add
these equations together and you get <span class="math">\(mc_1d + nc_2d = ma + nb\)</span>. The
distributive law allows us to rearrange the left hand side, yielding
<span class="math">\((mc_1 + nc_2)d = ma + nb\)</span>, from which we can immediately deduce that
<span class="math">\(d \mid ma + nb\)</span>.</p>
</div>
<div class="section" id="id1">
<h4>The Euclidean Algorithm<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>We will start by working through an example; suppose we want to find the
greatest common divisor of <span class="math">\(a = 1071\)</span> and <span class="math">\(b = 462\)</span>. Let’s call
their greatest common divisor <span class="math">\(d\)</span>. So immediately we have that <span class="math">\(d
\mid 1071\)</span> and that <span class="math">\(d \mid 462\)</span>.</p>
<p>We start by dividing <span class="math">\(a\)</span> by <span class="math">\(b\)</span>:</p>
<div class="math">
\[1071 = 2 * 462 + 147\]</div>
<p>That is, we get a quotient of <span class="math">\(2\)</span> and a remainder of <span class="math">\(147\)</span>. How
does this help? Well, we now know that <span class="math">\(147 = 1071 - 2*462\)</span>. Using the
result from a moment ago, if we choose <span class="math">\(m = 1\)</span> and <span class="math">\(n = -2\)</span>, we
have that <span class="math">\(d \mid ma + nb\)</span>, that is, <span class="math">\(d \mid 147\)</span>.</p>
<p>We now divide <span class="math">\(462\)</span> by the remainder:</p>
<div class="math">
\[462 = 3 * 147 + 21\]</div>
<p>Using the same argument as before, we see that <span class="math">\(21 = 462 - 3*147\)</span> and
therefore <span class="math">\(d \mid 21\)</span>. We now divide our previous remainder by our new
remainder:</p>
<div class="math">
\[147 = 7 * 21\]</div>
<p>This time, it goes exactly. The significance of this is that we have found our
GCD: it is <span class="math">\(21\)</span>. Why? Well, starting from the final step and working
backwards, we now know that <span class="math">\(21 \mid 147\)</span>. Looking to the previous step,
since <span class="math">\(21 \mid 147\)</span> and <span class="math">\(21 \mid 21\)</span> (note that any integer divides
itself), we can deduce using that same result from a moment ago that <span class="math">\(21
\mid 3 * 147 + 21\)</span> i.e. <span class="math">\(21 \mid 462\)</span>. Now going back to the very first
step, we can use a similar argument to show that since <span class="math">\(21 \mid 462\)</span> and
<span class="math">\(21 \mid 147\)</span>, we have that <span class="math">\(21 \mid 1071\)</span>. So we have established
that <span class="math">\(21\)</span> is a common divisor of <span class="math">\(1071\)</span> and <span class="math">\(462\)</span>. It then
follows that <span class="math">\(d \geq 21\)</span>.</p>
<p>The only way that we can have <span class="math">\(d \geq 21\)</span> and <span class="math">\(d \mid 21\)</span>
simultaneously is if <span class="math">\(d = 21\)</span>, so we’re done.</p>
<p>So the general form of the algorithm is that we keep dividing successive
remainders into each other until we find a pair that go exactly, and then the
last remainder is the greatest common divisor. In PureScript:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>gcd :: Int -&gt; Int -&gt; Int
gcd a 0 = a
gcd a b = gcd b (a `mod` b)
</pre></div>
</div>
<p>(note that <code class="docutils literal"><span class="pre">a</span> <span class="pre">`mod`</span> <span class="pre">b</span></code> computes the remainder when dividing <code class="docutils literal"><span class="pre">a</span></code> by <code class="docutils literal"><span class="pre">b</span></code>.)</p>
<p><strong>Exercise 9.1.</strong> Perform the Euclidean Algorithm on <span class="math">\(a = 1938\)</span>, <span class="math">\(b
= 782\)</span>.</p>
<p>How do we know that the algorithm terminates, though? We refer to the theorem
from the beginning of the chapter:</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If we have two integers <span class="math">\(a, b\)</span>, with <span class="math">\(b &gt; 0\)</span>, then there always
exists a pair of integers <span class="math">\(q\)</span> and <span class="math">\(r\)</span> such that <span class="math">\(a = qb + r\)</span>,
and <span class="math">\(0 \leq r &lt; b\)</span>.</p>
</div>
<p>In particular, <span class="math">\(r &lt; b\)</span>. That is, the remainders <em>keep getting smaller</em>.
A sequence of nonnegative integers which keep getting smaller is guaranteed to
eventually reach <span class="math">\(0\)</span>, so we know that our algorithm will always terminate
and all is well.</p>
</div>
</div>
<span id="document-polynomials"></span><div class="section" id="polynomials">
<h3>Polynomials<a class="headerlink" href="#polynomials" title="Permalink to this headline">¶</a></h3>
<p>It is time to meet yet another example of a ring.</p>
<p>A <em>polynomial</em> is a finite collection of <em>terms</em>, all added together, where
each term is formed of a product of two things: the <em>coefficient</em>, and the
<em>variable</em>, usually <span class="math">\(x\)</span>, raised to a non-negative integer power.  For
example, the following are all polynomials:</p>
<div class="math">
\[\begin{split}&amp;3 \\
&amp;x \\
&amp;3x + 2 \\
&amp;5x^2 + 2x + 4 \\
&amp;x^3 + 1\end{split}\]</div>
<p>Looking again at the example <span class="math">\(5x^2 + 2x + 4,\)</span> we see that it has three
terms: namely, <span class="math">\(5x^2, 2x,\)</span> and <span class="math">\(4\)</span>. The coefficients of these terms
are <span class="math">\(5, 2,\)</span> and <span class="math">\(4\)</span> respectively.</p>
<p>The <em>degree</em> of a polynomial is the highest power of <span class="math">\(x\)</span> appearing. So
for example, the degree of <span class="math">\(5x^2 + 2x + 4\)</span> is <span class="math">\(2\)</span>, and the degree
of <span class="math">\(x^3 + 1\)</span> is <span class="math">\(3\)</span>. We write <span class="math">\(\deg(p)\)</span> for the degree of a
polynomial <span class="math">\(p\)</span>, so e.g. <span class="math">\(\deg(5x^2 + 2x + 4) = 2\)</span>.</p>
<p>The coefficient of the term with the highest power is also important and
therefore has a special name: it is called the <em>leading coefficient</em>. For
example, the leading coefficient of the polynomial <span class="math">\(5x^2 + 2x + 4\)</span> is
<span class="math">\(5\)</span>. A <em>monic</em> polynomial is a polynomial whose leading coefficient is
<span class="math">\(1\)</span>.</p>
<p>Polynomial addition and multiplication both work how you would expect. To add
two polynomials together, we simply add together the coefficients of matching
pairs of terms. So for example, we add together the coefficients of <span class="math">\(x\)</span>
to obtain the coefficient of <span class="math">\(x\)</span> in the result, we add the coefficients
of <span class="math">\(x^2\)</span> to obtain the coefficient of <span class="math">\(x^2\)</span> in the
result, and so on.  For example:</p>
<div class="math">
\[\begin{split}(5x^2 + 2x + 4) + (3x + 2)
&amp;= (5+0)x^2 + (2+3)x + (4+2) \\
&amp;= 5x^2 + 5x + 6\end{split}\]</div>
<p>To multiply polynomials of just one term, we multiply the coefficients and add
the powers. For example, <span class="math">\((6x)(7x^2) = (6 \times 7)x^{1 + 2} = 42x^3\)</span>. To
multiply polynomials with more than one term, we make use of distributivity to
break them down into sums of products of single terms, and then combine them.
For example:</p>
<div class="math">
\[\begin{split}&amp;(5x^2 + 2x + 4)(3x + 2) \\
&amp;= 5x^2(3x + 2) + 2x(3x + 2) + 4(3x + 2) \\
&amp;= (5x^2)(3x) + (5x^2)(2) + (2x)(3x) + (2x)(2) + 4(3x) + 4(2) \\
&amp;= 15x^3 + 10x^2 + 6x^2 + 4x + 12x + 8 \\
&amp;= 15x^3 + 16x^2 + 16x + 8\end{split}\]</div>
<p>In the examples we have seen so far, the coefficients have come from
<span class="math">\(\mathbb{R}\)</span>. However, we can choose coefficients from any ring. We
denote the set of polynomials with coefficients in some ring <span class="math">\(R\)</span> by
<span class="math">\(R[x]\)</span>.</p>
<p>So, if we let <span class="math">\(R\)</span> be any ring, then <span class="math">\(R[x]\)</span> is a ring too; the
additive and multiplicative identities in <span class="math">\(R[x]\)</span> are <span class="math">\(0_R\)</span> and
<span class="math">\(1_R\)</span> respectively. Notice that if <span class="math">\(R\)</span> is a commutative ring, then
so is <span class="math">\(R[x]\)</span>; this follows from how multiplication is defined in
<span class="math">\(R[x]\)</span>.</p>
<p>Here are some polynomials in the ring <span class="math">\(\mathbb{Z}_3[x]\)</span>:</p>
<div class="math">
\[\begin{split}&amp;\overline{2} \\
&amp;x^3 + \overline{2} \\
&amp;\overline{2}x^2 + x + \overline{1}\end{split}\]</div>
<p>Note that we usually don’t bother writing down the coefficient if it is the
multiplicative identity; the second example there could also have been written
<span class="math">\(\overline{1}x^3 + \overline{2}\)</span>.</p>
<p>We have already seen that <span class="math">\(R\)</span> being a commutative ring implies that
<span class="math">\(R[x]\)</span> is a commutative ring. Another similar result is that if <span class="math">\(R\)</span>
has no zero-divisors then neither does <span class="math">\(R[x]\)</span>. To see this, first notice
that if <span class="math">\(p, q \in R[x],\)</span> with <span class="math">\(p \neq 0, q \neq 0,\)</span> the leading
coefficient of <span class="math">\(pq\)</span> is equal to the product of the leading coefficients
of <span class="math">\(p\)</span> and <span class="math">\(q\)</span>. If a polynomial is nonzero then its leading
coefficient is necessarily also nonzero, so it follows that the leading
coefficients of <span class="math">\(p\)</span> and <span class="math">\(q\)</span> are both nonzero, and therefore the
leading coefficient of <span class="math">\(pq\)</span> is also nonzero (here we are using the fact
that <span class="math">\(R\)</span> has no zero-divisors). So <span class="math">\(pq\)</span> is nonzero, and we are
done.</p>
<p>We can neatly wrap all of this up by simply saying that if <span class="math">\(R\)</span> is an
integral domain then so is <span class="math">\(R[x]\)</span>.</p>
<div class="section" id="polynomial-division">
<h4>Polynomial division<a class="headerlink" href="#polynomial-division" title="Permalink to this headline">¶</a></h4>
<p>Consider the ring of polynomials with coefficients in some integral domain
<span class="math">\(R\)</span>. Let <span class="math">\(a, b \in R[x]\)</span>, with <span class="math">\(b \neq 0\)</span>, and <span class="math">\(b\)</span>
monic. Then, there exists <span class="math">\(q, r \in R[x]\)</span> such that <span class="math">\(a = qb + r\)</span>,
and either <span class="math">\(\deg(r) &lt; \deg(b)\)</span>, or <span class="math">\(r = 0\)</span>.</p>
<p>Depending on your philosophy, it might or might not be a problem that the
following proof of this result is non-constructive, i.e. it proves that
<span class="math">\(q\)</span> and <span class="math">\(r\)</span> exist, but it doesn’t give you an algorithm for finding
them. It’s also a little trickier than many of the proofs we’ve seen so far, so
don’t worry if you can’t quite get your head around it straight away.  We won’t
go on to do anything that requires understanding this proof; we really just
want to make sure we’re aware of the result.</p>
<p>Anyway, to prove this result, we start by choosing a polynomial <span class="math">\(q\)</span> which
ensures that the degree of <span class="math">\(a - qb\)</span> is as small as possible. Note that it
is always possible to find such a polynomial <span class="math">\(q\)</span>, because the degree is a
nonnegative integer, and any set of nonnegative integers is guaranteed to have
a smallest element.</p>
<p>Let <span class="math">\(s = \deg(a - qb)\)</span>, and let <cite>c</cite> be the leading coefficient of
<span class="math">\(a - qb\)</span>. So the leading term of <span class="math">\(a - qb\)</span> is <span class="math">\(cx^s\)</span>. Also,
let <span class="math">\(d = \deg(b)\)</span>.</p>
<p>Now, suppose that <span class="math">\(s \geq d\)</span>, and consider the polynomial <span class="math">\(a - (q +
cx^{s-d})b = a - qb - (cx^{s-d})b\)</span>. Since the leading term of <span class="math">\(b\)</span> is
<span class="math">\(x^d\)</span> (by assumption), the leading term of <span class="math">\((cx^{s-d})b\)</span> is
<span class="math">\(cx^s\)</span>. Therefore, when we subtract <span class="math">\((cx^{s-d})b\)</span> from <span class="math">\(a -
qb\)</span>, the <span class="math">\(x^s\)</span> terms cancel and the polynomial we are left with has
degree no higher than <span class="math">\(s-1\)</span>. This is a contradiction: we chose <span class="math">\(q\)</span>
to minimise the degree of <span class="math">\(a - qb\)</span>, but here we have another polynomial
<span class="math">\(q + cx^{s-d}\)</span>, for which <span class="math">\(a - (q + cx^{s-d})b\)</span> gives us a smaller
degree still.</p>
<p>Because we have reached a contradiction, we can deduce that <span class="math">\(s &lt; d\)</span>, i.e.
<span class="math">\(\deg(a - qb) &lt; \deg(s)\)</span>. Therefore, we can define <span class="math">\(r = a - qb\)</span>,
and we are done: <span class="math">\(a = qb + r\)</span> by construction, and also either <span class="math">\(r =
0\)</span> or <span class="math">\(\deg(r) &lt; \deg(b)\)</span>.</p>
<p>If we want to allow division by any nonzero polynomial, not just monic
polynomials, we need to impose one additional requirement: that <span class="math">\(R\)</span> is a
field. In this case we can divide coefficients exactly, so if we want to divide
a polynomial <span class="math">\(a\)</span> by another polynomial <span class="math">\(b\)</span>, we can multiply
<span class="math">\(b\)</span> by the multiplicative inverse of its leading coefficient to make it
monic.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">For example, in <span class="math">\(\mathbb{R}[x]\)</span>, we can multiply the polynomial
<span class="math">\(2x + 1\)</span> by <span class="math">\(\frac{1}{2}\)</span> to give <span class="math">\(x + \frac{1}{2}\)</span>, which
is monic. Note that we could not do this if we were working in
<span class="math">\(\mathbb{Z}[x]\)</span>, since <span class="math">\(\frac{1}{2}\)</span> is not an integer.</p>
</div>
<p>Let <span class="math">\(c\)</span> be the leading coefficient of <span class="math">\(b\)</span>, so that <span class="math">\(c^{-1}b\)</span>
is monic. Now we can use the previous result to divide <span class="math">\(a\)</span> by
<span class="math">\(c^{-1}b\)</span>, which tells us that there are <span class="math">\(q\)</span> and <span class="math">\(r\)</span> such
that <span class="math">\(a = c^{-1}bq + r\)</span>, with either <span class="math">\(\deg(r) &lt; \deg(b)\)</span> or
<span class="math">\(r = 0\)</span>. With a small shift in perspective we can now say that we have
divided <span class="math">\(a\)</span> by <span class="math">\(b\)</span>, by considering the quotient to be
<span class="math">\(c^{-1}q\)</span>.</p>
<p>So the final form of our polynomial division theorem is as follows.</p>
<p>Let <span class="math">\(F\)</span> be a field, and let <span class="math">\(a, b \in F[x]\)</span>, with <span class="math">\(b \neq 0\)</span>.
Then, there exists <span class="math">\(q, r \in F[x]\)</span> such that <span class="math">\(a = qb + r\)</span>, and
either <span class="math">\(\deg(r) &lt; \deg(b)\)</span>, or <span class="math">\(r = 0\)</span>.</p>
<p>The important thing to notice is that this theorem bears a strong resemblance
to the theorem regarding integer division which we saw in the previous chapter.
So now we might ask: is there a generalisation which can unify these two
concepts? The answer is of course yes: it’s called a <em>euclidean ring</em>.</p>
</div>
</div>
<span id="document-euclidean-rings"></span><div class="section" id="euclidean-rings">
<h3>Euclidean rings<a class="headerlink" href="#euclidean-rings" title="Permalink to this headline">¶</a></h3>
<p>Over the previous two chapters, we covered the Euclidean Algorithm, which
allows you to compute the greatest common divisor of two integers. We also
encountered a new example of a ring, namely polynomials, and noticed that they
both support a very similar kind of division.</p>
<p>In this chapter we will see how to generalise the Euclidean Algorithm and
discuss the resulting structure, which is called a <em>euclidean ring</em>.</p>
<div class="section" id="divisors-again">
<h4>Divisors, again<a class="headerlink" href="#divisors-again" title="Permalink to this headline">¶</a></h4>
<p>Instead of working in <span class="math">\(\mathbb{Z}\)</span> we will now work in an arbitrary
integral domain <span class="math">\(R\)</span>. The first thing we will want to do is generalise our
definition of “divisor”; fortunately this is easy:</p>
<p>Let <span class="math">\(a, b \in R\)</span>. We say that <span class="math">\(a\)</span> divides <span class="math">\(b\)</span> if there exists
some <span class="math">\(q \in R\)</span> such that <span class="math">\(aq = b\)</span>.</p>
<p>In fact it’s the exact same definition except that we just replace
<span class="math">\(\mathbb{Z}\)</span> with <span class="math">\(R\)</span>. The definition of “common divisors” also
immediately generalises with no extra effort required. However, it’s less
obvious how to define a <em>greatest</em> common divisor, since we might not be able
to say whether whether an element of an arbitrary integral domain is greater
than some other element. We address this as follows:</p>
<p>Let <span class="math">\(a, b, d \in R\)</span> and suppose <span class="math">\(d \mid a\)</span> and also <span class="math">\(d \mid
b\)</span>, that is, <span class="math">\(d\)</span> is a common divisor of <span class="math">\(a\)</span> and <span class="math">\(b\)</span>. We say
that <span class="math">\(d\)</span> is a <em>greatest common divisor</em> of <span class="math">\(a\)</span> and <span class="math">\(b\)</span> if
for any other common divisor <span class="math">\(d'\)</span> of <span class="math">\(a\)</span> and <span class="math">\(b\)</span>, we have
that <span class="math">\(d' \mid d\)</span>.</p>
<p>Note that we have started saying “<em>a</em> greatest common divisor” rather than
“<em>the</em> greatest common divisor”; this is because greatest common divisors are
no longer guaranteed to be unique. For example, in the previous chapter we saw
that a greatest common divisor of <span class="math">\(462\)</span> and <span class="math">\(1071\)</span> was <span class="math">\(21\)</span>.
In this setting we would also consider <span class="math">\(-21\)</span> to be a greatest common
divisor of these two numbers.</p>
<p>I wouldn’t blame you if, at this point, you said this was a nonsense
definition, because it’s not clear that “greatest” really means anything at
this point. Don’t worry — we will clear this all up shortly.</p>
</div>
<div class="section" id="generalising-the-euclidean-algorithm">
<h4>Generalising the Euclidean Algorithm<a class="headerlink" href="#generalising-the-euclidean-algorithm" title="Permalink to this headline">¶</a></h4>
<p>In the last chapter we saw two key ideas which the Euclidean Algorithm relies
on to work:</p>
<ol class="arabic simple">
<li>For <span class="math">\(a, b, d \in \mathbb{Z}\)</span>, if <span class="math">\(d \mid a\)</span> and <span class="math">\(d \mid b\)</span>,
then <span class="math">\(d \mid ma + nb\)</span> for any <span class="math">\(m, n \in \mathbb{Z}\)</span>.</li>
<li>Remainders keep getting smaller, and are guaranteed to eventually reach
<span class="math">\(0\)</span>.</li>
</ol>
<p>It’s very pleasing to see that the first of these immediately generalises from
<span class="math">\(\mathbb{Z}\)</span> to an arbitrary integral domain. We can even use the exact
same proof as we did in the case of <span class="math">\(\mathbb{Z}\)</span>!</p>
<p>However, we can’t generalise the second idea if all we have is an integral
domain — we need something a little stronger.</p>
<p>Let <span class="math">\(R\)</span> be an integral domain. A <em>euclidean function</em> is a function
<span class="math">\(f : R \setminus \{ 0 \} \rightarrow \mathbb{N}\)</span> satisfying:</p>
<ul class="simple">
<li>For <span class="math">\(a\)</span> and <span class="math">\(b\)</span> in <span class="math">\(R\)</span>, with <span class="math">\(b \neq 0\)</span>, there exist
<span class="math">\(q\)</span> and <span class="math">\(r\)</span> in <span class="math">\(R\)</span> such that <span class="math">\(a = bq + r\)</span> and either
<span class="math">\(r = 0\)</span> or <span class="math">\(f(r) &lt; f(b)\)</span>.</li>
<li>For all nonzero <span class="math">\(a\)</span> and <span class="math">\(b\)</span> in <span class="math">\(R\)</span>, we have <span class="math">\(f(a)
\leq f(ab)\)</span>.</li>
</ul>
<p>A <em>euclidean ring</em>, or <em>euclidean domain</em>, is then defined as an integral
domain which can be endowed with a euclidean function.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>On notation: if <span class="math">\(A\)</span> and <span class="math">\(B\)</span> are sets then their <em>difference</em> is
defined as</p>
<div class="math">
\[A \setminus B = \{\, x \in A \,|\, x \notin B \,\}\]</div>
<p class="last">that is, the elements of <span class="math">\(A\)</span> which are not in <span class="math">\(B\)</span>. So if <span class="math">\(R\)</span>
is a ring, then the set <span class="math">\(R \setminus \{0\}\)</span> consists of all elements of
<span class="math">\(R\)</span> except <span class="math">\(0\)</span>. Essentially, what we are doing here is saying that
for a euclidean function <span class="math">\(f\)</span>, the result of applying <span class="math">\(f\)</span> to
<span class="math">\(0\)</span> need not be defined.</p>
</div>
<p>The idea of this definition is that it allows us to say when “remainders
keep getting smaller” still holds in a more general setting. If we perform the
Euclidean Algorithm on a pair of elements <span class="math">\(a, b\)</span> from an arbitrary
euclidean ring, then the first remainder <span class="math">\(r_1\)</span> will be smaller than
<span class="math">\(b\)</span> in the sense that <span class="math">\(f(r_1) &lt; f(b)\)</span>, and the second remainder
<span class="math">\(r_2\)</span> will be smaller than <span class="math">\(r_1\)</span> in the sense that <span class="math">\(f(r_2) &lt;
f(r_1)\)</span>, and so on until we reach <span class="math">\(0\)</span>.</p>
<p>So now we’re done — we can use what is essentially the same argument as in the
case of integers to show that our GCD algorithm actually works with any
euclidean ring!</p>
<p>We still need to verify that integers and polynomials do actually form
euclidean rings, though, and to do this we need to find euclidean functions for
each of them.</p>
<p>Cast your mind back one more time to the theorem about integer division:</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If we have two integers <span class="math">\(a, b\)</span>, with <span class="math">\(b &gt; 0\)</span>, then there always
exists a pair of integers <span class="math">\(q\)</span> and <span class="math">\(r\)</span> such that <span class="math">\(a = qb +
r\)</span>, and <span class="math">\(0 \leq r &lt; b\)</span>.</p>
</div>
<p>This is almost in the right form for us to show that <span class="math">\(\mathbb{Z}\)</span> is a
euclidean ring, but not quite. In particular we need to be able to deal any
nonzero <span class="math">\(b\)</span>, not just positive <span class="math">\(b\)</span>.</p>
<p>We can address this with the <em>absolute value function</em>. For any <span class="math">\(x \in
\mathbb{R}\)</span>, the absolute value of <span class="math">\(x\)</span> is defined as:</p>
<div class="math">
\[\begin{split}\lvert x \rvert = \begin{cases}
                    x  &amp; \mathrm{if} \; x \geq 0 \\
                    -x &amp; \mathrm{if} \; x &lt; 0
                  \end{cases}\end{split}\]</div>
<p>Note that for any real number <span class="math">\(x\)</span>, the absolute value of <span class="math">\(x\)</span> is
always nonnegative. Also, again for any real number <span class="math">\(x\)</span>, note that
<span class="math">\(\lvert x \rvert = \lvert -x \rvert\)</span> (check this if you need to).</p>
<p>We can prove that the absolute value function is a euclidean function on
<span class="math">\(\mathbb{Z}\)</span> by cases. First, we will cover the case where <span class="math">\(b &gt; 0\)</span>,
and then we will cover the case where <span class="math">\(b &lt; 0\)</span>.</p>
<p>In the case where <span class="math">\(b &gt; 0,\)</span> we already know that we can find an
appropriate <span class="math">\(r\)</span> with <span class="math">\(0 \leq r &lt; b;\)</span> since <span class="math">\(r\)</span> and <span class="math">\(b\)</span>
are both nonnegative, we must have <span class="math">\(r = \lvert r \rvert\)</span> and <span class="math">\(b =
\lvert b \rvert,\)</span> so <span class="math">\(\lvert r \rvert &lt; \lvert b \rvert\)</span> as required. In
the case where <span class="math">\(b &lt; 0,\)</span> we know that <span class="math">\(-b\)</span> is positive, so we can
divide <span class="math">\(a\)</span> by <span class="math">\(-b\)</span> and get a <span class="math">\(q\)</span> and <span class="math">\(r\)</span> satisfying
<span class="math">\(a = q(-b) + r\)</span> and <span class="math">\(0 \leq r &lt; -b\)</span>.  Rearranging a little, we can
write <span class="math">\(a = (-q)b + r,\)</span> showing that our quotient is <span class="math">\(-q\)</span> and our
remainder <span class="math">\(r\)</span>. We also have that <span class="math">\(r &lt; -b,\)</span> so <span class="math">\(\lvert r
\rvert &lt; \lvert -b \rvert,\)</span> and of course <span class="math">\(\lvert -b \rvert = \lvert b
\rvert,\)</span> so again <span class="math">\(\lvert r \rvert &lt; \lvert b \rvert\)</span> as required.</p>
<p><strong>Exercise 11.1.</strong> Complete the proof that the absolute value function is a
euclidean function on <span class="math">\(\mathbb{Z}\)</span> by showing that <span class="math">\(\lvert a \rvert
\leq \lvert ab \rvert\)</span> for all nonzero <span class="math">\(a, b \in \mathbb{Z}\)</span>.</p>
<p>Polynomials are a bit easier, since our polynomial division theorem is already
in the correct form; looking back at the theorem from the previous chapter:</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Let <span class="math">\(F\)</span> be a field, and let <span class="math">\(a, b \in F[x]\)</span>, with <span class="math">\(b \neq
0\)</span>. Then, there exists <span class="math">\(q, r \in F[x]\)</span> such that <span class="math">\(a = qb + r\)</span>,
and either <span class="math">\(\deg(r) &lt; \deg(b)\)</span>, or <span class="math">\(r = 0\)</span>.</p>
</div>
<p>So the degree function satisfies the first condition for being a euclidean
function.</p>
<p><strong>Exercise 11.2.</strong> Complete the proof that the degree function is a euclidean
function on <span class="math">\(F[x]\)</span> by showing that <span class="math">\(\deg(a) \leq \deg(ab)\)</span> for all
nonzero <span class="math">\(a, b \in F[x]\)</span>. Hint: can you find an expression for
<span class="math">\(\deg(ab)\)</span> in terms of <span class="math">\(\deg(a)\)</span> and <span class="math">\(\deg(b)\)</span>?</p>
<p>So the degree function is a euclidean function on polynomials, and therefore
polynomials are indeed euclidean rings.</p>
<p>There’s one more example of a euclidean ring which we should mention, and that
is any field. Of course, in a field, you can always divide exactly, so this
isn’t the most interesting example of a euclidean ring — but it’s good to be
aware of nonetheless.</p>
<p>Let <span class="math">\(F\)</span> be a field, and suppose <span class="math">\(f : F \setminus \{ 0 \}
\rightarrow \mathbb{N}\)</span> is a euclidean function. Recall the second condition
for being a euclidean function, which is that for all nonzero <span class="math">\(a, b \in
F\)</span>, we have that <span class="math">\(f(a) \leq f(ab)\)</span>. Let <span class="math">\(x\)</span> be any element of
<span class="math">\(F\)</span>. If we set <span class="math">\(a = 1\)</span> and <span class="math">\(b = x\)</span> then we see that
<span class="math">\(f(1) \leq f(x)\)</span>.  Also, since <span class="math">\(F\)</span> is a field, <span class="math">\(x\)</span> must have
a multiplicative inverse, <span class="math">\(x^{-1}\)</span>. So if we set <span class="math">\(a = x\)</span> and
<span class="math">\(b = x^{-1}\)</span> we see that <span class="math">\(f(x) \leq f(1)\)</span>. The only way that both
of these things can be true is if <span class="math">\(f(x) = f(1)\)</span>, that is, <span class="math">\(f\)</span> is
constant: it always gives us back the same thing, no matter what we put in.</p>
<p>Now, we look back to the first condition, which says that for all nonzero
<span class="math">\(a, b \in F\)</span>, there exist <span class="math">\(q, r \in F\)</span> such that <span class="math">\(a = qb + r\)</span>
and either <span class="math">\(r = 0\)</span> or <span class="math">\(f(r) &lt; f(b)\)</span>. However, since <span class="math">\(f\)</span> is
constant, there is no pair of elements <span class="math">\(r, b \in F\)</span> such that <span class="math">\(f(r)
&lt; f(b)\)</span>. What this means is that whenever we divide two elements, we must
always hit the <span class="math">\(r = 0\)</span> case, i.e. we must always have <span class="math">\(q = ab^{-1}\)</span>
and <span class="math">\(r = 0\)</span>.</p>
<p>Therefore, whenever we try to run our GCD algorithm, it always terminates
immediately. In fact every single element of a field (apart from <span class="math">\(0\)</span>) is
a “greatest common divisor” of any pair of elements (I put “greatest common
divisor” in quotes here, because in this context it breaks down, and doesn’t
really mean anything any more). But we have established an interesting fact
nonetheless: for any field, the <em>only option</em> for a euclidean function is a
constant function, which means that no field can have any euclidean ring
structure other than this rather uninteresting one.</p>
</div>
<div class="section" id="summary">
<h4>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h4>
<p>The answer to the question “what is a euclidean ring” of course is the
definition; there’s no substitute for it, that is what a euclidean ring is.
However it’s often useful to have an intuitive understanding to go along with
actual definition of what something is, and allowing you to develop this
intuition has been my aim in these last three chapters. My intuitive
understanding of a euclidean ring is a ring which behaves “a bit like the
integers”, in the sense that</p>
<ul class="simple">
<li>elements can be divided to give a quotient and a remainder,</li>
<li>any pair of elements has at least one greatest common divisor, in the sense
that any other common divisor divides a GCD,</li>
<li>it has a euclidean function which tells you the “size” of an element (and
this sense of “size” is exactly same as the sense of “greatest” in “greatest
common divisor”)</li>
<li>the Euclidean Algorithm can be used to find a GCD of any two elements of the
ring.</li>
</ul>
</div>
</div>
<span id="document-quaternions"></span><div class="section" id="quaternions">
<h3>Quaternions<a class="headerlink" href="#quaternions" title="Permalink to this headline">¶</a></h3>
<p>It is time to introduce you to the example I mentioned earlier of a division
ring which is not a field. This division ring is called the <em>quaternions</em>,
and it has important applications in 3D graphics and orbital mechanics of
satellites, due to its ability to represent orientations and rotations of
objects in three dimensions in a simple and efficient way.</p>
<p>The quaternions were first described in 1843 by William Rowan Hamilton, from
whom they take their notation: the ring of quaternions is often denoted by
<span class="math">\(\mathbb{H}\)</span>, for Hamilton (perhaps because <span class="math">\(\mathbb{Q}\)</span> was
already taken by the rationals).</p>
<p>The quaternions can be seen as an extension of the complex numbers in a similar
sense that the complex numbers can be seen as an extension of the real numbers.
Where complex numbers can be written <span class="math">\(a + bi\)</span>, where <span class="math">\(a\)</span> and
<span class="math">\(b\)</span> are real numbers, and <span class="math">\(i\)</span> is the ‘imaginary unit’ satisfying
<span class="math">\(i^2 = -1\)</span>, quaternions can be written <span class="math">\(a + bi + cj + dk\)</span>, where
<span class="math">\(a, b, c,\)</span> and <span class="math">\(d\)</span> are real numbers, and <span class="math">\(i, j,\)</span> and
<span class="math">\(k\)</span> are each different ‘imaginary units’. Addition is simple enough; as
with complex numbers, we add component-wise:</p>
<div class="math">
\[ \begin{align}\begin{aligned}(a + bi + cj + dk) + (e + fi + gj + hk)\\= (a+e) + (b+f)i + (c+g)j + (d+h)k\end{aligned}\end{align} \]</div>
<p>Multiplication is a little more complex, but it follows from the fact that the
imaginary units <span class="math">\(i, j\)</span> and <span class="math">\(k\)</span> satisfy the following equation:</p>
<div class="math">
\[i^2 = j^2 = k^2 = ijk = -1\]</div>
<p>The first thing to note is that the multiplicative inverses of <span class="math">\(i, j,\)</span>
and <span class="math">\(k\)</span> are <span class="math">\(-i, -j,\)</span> and <span class="math">\(-k\)</span> respectively.</p>
<p>The above equation does in fact allow us to work out the product of any two
quaternions. For instance, we can work out what the product <span class="math">\(ij\)</span> is by
starting with the equation <span class="math">\(ijk = -1\)</span> and multiplying both sides by
<span class="math">\(-k\)</span> on the right:</p>
<div class="math">
\[ \begin{align}\begin{aligned}ijk(-k) = -1(-k)\\ij(-k^2) = k\end{aligned}\end{align} \]</div>
<p>and then using the fact that <span class="math">\(-k^2 = 1\)</span>, we obtain <span class="math">\(ij = k\)</span>.</p>
<p>You may be wondering why I specified that we were multiplying by <span class="math">\(-k\)</span> ‘on
the right’. For the more common number systems such as the real or complex
numbers, we don’t need to specify, because multiplying on the left is the same
as multiplying on the right, due to both of these number systems being
commutative rings. Because quaternions are not commutative, it <em>does</em> matter in
this case, so we need to specify.</p>
<p>For example, if we now want to work out the product <span class="math">\(ji\)</span>, we can use the
fact that <span class="math">\((ji)^{-1} = i^{-1} j^{-1}\)</span>. (Look back at Exercise 3.3 if this
is unclear.) Then, we have <span class="math">\((ji)^{-1} = i^{-1} j^{-1} = (-i)(-j) = ij =
k\)</span>. Therefore, <span class="math">\(ji = k^{-1} = -k\)</span>. In particular, <span class="math">\(ij \neq ji\)</span>.</p>
<p>We can derive a complete rule for multiplying quaternions by making use of the
distributive property:</p>
<div class="math">
\[ \begin{align}\begin{aligned}&amp;(a + bi + cj + dk) \cdot (e + fi + gj + hk)\\=\; &amp;ae + afi + agj + ahk\\ &amp;+ bei + bf(i^2) + bg(ij) + bh(ik)\\ &amp;+ cej + cf(ji) + cg(j^2) + ch(jk)\\ &amp;+ dek + df(ki) + dg(kj) + dh(k^2)\\=\; &amp;ae - bf - cg - dh\\ &amp;+ (af + be + ch - dg) i\\ &amp;+ (ag - bh + ce + df) j\\ &amp;+ (ah + bg - cf + de) k\end{aligned}\end{align} \]</div>
<p>The non-commutativity of the quaternions make them a little strange to work
with. However, there are subsets of the quaternions which are easier to deal
with.  You all may be relieved to learn that the quaternions for which
<span class="math">\(c\)</span> and <span class="math">\(d\)</span> are both zero behave identically to the complex
numbers, for instance.</p>
<div class="section" id="multiplicative-inverses">
<h4>Multiplicative inverses<a class="headerlink" href="#multiplicative-inverses" title="Permalink to this headline">¶</a></h4>
<p>Recall that a division ring is a ring in which all non-zero elements have
multiplicative inverses. We have already seen that the multiplicative inverses
of <span class="math">\(i, j,\)</span> and <span class="math">\(k\)</span> are <span class="math">\(-i, -j,\)</span> and <span class="math">\(-k\)</span> respectively,
but what about all the other quaternions?</p>
<p>We can provide a rule for finding the multiplicative inverse of a quaternion
without too much difficulty, although we will first need a couple of
operations.</p>
<p>Firstly, the <em>norm</em> of a quaternion <span class="math">\(q = a + bi + cj + dk\)</span> is defined as</p>
<div class="math">
\[\lVert q \rVert = \sqrt{a^2 + b^2 + c^2 + d^2}\]</div>
<p>(notice that the norm is always a nonnegative real number). Secondly, the
<em>conjugate</em> <span class="math">\(\bar q\)</span> of a quaternion <span class="math">\(q = a + bi + cj + dk\)</span> is
defined as <span class="math">\(\bar q = a - bi - cj - dk\)</span>; we simply negate <span class="math">\(b, c,\)</span>
and <span class="math">\(d\)</span>.</p>
<p>Then, the multiplicative inverse of a quaternion <span class="math">\(q\)</span> is given by</p>
<div class="math">
\[q^{-1} = \frac{\bar q}{\lVert q \rVert^2}\]</div>
<p>You can check this if you really want, but I haven’t set it as an exercise
because it’s a bit tedious. The important thing to remember is that for any
quaternion <span class="math">\(q\)</span>, we have that <span class="math">\(qq^{-1} = q^{-1}q = 1\)</span>.</p>
</div>
<div class="section" id="dividing-quaternions">
<h4>Dividing quaternions<a class="headerlink" href="#dividing-quaternions" title="Permalink to this headline">¶</a></h4>
<p>The non-commutativity of quaternion multiplication makes defining a division
operation for quaternions a little thorny. With fields, we can define division
as follows:</p>
<div class="math">
\[a / b = ab^{-1}\]</div>
<p>But with quaternions, we have two options for the operation of dividing
<span class="math">\(a\)</span> by <span class="math">\(b\)</span>: either <span class="math">\(ab^{-1}\)</span> or <span class="math">\(b^{-1}a\)</span>; these two
choices will give us different results for most choices of <span class="math">\(a\)</span> and
<span class="math">\(b\)</span>.</p>
<p>My understanding is that there is no strong reason to prefer one over the
other, so instead we have to come up with a name for each of them so that
people know which one we are talking about; these names are ‘right division’
and ‘left division’ respectively. (I can never remember which one is
which.)</p>
<p>Both of these operations are defined in the <code class="docutils literal"><span class="pre">Data.DivisionRing</span></code> module, which
is part of the Prelude.</p>
</div>
<div class="section" id="using-quaternions-for-rotations">
<h4>Using quaternions for rotations<a class="headerlink" href="#using-quaternions-for-rotations" title="Permalink to this headline">¶</a></h4>
<p>I won’t go into this in too much detail here, but it turns out that a rotation
of <span class="math">\(\theta\)</span> radians about the axis <span class="math">\((x, y, z)\)</span> in 3D space can be
represented by the quaternion</p>
<div class="math">
\[q = \cos \frac{\theta}{2} + \sin \frac{\theta}{2} \big[ xi + yj + zk \big]\]</div>
<p>Now, if we have a point <span class="math">\((a, b, c)\)</span> in 3D space, we can consider it as a
quaternion <span class="math">\(p\)</span> by setting <span class="math">\(p = 0 + ai + bj + ck\)</span>.</p>
<p>If we now want to calculate where the point <span class="math">\(p\)</span> ends up after being
rotated about the origin by the rotation represented by <span class="math">\(q\)</span>, we
calculate:</p>
<div class="math">
\[qpq^{-1}\]</div>
<p>The resulting quaternion will have a zero real part, like <span class="math">\(p\)</span>, and we can
read off the <span class="math">\(i, j,\)</span> and <span class="math">\(k\)</span> coefficients to obtain the point in 3D
space where we end up.</p>
<p>We can also compose rotations easily; if we have two rotations represented by
quaternions <span class="math">\(q_1, q_2\)</span>, then the rotation given by first performing
<span class="math">\(q_1\)</span> and then performing <span class="math">\(q_2\)</span> is simply <span class="math">\(q_2 q_1\)</span>.</p>
</div>
<div class="section" id="further-references">
<h4>Further references<a class="headerlink" href="#further-references" title="Permalink to this headline">¶</a></h4>
<p>If you want to learn more about quaternions and rotations, the Wikipedia
article <a class="reference external" href="https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation">Quaternions and spatial rotation</a>
might be a good place to start.</p>
<p>I also highly recommend the YouTube video <a class="reference external" href="https://www.youtube.com/watch?v=d4EgbgTm0Bg">What are quaternions, and how do you visualize them? A story of four dimensions</a>
by <a class="reference external" href="https://youtube.com/3Blue1Brown">3Blue1Brown</a>.</p>
<p>There is also my PureScript library <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-quaternions">purescript-quaternions</a>,
which provides a Quaternion type, instances, and various operations, as well as
utilities for using quaternions to represent 3D rotations.</p>
</div>
</div>
<span id="document-epilogue"></span><div class="section" id="epilogue">
<h3>Epilogue<a class="headerlink" href="#epilogue" title="Permalink to this headline">¶</a></h3>
<p>If you’ve read the entire thing and understood at least some of it, well done!
This text is essentially a whirlwind tour through some of the best bits of an
undergraduate maths degree, so going through it in a self-directed manner is
no mean feat.</p>
<p>We’ve now seen all of the type classes included in the PureScript numeric
hierarchy together with motivating examples of each. One of my goals in writing
this guide has been to persuade you that it does make sense to define the
numeric hierarchy as we have in PureScript, since it allows much better code
generality and reuse potential when compared to alternative approaches, such as
putting <code class="docutils literal"><span class="pre">.add(other)</span></code> methods on various classes without any type system
support to help us know which properties will be satisfied by objects of a
given class, or worse, reserving the built-in arithmetical operators for
built-in types.</p>
<p>Another benefit of the type class hierarchy approach is that by being based on
mathematical structures which are already very well studied, there is plenty of
information available on them via the web (provided that you have the
background to understand it). This means that it should be easier for us to
determine what the appropriate set of constraints should be for a particular
function.</p>
<p>To give an example, suppose we want to implement the <a class="reference external" href="https://en.wikipedia.org/wiki/Field_of_fractions">field of fractions</a> of
an arbitrary integral domain. The maths tells us that we do in fact need an
integral domain for this to work, so we know that we need to include this as a
constraint somehow. We don’t actually have an integral domain type class in the
PureScript hierarchy, but the closest thing we have which is at least as strong
is <code class="docutils literal"><span class="pre">EuclideanRing</span></code>, so we’ll have to use a <code class="docutils literal"><span class="pre">EuclideanRing</span> <span class="pre">a</span></code> constraint in
our <code class="docutils literal"><span class="pre">CommutativeRing</span> <span class="pre">(Fraction</span> <span class="pre">a)</span></code> and <code class="docutils literal"><span class="pre">DivisionRing</span> <span class="pre">(Fraction</span> <span class="pre">a)</span></code>
instances.</p>
<p>This is just my viewpoint, though. Are you convinced? Have I changed your
mind? Let me know. :)</p>
</div>
<span id="document-appendix/index"></span><div class="section" id="appendix">
<h3>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">¶</a></h3>
<div class="toctree-wrapper compound">
<span id="document-appendix/cheatsheet"></span><div class="section" id="cheatsheet">
<h4>Cheatsheet<a class="headerlink" href="#cheatsheet" title="Permalink to this headline">¶</a></h4>
<p>See also <a class="reference external" href="https://harry.garrood.me/numeric-hierarchy-overview/">the full-size version</a>.</p>
<img alt="_images/hierarchy-cheatsheet.png" src="_images/hierarchy-cheatsheet.png" />
</div>
<span id="document-appendix/purescript-impls"></span><div class="section" id="purescript-implementations-of-objects-discussed-in-this-guide">
<h4>PureScript implementations of objects discussed in this guide<a class="headerlink" href="#purescript-implementations-of-objects-discussed-in-this-guide" title="Permalink to this headline">¶</a></h4>
<p>If you’re finding yourself wanting to use some of the mathematical objects
discussed in this guide, look no further. Many of these objects are implemented
in the core libraries, but for some of them, you’ll have to look a little
further afield.</p>
<p>The information here is correct as of Nov 2018, but could easily change; new
libraries could pop up and replace older ones as the best choice in certain
contexts, libraries could become unmaintained, and so on.</p>
<p><strong>The integers,</strong> <span class="math">\(\mathbb{Z}\)</span>. There are a few options for this:</p>
<ol class="arabic simple">
<li>The <code class="docutils literal"><span class="pre">Int</span></code> type built in to the language. This is not a completely
faithful representation of <span class="math">\(\mathbb{Z}\)</span>, because it’s a 32-bit integer
type, which means that it cannot represent integers outside the range
<span class="math">\([-2^{31}, 2^{31}-1]\)</span>. In fact, since overflow is handled by wrapping
around, this type is actually equivalent to the integers modulo
<span class="math">\(2^{32}\)</span>. While not suitable for representing integers outside this
range, this type has the advantage that interop is the easiest, and also it
will have the best performance.</li>
<li>A wrapper around a JavaScript bigint library, such as <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-bigints">purescript-bigints</a>.</li>
<li>A native implementation of arbitrarily-sized integers: this has the
advantage of being able to work even if you’re not compiling to JS. See e.g.
<a class="reference external" href="https://pursuit.purescript.org/packages/purescript-precise">purescript-precise</a>.</li>
</ol>
<p>There is also work on adding arbitrarily-sized integers to JavaScript: there is
a <a class="reference external" href="https://tc39.github.io/proposal-bigint/">Stage 3 TC39 proposal</a>, and they
<a class="reference external" href="https://developers.google.com/web/updates/2018/05/bigint">have already landed in (at least) Chrome</a>.</p>
<p><strong>The real numbers,</strong> <span class="math">\(\mathbb{R}\)</span>. These are notoriously difficult to
represent in the discrete world of computers, since <span class="math">\(\mathbb{R}\)</span> is such
a monstrously large set that you can’t even pair its elements up with the
elements of <span class="math">\(\mathbb{N}\)</span>. You’ll essentially be forced to compromise and
to work with a simpler set…</p>
<p><strong>The rationals,</strong> <span class="math">\(\mathbb{Q}\)</span>. The rationals are of course infinite,
but unlike the reals, they <em>can</em> in fact be paired up with the natural numbers,
which means you can faithfully represent them on a computer (as long as you
don’t run out of memory). However, it may be prohibitively expensive in time or
memory (or both) to do this.</p>
<ol class="arabic">
<li><p class="first">The <code class="docutils literal"><span class="pre">Number</span></code> type built in to the language, which is a double-precision
IEEE 754 floating point number. This type does of course have a number of
drawbacks, including having counterexamples to pretty much any law or
property which you might expect them to have (e.g. <code class="docutils literal"><span class="pre">0.1</span> <span class="pre">+</span> <span class="pre">0.2</span></code> does not
quite equal <code class="docutils literal"><span class="pre">0.3</span></code>), and being inhabited by values like <code class="docutils literal"><span class="pre">NaN</span></code> and
<code class="docutils literal"><span class="pre">Infinity</span></code> which can have surprising behaviour.</p>
<p>However, they also have a number of important advantages. They are
the default option for almost any work requiring an approximation of
<span class="math">\(\mathbb{R}\)</span>; their operations are implemented in hardware basically
everywhere, making them significantly faster than any other option; they
have predictable performance and memory usage, which is very unlikely to be
true for any other option; and there is already a significant amount of
literature about how to write algorithms in such a way as to avoid their
pitfalls, as well as freely available implementations of these algorithms
(e.g. on the <code class="docutils literal"><span class="pre">Math</span></code> object in JS).</p>
</li>
<li><p class="first">The <code class="docutils literal"><span class="pre">Ratio</span></code> type from <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-rationals">purescript-rationals</a>. When combined with a
big-integer implementation (see above), it gives you a completely faithful
representation of <span class="math">\(\mathbb{Q}\)</span>.</p>
</li>
<li><p class="first">The <code class="docutils literal"><span class="pre">HugeNum</span></code> type from <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-precise">purescript-precise</a>. This will be useful in some
of the same contexts as <code class="docutils literal"><span class="pre">Ratio</span></code>, although it is implemented in a slightly
different way. Division does not yet appear to be implemented in this
library, however.</p>
</li>
</ol>
<p><strong>The natural numbers,</strong> <span class="math">\(\mathbb{N}\)</span>. The library <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-naturals">purescript-naturals</a>
provides a type backed by <code class="docutils literal"><span class="pre">Int</span></code>, which means that it’s perfect provided that
you don’t need to go above <span class="math">\(2^{31}-1\)</span>.</p>
<p><strong>The complex numbers,</strong> <span class="math">\(\mathbb{C}\)</span>. Since this set is essentially
<span class="math">\(\mathbb{R}^2\)</span>, we encounter many of the same issues that we would when
trying to represent <span class="math">\(\mathbb{R}\)</span>. As far as I’m aware, there’s only one
option for these in PureScript: the <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-complex">purescript-complex</a> library (although it
doesn’t appear to be compatible with the latest versions of the core libraries
right now).</p>
<p><strong>Matrices.</strong> There are number of JS libraries you can wrap for this, such as
<a class="reference external" href="http://glmatrix.net">glMatrix</a>, or <a class="reference external" href="https://gitgud.io/unconed/mathbox">MathBox</a>. MathBox in particular has PureScript bindings
already via <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-mathbox">purescript-mathbox</a>.</p>
<p><strong>The quaternions,</strong> <span class="math">\(\mathbb{H}\)</span>. I made a library for these! It’s
<a class="reference external" href="https://pursuit.purescript.org/packages/purescript-quaternions">purescript-quaternions</a>.</p>
<p><strong>Modular arithmetic,</strong> <span class="math">\(\mathbb{Z}_m\)</span> for some integer <span class="math">\(m\)</span>.
I made a library for these too: <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-modular-arithmetic">purescript-modular-arithmetic</a>.</p>
<p><strong>Polynomials,</strong> <span class="math">\(R[x]\)</span> for some ring <span class="math">\(R\)</span>. We’re getting a bit more
exotic now. I would love to hear from you if you have a use case for this
library: <a class="reference external" href="https://pursuit.purescript.org/packages/purescript-polynomials">purescript-polynomials</a>.</p>
<p><strong>The symmetric group,</strong> <span class="math">\(S_n\)</span>. This is also one of mine:
<a class="reference external" href="https://pursuit.purescript.org/packages/purescript-symmetric-groups">purescript-symmetric-groups</a>.</p>
</div>
<span id="document-appendix/solutions"></span><div class="section" id="solutions-to-exercises">
<h4>Solutions to Exercises<a class="headerlink" href="#solutions-to-exercises" title="Permalink to this headline">¶</a></h4>
<div class="toctree-wrapper compound">
<span id="document-appendix/solutions/logic"></span><div class="section" id="logic">
<h5>Logic<a class="headerlink" href="#logic" title="Permalink to this headline">¶</a></h5>
<div class="toctree-wrapper compound">
<span id="document-appendix/solutions/logic/ex1"></span><div class="section" id="exercise-1-1">
<h6>Exercise 1.1<a class="headerlink" href="#exercise-1-1" title="Permalink to this headline">¶</a></h6>
<p>The statement <span class="math">\(P \land Q\)</span> is false, since it would require both <span class="math">\(P\)</span>
and <span class="math">\(Q\)</span> to be true: in this case, <span class="math">\(Q\)</span> is “pigs can fly”, which is
(thankfully) false.</p>
</div>
<span id="document-appendix/solutions/logic/ex2"></span><div class="section" id="exercise-1-2">
<h6>Exercise 1.2<a class="headerlink" href="#exercise-1-2" title="Permalink to this headline">¶</a></h6>
<p>The truth table for <span class="math">\(\lor\)</span> looks like this:</p>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="26%" />
<col width="47%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math">\(P\)</span></th>
<th class="head"><span class="math">\(Q\)</span></th>
<th class="head"><span class="math">\(P \lor Q\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>T</td>
<td>T</td>
<td>T</td>
</tr>
<tr class="row-odd"><td>T</td>
<td>F</td>
<td>T</td>
</tr>
<tr class="row-even"><td>F</td>
<td>T</td>
<td>T</td>
</tr>
<tr class="row-odd"><td>F</td>
<td>F</td>
<td>F</td>
</tr>
</tbody>
</table>
</div>
<span id="document-appendix/solutions/logic/ex3"></span><div class="section" id="exercise-1-3">
<h6>Exercise 1.3<a class="headerlink" href="#exercise-1-3" title="Permalink to this headline">¶</a></h6>
<p>The completed truth table for <span class="math">\(\Leftrightarrow\)</span> looks like this:</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="60%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math">\(P\)</span></th>
<th class="head"><span class="math">\(Q\)</span></th>
<th class="head"><span class="math">\(P \Leftrightarrow Q\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>T</td>
<td>T</td>
<td>T</td>
</tr>
<tr class="row-odd"><td>T</td>
<td>F</td>
<td>F</td>
</tr>
<tr class="row-even"><td>F</td>
<td>T</td>
<td>F</td>
</tr>
<tr class="row-odd"><td>F</td>
<td>F</td>
<td>T</td>
</tr>
</tbody>
</table>
</div>
<span id="document-appendix/solutions/logic/ex4"></span><div class="section" id="exercise-1-4">
<h6>Exercise 1.4<a class="headerlink" href="#exercise-1-4" title="Permalink to this headline">¶</a></h6>
<p>Here is a truth table which might help you understand why the first of De
Morgan’s laws is true:</p>
<table border="1" class="docutils">
<colgroup>
<col width="8%" />
<col width="8%" />
<col width="15%" />
<col width="21%" />
<col width="12%" />
<col width="12%" />
<col width="23%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><span class="math">\(P\)</span></th>
<th class="head"><span class="math">\(Q\)</span></th>
<th class="head"><span class="math">\(P \land Q\)</span></th>
<th class="head"><span class="math">\(\neg (P \land Q)\)</span></th>
<th class="head"><span class="math">\(\neg P\)</span></th>
<th class="head"><span class="math">\(\neg Q\)</span></th>
<th class="head"><span class="math">\(\neg P \lor \neg Q\)</span></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>T</td>
<td>T</td>
<td>T</td>
<td>F</td>
<td>F</td>
<td>F</td>
<td>F</td>
</tr>
<tr class="row-odd"><td>T</td>
<td>F</td>
<td>F</td>
<td>T</td>
<td>F</td>
<td>T</td>
<td>T</td>
</tr>
<tr class="row-even"><td>F</td>
<td>T</td>
<td>F</td>
<td>T</td>
<td>T</td>
<td>F</td>
<td>T</td>
</tr>
<tr class="row-odd"><td>F</td>
<td>F</td>
<td>T</td>
<td>T</td>
<td>T</td>
<td>T</td>
<td>T</td>
</tr>
</tbody>
</table>
<p>Another truth table can be constructed for the other law in a similar way.</p>
</div>
<span id="document-appendix/solutions/logic/ex5"></span><div class="section" id="exercise-1-5">
<h6>Exercise 1.5<a class="headerlink" href="#exercise-1-5" title="Permalink to this headline">¶</a></h6>
<p>This exercise doesn’t really have a solution, as it only asks you to persuade
yourself of a fact.</p>
</div>
<span id="document-appendix/solutions/logic/ex6"></span><div class="section" id="exercise-1-6">
<h6>Exercise 1.6<a class="headerlink" href="#exercise-1-6" title="Permalink to this headline">¶</a></h6>
<p>This exercise doesn’t really have a solution, as it only asks you to persuade
yourself of a fact.</p>
</div>
<span id="document-appendix/solutions/logic/ex7"></span><div class="section" id="exercise-1-7">
<h6>Exercise 1.7<a class="headerlink" href="#exercise-1-7" title="Permalink to this headline">¶</a></h6>
<p>If we take the contrapositive of the statement</p>
<div class="math">
\[x^2 \text{ is odd} \Rightarrow x \text{ is odd}\]</div>
<p>then we should end up with</p>
<div class="math">
\[x \text{ is not odd} \Rightarrow x^2 \text{ is not odd}.\]</div>
<p>A more sensible way of saying “<span class="math">\(x\)</span> is not odd” is to say “<span class="math">\(x\)</span> is
even”, so this statement is equivalent to the statement</p>
<div class="math">
\[x \text{ is even} \Rightarrow x^2 \text{ is even}.\]</div>
<p>And we’ve already proved that this is true, so we are done!</p>
</div>
<span id="document-appendix/solutions/logic/ex8"></span><div class="section" id="exercise-1-8">
<h6>Exercise 1.8<a class="headerlink" href="#exercise-1-8" title="Permalink to this headline">¶</a></h6>
<p>If we start with an equation, we are allowed to do the same thing to both
sides, and we will get another equation which also holds.</p>
<p>Subtracting 4 from both sides gives us</p>
<div class="math">
\[ \begin{align}\begin{aligned}3x = 13 - 4\\3x = 9\end{aligned}\end{align} \]</div>
<p>Now we can divide both sides by 3:</p>
<div class="math">
\[x = 3\]</div>
<p>So we can choose <span class="math">\(x\)</span> to be <span class="math">\(3\)</span> as a suitable value to illustrate
the truth of this statement. In fact <span class="math">\(3\)</span> is the only suitable value in
this case. Note, however, that not all equations have exactly one solution:
some have zero, some have 2 or more, and some have infinitely many.</p>
</div>
<span id="document-appendix/solutions/logic/ex9"></span><div class="section" id="exercise-1-9">
<h6>Exercise 1.9<a class="headerlink" href="#exercise-1-9" title="Permalink to this headline">¶</a></h6>
<p>One example of an <span class="math">\(x \in \mathbb{R}\)</span> for which <span class="math">\(x &lt; x^2\)</span> is not
true is <span class="math">\(\frac{1}{2}\)</span>; squaring <span class="math">\(\frac{1}{2}\)</span> gives you
<span class="math">\(\frac{1}{4}\)</span>.</p>
<p>In fact, for any <span class="math">\(x\)</span> satisfying <span class="math">\(0 \leq x \leq 1\)</span>, we will have
that <span class="math">\(x \geq x^2\)</span>; this is perhaps best illustrated by plotting <span class="math">\(y
= x\)</span> and <span class="math">\(y = x^2\)</span> on a graph:</p>
<img alt="_images/x-vs-x2.png" src="_images/x-vs-x2.png" />
</div>
</div>
</div>
<span id="document-appendix/solutions/monoids"></span><div class="section" id="monoids">
<h5>Monoids<a class="headerlink" href="#monoids" title="Permalink to this headline">¶</a></h5>
<div class="toctree-wrapper compound">
<span id="document-appendix/solutions/monoids/ex1"></span><div class="section" id="exercise-2-1">
<h6>Exercise 2.1<a class="headerlink" href="#exercise-2-1" title="Permalink to this headline">¶</a></h6>
<p>The natural numbers together with subtraction <span class="math">\((\mathbb{N}, -)\)</span> is not a
monoid; it fails to satisfy any of the three monoid laws!</p>
<p>It doesn’t satisfy closure because if you subtract a larger number from a
smaller number, you get a negative number (recall that there are no negative
numbers in <span class="math">\(\mathbb{N}\)</span>).</p>
<p>It doesn’t satisfy associativity. For example:</p>
<div class="math">
\[\begin{split}(3 - 0) - 2 &amp;= 3 - 2 \\
            &amp;= 1\end{split}\]</div>
<p>But:</p>
<div class="math">
\[\begin{split}3 - (0 - 2) &amp;= 3 - (-2) \\
            &amp;= 5\end{split}\]</div>
<p>It fails to satisfy identity as well. To see this, we will first note that
there is only one <em>right identity</em> in this set; that is, there is only one
<span class="math">\(e \in \mathbb{N}\)</span> which makes the following equation hold for all
<span class="math">\(x \in \mathbb{N}\)</span>:</p>
<div class="math">
\[x - e = x\]</div>
<p>It’s not too difficult to see that this <span class="math">\(e\)</span> is <span class="math">\(0\)</span>. So <span class="math">\(0\)</span> is
the only possible candidate to be the identity element thus far. But remember
that we need it to work the other way around too: to be the identity element,
we need it to be a <em>left identity</em> too; that is, it needs to satisfy the
following for all <span class="math">\(x \in \mathbb{N}\)</span>:</p>
<div class="math">
\[e - x = x\]</div>
<p>But if we set <span class="math">\(e\)</span> to be <span class="math">\(0\)</span>, this won’t work, so <span class="math">\(0\)</span> is not a
left identity. In fact no element of <span class="math">\(\mathbb{N}\)</span> is a left identity
under subtraction.</p>
</div>
<span id="document-appendix/solutions/monoids/ex2"></span><div class="section" id="exercise-2-2">
<h6>Exercise 2.2<a class="headerlink" href="#exercise-2-2" title="Permalink to this headline">¶</a></h6>
<p>We first check the closure law for <span class="math">\((\mathbb{Q}, +)\)</span>. Suppose we have two
arbitrary elements of <span class="math">\(\mathbb{Q}\)</span>; we can write them as
<span class="math">\(\frac{a}{b}\)</span> and <span class="math">\(\frac{c}{d}\)</span>, where <span class="math">\(a, b, c, d \in
\mathbb{Z}\)</span>.</p>
<p>Then:</p>
<div class="math">
\[\begin{split}\frac{a}{b} + \frac{c}{d} &amp;= \frac{ad}{bd} + \frac{bc}{bd} \\
                          &amp;= \frac{ad + bc}{bd}.\end{split}\]</div>
<p>We have an integer on the top and an integer on the bottom, so the result of
adding these two values is in <span class="math">\(\mathbb{Q}\)</span>, and therefore the closure
law is satisfied.</p>
<p>We could check associativity similarly to how we checked closure, but we
already know that addition is associative for all real numbers; since the
rational numbers are a subset of the real numbers, we can simply conclude that
the associativity law holds for <span class="math">\((\mathbb{Q}, +)\)</span>.</p>
<p>The identity element in <span class="math">\((\mathbb{Q}, +)\)</span> is 0, just like in
<span class="math">\((\mathbb{Z}, +)\)</span> and in <span class="math">\((\mathbb{R}, +)\)</span>.</p>
</div>
<span id="document-appendix/solutions/monoids/ex3"></span><div class="section" id="exercise-2-3">
<h6>Exercise 2.3<a class="headerlink" href="#exercise-2-3" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\((M, *)\)</span> be a monoid, and let <span class="math">\(e, e' \in M\)</span>. Assume that
<span class="math">\(e\)</span> and <span class="math">\(e'\)</span> are both identity elements; that is,</p>
<div class="math">
\[ \begin{align}\begin{aligned}\forall x \in M.\; e * x = x * e = x\\\forall x \in M.\; e' * x = x * e' = x.\end{aligned}\end{align} \]</div>
<p>Now what is the result of <span class="math">\(e * e'\)</span>? Since <span class="math">\(e\)</span> is an identity, we
must have that <span class="math">\(e * e' = e'\)</span>. Additionally, since <span class="math">\(e'\)</span> is an
identity, we must have that <span class="math">\(e * e' = e\)</span>. The only way that <span class="math">\(e *
e'\)</span> can be equal to both of these two things at once is if they are the same,
so we conclude that <span class="math">\(e = e'\)</span>, i.e. any monoid has exactly one identity
element.</p>
</div>
<span id="document-appendix/solutions/monoids/ex4"></span><div class="section" id="exercise-2-4">
<h6>Exercise 2.4<a class="headerlink" href="#exercise-2-4" title="Permalink to this headline">¶</a></h6>
<p>We check each monoid law in turn:</p>
<p><em>Closure.</em> If we have two functions <span class="math">\(f, g \in \mathrm{Maps}(X, M)\)</span>, then
their star product is itself a function from <span class="math">\(X\)</span> to <span class="math">\(M\)</span>, i.e.
<span class="math">\(f \star g \in \mathrm{Maps}(X, M)\)</span>. So closure is satisfied.</p>
<p><em>Associativity.</em> Let <span class="math">\(f, g, h \in \mathrm{Maps}(X, M)\)</span>. Then:</p>
<div class="math">
\[\begin{split}(f \star g) \star h
  &amp;= (x \mapsto f(x) * g(x)) \star h \\
  &amp;= x \mapsto (f(x) * g(x)) * h(x) \\
  &amp;= x \mapsto f(x) * (g(x) * h(x)) \\
  &amp;= f \star (x \mapsto g(x) * h(x)) \\
  &amp;= f \star (g \star h)\end{split}\]</div>
<p>This gets a little bit messy, but the key observation is that associativity
of the star product follows from associativity of the underlying monoid
<span class="math">\((M, *)\)</span>. So associativity is satisfied.</p>
<p><em>Identity.</em> Let <span class="math">\(\iota : X \rightarrow M\)</span> be defined by <span class="math">\(\iota(x) =
e_M\)</span>, where <span class="math">\(e_M\)</span> denotes the identity element in <span class="math">\(M\)</span>. Then, for
any <span class="math">\(f \in \mathrm{Maps}(X, M)\)</span>, we have that:</p>
<div class="math">
\[ \begin{align}\begin{aligned}f \star \iota = x \mapsto f(x) * e_M = x \mapsto f(x) = f\\\iota \star f = x \mapsto e_M * f(x) = x \mapsto f(x) = f\end{aligned}\end{align} \]</div>
<p>That is, <span class="math">\(\iota\)</span> is the identity element of <span class="math">\((\mathrm{Maps}(X, M),
\star)\)</span>. So identity is satisifed, and this completes the proof.</p>
</div>
</div>
</div>
<span id="document-appendix/solutions/groups"></span><div class="section" id="groups">
<h5>Groups<a class="headerlink" href="#groups" title="Permalink to this headline">¶</a></h5>
<div class="toctree-wrapper compound">
<span id="document-appendix/solutions/groups/ex1"></span><div class="section" id="exercise-3-1">
<h6>Exercise 3.1<a class="headerlink" href="#exercise-3-1" title="Permalink to this headline">¶</a></h6>
<p>If we take the monoid of the set of truth-values <span class="math">\(\{T, F\}\)</span> together with
<span class="math">\(\land\)</span>, we can write</p>
<div class="math">
\[F \land x = T\]</div>
<p>which is unsatisfiable; the equation does not hold for either of the two
possible values of <span class="math">\(x \in \{T, F\}\)</span>.</p>
<p>Another example is the monoid of strings, i.e. the <code class="docutils literal"><span class="pre">Monoid</span> <span class="pre">String</span></code> instance
in PureScript. The following equation is unsatisfiable, for any possible <code class="docutils literal"><span class="pre">x</span> <span class="pre">::</span>
<span class="pre">String</span></code> value:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="s2">&quot;abc&quot;</span> <span class="o">&lt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="s2">&quot;def&quot;</span>
</pre></div>
</div>
<p>One final example is the monoid <span class="math">\((\mathbb{N}, \max)\)</span>, where
<span class="math">\(\max(x, y)\)</span> is defined to be the larger of <span class="math">\(x\)</span> and <span class="math">\(y\)</span>. Then
this equation is unsatisfiable:</p>
<div class="math">
\[\max(5, x) = 4\]</div>
<p>If <span class="math">\(x \leq 5\)</span>, then <span class="math">\(\max(5, x) = 5\)</span>. If <span class="math">\(x &gt; 5\)</span>, then
<span class="math">\(\max(5, x) = x\)</span>. Either way, the result can never be <span class="math">\(4\)</span>.</p>
</div>
<span id="document-appendix/solutions/groups/ex2"></span><div class="section" id="exercise-3-2">
<h6>Exercise 3.2<a class="headerlink" href="#exercise-3-2" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\((G, *)\)</span> be a group. We are looking for an <span class="math">\(e^{-1} \in G\)</span> such
that <span class="math">\(e * e^{-1} = e^{-1} * e = e\)</span> (remember that inverses are unique, so
there must be exactly one such <span class="math">\(e^{-1}\)</span>).</p>
<p>By the monoid identity law (remember all groups are monoids), we have that
<span class="math">\(e * e = e\)</span>, so the inverse of the identity must be the identity itself.</p>
</div>
<span id="document-appendix/solutions/groups/ex3"></span><div class="section" id="exercise-3-3">
<h6>Exercise 3.3<a class="headerlink" href="#exercise-3-3" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\(G\)</span> be a group, and let <span class="math">\(g, h \in G\)</span>. We’re going to try
multiplying <span class="math">\(g^{-1} h^{-1}\)</span> and <span class="math">\(hg\)</span> and seeing what happens:</p>
<div class="math">
\[ \begin{align}\begin{aligned}&amp;g^{-1} h^{-1} hg\\&amp;= g^{-1} (h^{-1}h) g\\&amp;= g^{-1} e g\\&amp;= g^{-1} g\\&amp;= e.\end{aligned}\end{align} \]</div>
<p>Since inverses are unique, we know that <span class="math">\(hg\)</span> must be the unique inverse
of <span class="math">\(g^{-1} h^{-1}\)</span>. That is, <span class="math">\(g^{-1} h^{-1} = (hg)^{-1}\)</span>.</p>
</div>
<span id="document-appendix/solutions/groups/ex4"></span><div class="section" id="exercise-3-4">
<h6>Exercise 3.4<a class="headerlink" href="#exercise-3-4" title="Permalink to this headline">¶</a></h6>
<div class="section" id="part-a">
<h7>Part a)<a class="headerlink" href="#part-a" title="Permalink to this headline">¶</a></h7>
<p>Essentially, we are looking for an integer that solves <span class="math">\(3 + x = 2\)</span>, which
is clearly <span class="math">\(x = -1\)</span>. So the answer is <span class="math">\(\overline{-1}\)</span>. However, it
is customary to use a number between <span class="math">\(0\)</span> and <span class="math">\(m - 1\)</span> as the
representative for an element of <span class="math">\(\mathbb{Z}_m\)</span>. Remember that
<span class="math">\(\overline{x} = \overline{x + 12}\)</span>, so in particular <span class="math">\(\overline{-1}
= \overline{11}\)</span>. So we write the answer as <span class="math">\(\overline{11}\)</span>.</p>
</div>
<div class="section" id="part-b">
<h7>Part b)<a class="headerlink" href="#part-b" title="Permalink to this headline">¶</a></h7>
<p>The procedure is similar to part a); we are looking for an integer that solves
<span class="math">\(5 + x = 0\)</span>, which is clearly <span class="math">\(x = -5\)</span>, giving us the answer
<span class="math">\(\overline{-5} = \overline{7}\)</span>.</p>
</div>
</div>
<span id="document-appendix/solutions/groups/ex5"></span><div class="section" id="exercise-3-5">
<h6>Exercise 3.5<a class="headerlink" href="#exercise-3-5" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\(X = \{ 1, 2, ... , n \}\)</span>, and let <span class="math">\(f : X \to X\)</span> be bijective.
We wish to determine how many possibilities there are for <span class="math">\(f\)</span>. To
determine a particular choice of <span class="math">\(f\)</span>, we need to say what it does to each
element of <span class="math">\(X\)</span>:</p>
<div class="math">
\[ \begin{align}\begin{aligned}f(1) = \, ???\\f(2) = \, ???\\...\\f(n) = \, ???\end{aligned}\end{align} \]</div>
<p>We have <span class="math">\(n\)</span> choices to make: on the right-hand side of each of the above
<span class="math">\(n\)</span> equations, we need to choose an element of <span class="math">\(X\)</span>. However,
remember that the function we end up with needs to be <em>bijective</em>. That means
that each element of <span class="math">\(X\)</span> needs to appear on the right-hand side of
exactly one of these equations.</p>
<p>Suppose we decide to make a choice for <span class="math">\(f(1)\)</span> first. We may choose any
element of <span class="math">\(X\)</span>, so we have <span class="math">\(n\)</span> options.</p>
<p>Now, we decide to make a choice for <span class="math">\(f(2)\)</span>. We may choose any element of
<span class="math">\(X\)</span> other than the element we chose for <span class="math">\(f(1)\)</span>, which means we have
<span class="math">\(n-1\)</span> choices.</p>
<p>For <span class="math">\(f(3)\)</span>, we may choose any element of <span class="math">\(X\)</span> other than the
elements we chose for <span class="math">\(f(1)\)</span> and <span class="math">\(f(2)\)</span>, which means we have
<span class="math">\(n-3\)</span> choices.</p>
<p>We continue this process until we reach the end of our list of equations, at
<span class="math">\(f(n)\)</span>. At this point there will only be one element of <span class="math">\(X\)</span>
remaining which we haven’t yet picked, so we have no freedom at all here: we
have to choose that element for <span class="math">\(f(n)\)</span>.</p>
<p>In a process which involves making a sequence of choices, the total number of
end possibilities is equal to the product of the number of possibilities for
each choice. Therefore, the number of possibilities for an arbitrary
permutation <span class="math">\(f\)</span> of <span class="math">\(X\)</span> is</p>
<div class="math">
\[n \times (n-1) \times (n-2) \; \times \; ... \; \times \; 2 \times 1 = n!\]</div>
</div>
</div>
</div>
<span id="document-appendix/solutions/rings"></span><div class="section" id="rings">
<h5>Rings<a class="headerlink" href="#rings" title="Permalink to this headline">¶</a></h5>
<div class="toctree-wrapper compound">
<span id="document-appendix/solutions/rings/ex1"></span><div class="section" id="exercise-4-1">
<h6>Exercise 4.1<a class="headerlink" href="#exercise-4-1" title="Permalink to this headline">¶</a></h6>
<p>This follows from the previous theorem we proved, that <span class="math">\((-x)y = -(xy)\)</span>:</p>
<div class="math">
\[\begin{split}(-x)(-y) &amp;= -(x(-y)) \\
         &amp;= -(-(xy)) \\
         &amp;= xy\end{split}\]</div>
<p>In the first and second steps, we are just applying the previous theorem. In
the final step, we are using a property of groups, which is that the inverse of
the inverse of some element is just that element. In other words, if you invert
an element twice, you end up with what you started with.</p>
</div>
</div>
</div>
<span id="document-appendix/solutions/matrices"></span><div class="section" id="matrices">
<h5>Matrices<a class="headerlink" href="#matrices" title="Permalink to this headline">¶</a></h5>
<div class="toctree-wrapper compound">
<span id="document-appendix/solutions/matrices/ex1"></span><div class="section" id="exercise-5-1">
<h6>Exercise 5.1<a class="headerlink" href="#exercise-5-1" title="Permalink to this headline">¶</a></h6>
<p>We need to prove the associativity law for <span class="math">\((\mathbb{R}^2, +)\)</span>; that is,
we need to show that <span class="math">\(\forall \boldsymbol{x}, \boldsymbol{y},
\boldsymbol{z} \in \mathbb{R}^2.\; (\boldsymbol{x} + \boldsymbol{y}) +
\boldsymbol{z} = \boldsymbol{x} + (\boldsymbol{y} + \boldsymbol{z})\)</span>.</p>
<p>This result follows naturally from associativity of addition in
<span class="math">\(\mathbb{R}\)</span>:</p>
<div class="math">
\[\begin{split}(
  \begin{bmatrix}x_1\\x_2\end{bmatrix} +
  \begin{bmatrix}y_1\\y_2\end{bmatrix}
) +
\begin{bmatrix}z_1\\z_2\end{bmatrix}
&amp;=
\begin{bmatrix}x_1 + y_1\\x_1 + y_2\end{bmatrix} +
\begin{bmatrix}z_1\\z_2\end{bmatrix}
\\ &amp;=
\begin{bmatrix}x_1 + y_1 + z_1\\x_1 + y_2 + z_2\end{bmatrix}
\\ &amp;=
\begin{bmatrix}x_1\\x_2\end{bmatrix} +
\begin{bmatrix}y_1 + z_1\\y_1 + z_2\end{bmatrix}
\\ &amp;=
\begin{bmatrix}x_1\\x_2\end{bmatrix} +
(
  \begin{bmatrix}y_1\\y_2\end{bmatrix} +
  \begin{bmatrix}z_1\\z_2\end{bmatrix}
)\end{split}\]</div>
</div>
<span id="document-appendix/solutions/matrices/ex2"></span><div class="section" id="exercise-5-2">
<h6>Exercise 5.2<a class="headerlink" href="#exercise-5-2" title="Permalink to this headline">¶</a></h6>
<p>We need to come up with a recipe for finding the inverse of a vector in
<span class="math">\((\mathbb{R}^2, +)\)</span>: that is, given a vector, find another vector such that
the sum of these two vectors is the the zero vector.</p>
<p>Suppose we have an <span class="math">\(\boldsymbol{x} \in \mathbb{R}^2\)</span>, so
<span class="math">\(\boldsymbol{x} = (x_1, x_2)\)</span>. If we add it to some other vector
<span class="math">\(\boldsymbol{y} = (y_1, y_2)\)</span>, we get <span class="math">\((x_1 + y_1, x_2 + y_2)\)</span>.
For this sum to be equal to the zero vector we have to choose <span class="math">\(y_1, y_2\)</span>
so that the following two equations are satisfied:</p>
<div class="math">
\[ \begin{align}\begin{aligned}x_1 + y_1 = 0\\x_2 + y_2 = 0\end{aligned}\end{align} \]</div>
<p>The solution is therefore</p>
<div class="math">
\[ \begin{align}\begin{aligned}y_1 = -x_1\\y_2 = -x_2\end{aligned}\end{align} \]</div>
<p>or simply <span class="math">\(\boldsymbol{y} = -\boldsymbol{x}\)</span>. That is, you can invert a
vector in <span class="math">\((\mathbb{R}^2, +)\)</span> by performing a scalar multiplication by
<span class="math">\(-1\)</span>.</p>
</div>
<span id="document-appendix/solutions/matrices/ex3"></span><div class="section" id="exercise-5-3">
<h6>Exercise 5.3<a class="headerlink" href="#exercise-5-3" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\(\boldsymbol{x}, \boldsymbol{y} \in \mathbb{R}^2, k \in \mathbb{R}\)</span>.
We will write <span class="math">\(x_1\)</span> for the first component of <span class="math">\(\boldsymbol{x}\)</span>,
<span class="math">\(x_2\)</span> for the second component of <span class="math">\(\boldsymbol{x}\)</span>, and so on.</p>
<p>Then:</p>
<div class="math">
\[\begin{split}k (\boldsymbol{x} + \boldsymbol{y})
  &amp;= k (\begin{bmatrix}x_1\\x_2\end{bmatrix} + \begin{bmatrix}y_1\\y_2\end{bmatrix}) \\
  &amp;= k (\begin{bmatrix}x_1 + y_1\\x_2 + y_2\end{bmatrix}) \\
  &amp;= \begin{bmatrix}k(x_1 + y_1)\\k(x_2 + y_2)\end{bmatrix} \\
  &amp;= \begin{bmatrix}kx_1 + ky_1\\kx_2 + ky_2\end{bmatrix} \\
  &amp;= \begin{bmatrix}kx_1\\kx_2\end{bmatrix} + \begin{bmatrix}ky_1\\ky_2\end{bmatrix} \\
  &amp;= k \begin{bmatrix}x_1\\x_2\end{bmatrix} + k \begin{bmatrix}y_1\\y_2\end{bmatrix} \\
  &amp;= k\boldsymbol{x} + k\boldsymbol{y}\end{split}\]</div>
</div>
<span id="document-appendix/solutions/matrices/ex4"></span><div class="section" id="exercise-5-4">
<h6>Exercise 5.4<a class="headerlink" href="#exercise-5-4" title="Permalink to this headline">¶</a></h6>
<p>As in exercise 5.3, we will write the <span class="math">\(i\)</span>-th component of a vector
<span class="math">\(\boldsymbol{x}\)</span> as <span class="math">\(x_i\)</span>.</p>
<p>For the first identity:</p>
<div class="math">
\[\begin{split}\boldsymbol{x} \cdot (\boldsymbol{y} + \boldsymbol{z})
  &amp;= \begin{bmatrix}x_1\\x_2\end{bmatrix} \cdot (\begin{bmatrix}y_1\\y_2\end{bmatrix} + \begin{bmatrix}z_1\\z_2\end{bmatrix}) \\
  &amp;= \begin{bmatrix}x_1\\x_2\end{bmatrix} \cdot \begin{bmatrix}y_1+z_1\\y_2+z_2\end{bmatrix} \\
  &amp;= x_1(y_1 + z_1) + x_2(y_2 + z_2) \\
  &amp;= x_1y_1 + x_1z_1 + x_2y_2 + x_2z_2 \\
  &amp;= (x_1y_1 + x_2y_2) + (x_1z_1 + x_2z_2) \\
  &amp;= (\begin{bmatrix}x_1\\x_2\end{bmatrix} \cdot \begin{bmatrix}y_1\\y_2\end{bmatrix}) +
     (\begin{bmatrix}x_1\\x_2\end{bmatrix} \cdot \begin{bmatrix}z_1\\z_2\end{bmatrix}) \\
  &amp;= \boldsymbol{x} \cdot \boldsymbol{y} + \boldsymbol{x} \cdot \boldsymbol{z}\end{split}\]</div>
<p>For the second:</p>
<div class="math">
\[\begin{split}(k_1 \boldsymbol{x}) \cdot (k_2 \boldsymbol{y})
  &amp;= \begin{bmatrix}k_1x_1\\k_1x_2\end{bmatrix} \cdot \begin{bmatrix}k_2y_1\\k_2y_2\end{bmatrix} \\
  &amp;= (k_1x_1)(k_2y_1) + (k_1x_2)(k_2y_2) \\
  &amp;= k_1 k_2 (x_1y_1 + x_2y_2) \\
  &amp;= k_1 k_2 (\boldsymbol{x} \cdot \boldsymbol{y})\end{split}\]</div>
</div>
<span id="document-appendix/solutions/matrices/ex5"></span><div class="section" id="exercise-5-5">
<h6>Exercise 5.5<a class="headerlink" href="#exercise-5-5" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\(\boldsymbol{a}_1, \boldsymbol{a}_2 \in \mathbb{R}^2\)</span>, and define</p>
<div class="math">
\[\begin{split}f = \boldsymbol{x} \mapsto
    \begin{bmatrix}\boldsymbol{a_1} \cdot \boldsymbol{x} \\
                   \boldsymbol{a_2} \cdot \boldsymbol{x} \end{bmatrix}\end{split}\]</div>
<p>Then,</p>
<div class="math">
\[\begin{split}f(\boldsymbol{x} + \boldsymbol{y})
  &amp;= \begin{bmatrix}
       \boldsymbol{a_1} \cdot (\boldsymbol{x} + \boldsymbol{y}) \\
       \boldsymbol{a_2} \cdot (\boldsymbol{x} + \boldsymbol{y})
     \end{bmatrix} \\
  &amp;= \begin{bmatrix}
       \boldsymbol{a_1} \cdot \boldsymbol{x} + \boldsymbol{a_1} \cdot \boldsymbol{y} \\
       \boldsymbol{a_2} \cdot \boldsymbol{x} + \boldsymbol{a_2} \cdot \boldsymbol{y} \\
     \end{bmatrix} \\
  &amp;= \begin{bmatrix}
       \boldsymbol{a_1} \cdot \boldsymbol{x} \\
       \boldsymbol{a_2} \cdot \boldsymbol{x}
     \end{bmatrix} +
     \begin{bmatrix}
       \boldsymbol{a_1} \cdot \boldsymbol{y} \\
       \boldsymbol{a_2} \cdot \boldsymbol{y}
     \end{bmatrix} \\
  &amp;= f(\boldsymbol{x}) + f(\boldsymbol{y})\end{split}\]</div>
<p>The important thing to note about this proof is that we are using the property
which we previously proved about the dot product, that <span class="math">\(\boldsymbol{x}
\cdot (\boldsymbol{y} + \boldsymbol{z}) = \boldsymbol{x} \cdot \boldsymbol{y} +
\boldsymbol{x} \cdot \boldsymbol{z}\)</span>.</p>
<p>Similarly,</p>
<div class="math">
\[\begin{split}f(k \boldsymbol{x})
  &amp;= \begin{bmatrix}
       \boldsymbol{a_1} \cdot (k\boldsymbol{x}) \\
       \boldsymbol{a_2} \cdot (k\boldsymbol{x})
     \end{bmatrix} \\
  &amp;= \begin{bmatrix}
       k (\boldsymbol{a_1} \cdot \boldsymbol{x}) \\
       k (\boldsymbol{a_2} \cdot \boldsymbol{x})
     \end{bmatrix} \\
  &amp;= k \begin{bmatrix}
       \boldsymbol{a_1} \cdot \boldsymbol{x} \\
       \boldsymbol{a_2} \cdot \boldsymbol{x}
     \end{bmatrix} \\
  &amp;= k f(\boldsymbol{x})\end{split}\]</div>
<p>This argument similarly uses the other property of the dot product which we
proved a moment ago, namely that <span class="math">\((k_1 \boldsymbol{x}) \cdot (k_2
\boldsymbol{y}) = k_1 k_2 (\boldsymbol{x} \cdot \boldsymbol{y})\)</span>.</p>
<p>We have proved that the two linear mapping laws hold for any such function
<span class="math">\(f\)</span>, and therefore we are done: any function defined in terms of dot
products like this is a linear mapping.</p>
</div>
<span id="document-appendix/solutions/matrices/ex6"></span><div class="section" id="exercise-5-6">
<h6>Exercise 5.6<a class="headerlink" href="#exercise-5-6" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\(f, g\)</span> be linear mappings. We consider the function <span class="math">\(f \circ
g\)</span>, defined as</p>
<div class="math">
\[f \circ g = \boldsymbol{x} \mapsto f(g(\boldsymbol{x}).\]</div>
<p>Firstly, we know that</p>
<div class="math">
\[f(g(\boldsymbol{x} + \boldsymbol{y})) = f(g(\boldsymbol{x}) + g(\boldsymbol{y}))\]</div>
<p>since <span class="math">\(g\)</span> is a linear mapping by assumption. Now we use the fact that
<span class="math">\(f\)</span> is a linear mapping to conclude that</p>
<div class="math">
\[f(g(\boldsymbol{x}) + g(\boldsymbol{y})) = f(g(\boldsymbol{x})) + f(g(\boldsymbol{y})).\]</div>
<p>We have therefore shown that <span class="math">\((f \circ g)(\boldsymbol{x} +
\boldsymbol{y}) = (f \circ g)(\boldsymbol{x}) + (f \circ g)(\boldsymbol{y})\)</span>
and so we have established the first linear mapping law.</p>
<p>The second part of the proof is very similar: we show that <span class="math">\(f \circ g\)</span> is
compatible with scalar multiplication by first using the fact that <span class="math">\(g\)</span> is
compatible with scalar multiplication and then by using the fact that <span class="math">\(f\)</span>
is.</p>
</div>
</div>
</div>
<span id="document-appendix/solutions/integral-domains"></span><div class="section" id="integral-domains">
<h5>Integral domains<a class="headerlink" href="#integral-domains" title="Permalink to this headline">¶</a></h5>
<div class="toctree-wrapper compound">
<span id="document-appendix/solutions/integral-domains/ex1"></span><div class="section" id="exercise-6-1">
<h6>Exercise 6.1<a class="headerlink" href="#exercise-6-1" title="Permalink to this headline">¶</a></h6>
<p>There are two possible options for <span class="math">\(b\)</span> such that <span class="math">\(\overline{3}
\cdot b = 0\)</span>. They are <span class="math">\(\overline{4}\)</span> and <span class="math">\(\overline{8}\)</span>; notice
that</p>
<div class="math">
\[\overline{3} \cdot \overline{4} = \overline{3 \times 4} = \overline{12} = \overline{0}\]</div>
<p>and also that</p>
<div class="math">
\[\overline{3} \cdot \overline{8} = \overline{3 \times 8} = \overline{24} = \overline{0}.\]</div>
</div>
<span id="document-appendix/solutions/integral-domains/ex2"></span><div class="section" id="exercise-6-2">
<h6>Exercise 6.2<a class="headerlink" href="#exercise-6-2" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\(R\)</span> be a ring, and suppose <span class="math">\(1\)</span> is a zero-divisor. That is,
there exists a <span class="math">\(b \in R\)</span> with <span class="math">\(b \neq 0\)</span> such that <span class="math">\(1 \cdot b
= 0\)</span> or <span class="math">\(b \cdot 1 = 0\)</span>. But <span class="math">\(1 \cdot b = b \cdot 1 = b\)</span> since
<span class="math">\(1\)</span> is the multiplicative identity. So <span class="math">\(b = 0\)</span>, but this is a
contradiction. Therefore <span class="math">\(1\)</span> cannot be a zero-divisor.</p>
</div>
<span id="document-appendix/solutions/integral-domains/ex3"></span><div class="section" id="exercise-6-3">
<h6>Exercise 6.3<a class="headerlink" href="#exercise-6-3" title="Permalink to this headline">¶</a></h6>
<p>The ring <span class="math">\(\mathbb{Z}_8\)</span> is commutative, so our only option to show that
it is not an integral domain is to show that it has a zero-divisor. There are
in fact three zero-divisors in <span class="math">\(\mathbb{Z}_8\)</span>: they are
<span class="math">\(\overline{2}, \overline{4},\)</span> and <span class="math">\(\overline{6}\)</span>. Each of these
yields <span class="math">\(\overline{0}\)</span> when multiplied by <span class="math">\(\overline{4}\)</span>.</p>
</div>
<span id="document-appendix/solutions/integral-domains/ex4"></span><div class="section" id="exercise-6-4">
<h6>Exercise 6.4<a class="headerlink" href="#exercise-6-4" title="Permalink to this headline">¶</a></h6>
<p>Suppose <span class="math">\(m \geq 2\)</span> and <span class="math">\(\mathbb{Z}_m\)</span> has a zero-divisor. That is,
there exist integers <span class="math">\(a, b\)</span> such that <span class="math">\(\overline{a} \neq
\overline{0}, \overline{b} \neq \overline{0},\)</span> and <span class="math">\(\overline{ab} =
\overline{0},\)</span> or equivalently, neither <span class="math">\(a\)</span> nor <span class="math">\(b\)</span> is a multiple
of <span class="math">\(m\)</span>, but <span class="math">\(ab\)</span> is. The only way this can happen is if <span class="math">\(m\)</span>
is composite i.e. not prime, as in this case there must exist integers <span class="math">\(1
&lt; k, l &lt; m\)</span> with <span class="math">\(kl = m\)</span> such that <span class="math">\(k\)</span> divides <span class="math">\(a\)</span> and
<span class="math">\(l\)</span> divides <span class="math">\(b\)</span>.</p>
<p>Conversely, suppose <span class="math">\(m \geq 2\)</span> and <span class="math">\(\mathbb{Z}_m\)</span> is an integral
domain, i.e. it has no zero-divisors. That is, for any integers <span class="math">\(a, b\)</span>
with <span class="math">\(1 &lt; a, b &lt; m,\)</span> we have that <span class="math">\(ab\)</span> is not a multiple of
<span class="math">\(m\)</span>. The only way this can happen is if <span class="math">\(m\)</span> is prime.</p>
<p>Therefore, <span class="math">\(\mathbb{Z}_m\)</span> is an integral domain if and only if <span class="math">\(m\)</span>
is prime.</p>
</div>
</div>
</div>
<span id="document-appendix/solutions/euclidean-algorithm"></span><div class="section" id="the-euclidean-algorithm">
<h5>The Euclidean Algorithm<a class="headerlink" href="#the-euclidean-algorithm" title="Permalink to this headline">¶</a></h5>
<div class="toctree-wrapper compound">
<span id="document-appendix/solutions/euclidean-algorithm/ex1"></span><div class="section" id="exercise-9-1">
<h6>Exercise 9.1<a class="headerlink" href="#exercise-9-1" title="Permalink to this headline">¶</a></h6>
<p>We want to find the greatest common divisor of <span class="math">\(a = 1938\)</span> and <span class="math">\(b =
782\)</span>. We start by dividing <span class="math">\(1938\)</span> by <span class="math">\(782\)</span>:</p>
<div class="math">
\[1938 = 2 * 782 + 374\]</div>
<p>And now we divide <span class="math">\(798\)</span> by the remainder, <span class="math">\(374\)</span>:</p>
<div class="math">
\[782 = 2 * 374 + 34\]</div>
<p>Then we divide <span class="math">\(374\)</span> by our new remainder, <span class="math">\(34\)</span>:</p>
<div class="math">
\[374 = 11 * 34\]</div>
<p>This time, it goes exactly. So the greatest common divisor is <span class="math">\(34\)</span>.</p>
</div>
</div>
</div>
<span id="document-appendix/solutions/euclidean-rings"></span><div class="section" id="euclidean-rings">
<h5>Euclidean rings<a class="headerlink" href="#euclidean-rings" title="Permalink to this headline">¶</a></h5>
<div class="toctree-wrapper compound">
<span id="document-appendix/solutions/euclidean-rings/ex1"></span><div class="section" id="exercise-11-1">
<h6>Exercise 11.1<a class="headerlink" href="#exercise-11-1" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\(a, b \in \mathbb{Z}\)</span>, with both nonzero. We want to show that
<span class="math">\(\lvert a \rvert \leq \lvert ab \rvert\)</span>.</p>
<p>There are a few ways to do this. For the way I’m going to use here, our first
step is to show that <span class="math">\(\lvert ab \rvert = \lvert a \rvert \lvert b
\rvert\)</span> for any integers <span class="math">\(a, b.\)</span> In fact, this always holds, even if
<span class="math">\(a\)</span> or <span class="math">\(b\)</span> is zero. This can be proved by cases. We’ll consider
four cases:</p>
<ul class="simple">
<li><span class="math">\(a \geq 0, \; b \geq 0\)</span></li>
<li><span class="math">\(a \geq 0, \; b &lt; 0\)</span></li>
<li><span class="math">\(a &lt; 0,    \; b \geq 0\)</span></li>
<li><span class="math">\(a &lt; 0,    \; b &lt; 0\)</span></li>
</ul>
<p>In the first case, since both <span class="math">\(a\)</span> and <span class="math">\(b\)</span> are nonnegative, we have
that <span class="math">\(\lvert a \rvert = a\)</span> and <span class="math">\(\lvert b \rvert = b\)</span>, so it follows
that <span class="math">\(\lvert a \rvert \lvert b \rvert\)</span> is equal to <span class="math">\(ab\)</span>.  Also,
since <span class="math">\(a\)</span> and <span class="math">\(b\)</span> are both nonnegative, their product <span class="math">\(ab\)</span> is
also nonnegative, so <span class="math">\(\lvert ab \rvert = ab\)</span> and we are done.</p>
<p>In the second case, we have that <span class="math">\(\lvert a \rvert = a\)</span> as before, but
<span class="math">\(\lvert b \rvert = -b\)</span>, since <span class="math">\(b\)</span> is negative, and so the right
hand side is equal to <span class="math">\(-ab\)</span>. Also, in this case, the product <span class="math">\(ab
\leq 0\)</span>, so on the left hand side, we have <span class="math">\(\lvert ab \rvert = -ab\)</span>. So
both sides are equal to <span class="math">\(-ab\)</span> and we are done.</p>
<p>The remaining two cases play out similarly, so I won’t bother to write them
out.</p>
<p>Now we know that <span class="math">\(\lvert ab \rvert = \lvert a \rvert \lvert b \rvert\)</span>, we
can return to our original question. Using our new knowledge, we can rewrite
the statement we are trying to prove as <span class="math">\(\lvert a \rvert \leq \lvert a
\rvert \lvert b \rvert\)</span>. One thing we can do with inequalities is divide both
sides by a positive number. Since we have by assumption that <span class="math">\(a\)</span> is
nonzero, it follows that <span class="math">\(\lvert a \rvert &gt; 0\)</span> and so we can divide both
sides by <span class="math">\(\lvert a \rvert\)</span>, leaving us with <span class="math">\(1 \leq \lvert b
\rvert\)</span>. And since <span class="math">\(b\)</span> is a nonzero integer, <span class="math">\(\lvert b \rvert\)</span> must
be a positive integer, so <span class="math">\(1 \leq \lvert b \rvert\)</span> is necessarily true,
and we are done.</p>
</div>
<span id="document-appendix/solutions/euclidean-rings/ex2"></span><div class="section" id="exercise-11-2">
<h6>Exercise 11.2<a class="headerlink" href="#exercise-11-2" title="Permalink to this headline">¶</a></h6>
<p>Let <span class="math">\(F\)</span> be a field and let <span class="math">\(a, b \in F[x]\)</span>, with both nonzero. We
want to show that <span class="math">\(\deg(a) \leq \deg(ab)\)</span>.</p>
<p>Consider two nonzero polynomials <span class="math">\(a, b\)</span> and think about their product
<span class="math">\(ab\)</span>.  We already know that the leading term of <span class="math">\(ab\)</span> comes from the
product of the leading terms of <span class="math">\(a\)</span> and <span class="math">\(b\)</span>, whose powers of
<span class="math">\(x\)</span> will be <span class="math">\(\deg(a)\)</span> and <span class="math">\(\deg(b)\)</span> respectively. So the
power of <span class="math">\(x\)</span> in the leading term of <span class="math">\(ab\)</span> is <span class="math">\(\deg(a) +
\deg(b)\)</span>, i.e.  <span class="math">\(\deg(ab) = \deg(a) + \deg(b)\)</span>.</p>
<p>So our original inequality is equivalent to <span class="math">\(\deg(a) \leq \deg(a) +
\deg(b)\)</span> or equivalently, <span class="math">\(0 \leq \deg(b)\)</span>. But we know this to be true
already: the degree of a nonzero polynomial is always nonnegative! So we are
done.</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html#document-index">Table Of Contents</a></h3>
  <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-introduction">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#why">Why?</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#how-to-read-this-guide">How to read this guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#license">License</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-logic">Logic</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#truth-tables">Truth tables</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#logical-equivalence">Logical equivalence</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#logical-negation">Logical negation</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#logical-implication">Logical implication</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#converses">Converses</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#contrapositives">Contrapositives</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#sets">Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#quantifiers">Quantifiers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-monoids">Monoids</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#uniqueness-of-identity-elements">Uniqueness of identity elements</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#some-more-examples">Some more examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-groups">Groups</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#uniqueness-of-inverses">Uniqueness of inverses</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#modular-arithmetic">Modular arithmetic</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#permutations">Permutations</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#cancellation">Cancellation</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#abelian-groups">Abelian groups</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#a-final-note-on-groups">A final note on groups</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-rings">Rings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#the-definition">The definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#properties-of-rings">Properties of rings</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#semirings">Semirings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-matrices">Matrices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#vectors">Vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#linear-mappings">Linear mappings</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#representation-of-linear-mappings-as-matrices">Representation of linear mappings as matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#properties-of-matrix-operations">Properties of matrix operations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-integral-domains">Integral domains</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#the-cancellation-law-for-integral-domains">The cancellation law for integral domains</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-fields">Fields</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#a-quick-diversion-into-set-theory">A quick diversion into set theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#every-field-is-an-integral-domain">Every field is an integral domain</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#every-finite-integral-domain-is-a-field">Every finite integral domain is a field</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-complex-numbers">Complex numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-euclidean-algorithm">The Euclidean Algorithm</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#integer-division">Integer division</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#greatest-common-divisors">Greatest common divisors</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#id1">The Euclidean Algorithm</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-polynomials">Polynomials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#polynomial-division">Polynomial division</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-euclidean-rings">Euclidean rings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#divisors-again">Divisors, again</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#generalising-the-euclidean-algorithm">Generalising the Euclidean Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-quaternions">Quaternions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#multiplicative-inverses">Multiplicative inverses</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#dividing-quaternions">Dividing quaternions</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#using-quaternions-for-rotations">Using quaternions for rotations</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#further-references">Further references</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-epilogue">Epilogue</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html#document-appendix/index">Appendix</a><ul>
<li class="toctree-l2"><a class="reference internal" href="index.html#document-appendix/cheatsheet">Cheatsheet</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#document-appendix/purescript-impls">PureScript implementations of objects discussed in this guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#document-appendix/solutions">Solutions to Exercises</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html#document-index">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017-2018, Harry Garrood.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.7</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.8</a>
      
    </div>

    

    
  </body>
</html>